/**
 * FASE 5: AMAZON ATHENA - SQL SERVERLESS
 * 8 pasos para dominar Athena
 */

import { AWSStep } from '../types';

export const phase5Steps: AWSStep[] = [
  {
    id: 'aws-5-1', stepNumber: 38,
    title: { es: 'Introducci√≥n a Amazon Athena', en: 'Introduction to Amazon Athena', pt: 'Introdu√ß√£o ao Amazon Athena' },
    description: { es: 'Entender qu√© es Athena, pricing y casos de uso.', en: 'Understand what Athena is, pricing and use cases.', pt: 'Entender o que √© Athena, pricing e casos de uso.' },
    theory: { es: `## Amazon Athena - SQL sobre S3\n\n### ¬øQu√© es Athena?\nServicio serverless que permite ejecutar SQL directamente sobre datos en S3 sin cargarlos en una base de datos.\n\n### Pricing\n- **$5 por TB escaneado**\n- Sin costo por queries fallidas\n- Sin costo por DDL (CREATE, ALTER)\n\n### Optimizar costos\n1. Usar Parquet/ORC en lugar de CSV/JSON\n2. Particionar datos (year/month/day)\n3. Usar columnas espec√≠ficas, no SELECT *\n4. Comprimir datos (Snappy, Gzip)\n\n### Integraci√≥n\n- Usa **Glue Data Catalog** como metastore\n- Resultados van a **S3** (configurable)\n- Conecta con **QuickSight** para BI`, en: `## Amazon Athena - SQL on S3\n\n### What is Athena?\nServerless service that allows running SQL directly on data in S3 without loading it into a database.\n\n### Pricing\n- **$5 per TB scanned**\n- No cost for failed queries\n- No cost for DDL (CREATE, ALTER)\n\n### Optimize costs\n1. Use Parquet/ORC instead of CSV/JSON\n2. Partition data (year/month/day)\n3. Use specific columns, not SELECT *\n4. Compress data (Snappy, Gzip)\n\n### Integration\n- Uses **Glue Data Catalog** as metastore\n- Results go to **S3** (configurable)\n- Connect with **QuickSight** for BI`, pt: `## Amazon Athena - SQL sobre S3\n\n### O que √© Athena?\nServi√ßo serverless que permite executar SQL diretamente sobre dados no S3 sem carreg√°-los em um banco de dados.\n\n### Pricing\n- **$5 por TB escaneado**\n- Sem custo para queries que falham\n- Sem custo para DDL (CREATE, ALTER)\n\n### Otimizar custos\n1. Usar Parquet/ORC em vez de CSV/JSON\n2. Particionar dados (year/month/day)\n3. Usar colunas espec√≠ficas, n√£o SELECT *\n4. Comprimir dados (Snappy, Gzip)\n\n### Integra√ß√£o\n- Usa **Glue Data Catalog** como metastore\n- Resultados v√£o para **S3** (configur√°vel)\n- Conecta com **QuickSight** para BI` },
    practicalTips: [{ es: 'üí∞ Convierte CSVs a Parquet para reducir costos 90%+', en: 'üí∞ Convert CSVs to Parquet to reduce costs 90%+', pt: 'üí∞ Converta CSVs para Parquet para reduzir custos 90%+' }],
    externalLinks: [{ title: 'Amazon Athena User Guide', url: 'https://docs.aws.amazon.com/athena/latest/ug/what-is.html', type: 'aws_docs' }],
    checkpoint: { es: '‚úÖ ¬øEjecutaste tu primera query en Athena?', en: '‚úÖ Did you run your first query in Athena?', pt: '‚úÖ Voc√™ executou sua primeira query no Athena?' },
    xpReward: 50, estimatedMinutes: 25, services: ['Athena']
  },
  {
    id: 'aws-5-2', stepNumber: 39,
    title: { es: 'Crear tablas externas en Athena', en: 'Create external tables in Athena', pt: 'Criar tabelas externas no Athena' },
    description: { es: 'Definir tablas que apuntan a datos en S3.', en: 'Define tables pointing to data in S3.', pt: 'Definir tabelas que apontam para dados no S3.' },
    theory: { es: `## Crear Tablas en Athena\n\n### DDL para tabla Parquet particionada\n\`\`\`sql\nCREATE EXTERNAL TABLE IF NOT EXISTS events (\n  event_id STRING,\n  user_id STRING,\n  event_type STRING,\n  value DOUBLE,\n  timestamp TIMESTAMP\n)\nPARTITIONED BY (year STRING, month STRING, day STRING)\nSTORED AS PARQUET\nLOCATION 's3://bucket/processed/events/'\nTBLPROPERTIES ('parquet.compression'='SNAPPY');\n\n-- A√±adir particiones\nMSCK REPAIR TABLE events;\n\n-- O a√±adir manualmente\nALTER TABLE events ADD PARTITION (year='2024', month='01', day='15')\nLOCATION 's3://bucket/processed/events/year=2024/month=01/day=15/';\n\`\`\`\n\n### Tabla CSV\n\`\`\`sql\nCREATE EXTERNAL TABLE logs (\n  timestamp STRING,\n  level STRING,\n  message STRING\n)\nROW FORMAT DELIMITED FIELDS TERMINATED BY ','\nSTORED AS TEXTFILE\nLOCATION 's3://bucket/raw/logs/';\n\`\`\``, en: `## Create Tables in Athena\n\n### DDL for partitioned Parquet table\n\`\`\`sql\nCREATE EXTERNAL TABLE IF NOT EXISTS events (\n  event_id STRING,\n  user_id STRING,\n  event_type STRING,\n  value DOUBLE,\n  timestamp TIMESTAMP\n)\nPARTITIONED BY (year STRING, month STRING, day STRING)\nSTORED AS PARQUET\nLOCATION 's3://bucket/processed/events/'\nTBLPROPERTIES ('parquet.compression'='SNAPPY');\n\n-- Add partitions\nMSCK REPAIR TABLE events;\n\n-- Or add manually\nALTER TABLE events ADD PARTITION (year='2024', month='01', day='15')\nLOCATION 's3://bucket/processed/events/year=2024/month=01/day=15/';\n\`\`\`\n\n### CSV Table\n\`\`\`sql\nCREATE EXTERNAL TABLE logs (\n  timestamp STRING,\n  level STRING,\n  message STRING\n)\nROW FORMAT DELIMITED FIELDS TERMINATED BY ','\nSTORED AS TEXTFILE\nLOCATION 's3://bucket/raw/logs/';\n\`\`\``, pt: `## Criar Tabelas no Athena\n\n### DDL para tabela Parquet particionada\n\`\`\`sql\nCREATE EXTERNAL TABLE IF NOT EXISTS events (\n  event_id STRING,\n  user_id STRING,\n  event_type STRING,\n  value DOUBLE,\n  timestamp TIMESTAMP\n)\nPARTITIONED BY (year STRING, month STRING, day STRING)\nSTORED AS PARQUET\nLOCATION 's3://bucket/processed/events/'\nTBLPROPERTIES ('parquet.compression'='SNAPPY');\n\n-- Adicionar parti√ß√µes\nMSCK REPAIR TABLE events;\n\n-- Ou adicionar manualmente\nALTER TABLE events ADD PARTITION (year='2024', month='01', day='15')\nLOCATION 's3://bucket/processed/events/year=2024/month=01/day=15/';\n\`\`\`\n\n### Tabela CSV\n\`\`\`sql\nCREATE EXTERNAL TABLE logs (\n  timestamp STRING,\n  level STRING,\n  message STRING\n)\nROW FORMAT DELIMITED FIELDS TERMINATED BY ','\nSTORED AS TEXTFILE\nLOCATION 's3://bucket/raw/logs/';\n\`\`\`` },
    practicalTips: [{ es: 'üîß Usa MSCK REPAIR TABLE para detectar particiones autom√°ticamente', en: 'üîß Use MSCK REPAIR TABLE to detect partitions automatically', pt: 'üîß Use MSCK REPAIR TABLE para detectar parti√ß√µes automaticamente' }],
    externalLinks: [{ title: 'Athena DDL Statements', url: 'https://docs.aws.amazon.com/athena/latest/ug/language-reference.html', type: 'aws_docs' }],
    checkpoint: { es: '‚úÖ ¬øCreaste una tabla particionada en Athena?', en: '‚úÖ Did you create a partitioned table in Athena?', pt: '‚úÖ Voc√™ criou uma tabela particionada no Athena?' },
    xpReward: 55, estimatedMinutes: 30, services: ['Athena']
  },
  {
    id: 'aws-5-3', stepNumber: 40,
    title: { es: 'Optimizaci√≥n de queries en Athena', en: 'Query optimization in Athena', pt: 'Otimiza√ß√£o de queries no Athena' },
    description: { es: 'T√©cnicas para reducir tiempo y costo de queries.', en: 'Techniques to reduce query time and cost.', pt: 'T√©cnicas para reduzir tempo e custo de queries.' },
    theory: { es: `## Optimizaci√≥n de Queries\n\n### 1. Partition pruning\n\`\`\`sql\n-- BIEN: usa filtros de partici√≥n\nSELECT * FROM events WHERE year='2024' AND month='01';\n\n-- MAL: escanea todo\nSELECT * FROM events WHERE timestamp > '2024-01-01';\n\`\`\`\n\n### 2. Column projection\n\`\`\`sql\n-- BIEN: solo columnas necesarias\nSELECT user_id, event_type FROM events;\n\n-- MAL: todas las columnas\nSELECT * FROM events;\n\`\`\`\n\n### 3. Predicate pushdown\n\`\`\`sql\n-- BIEN: filtra temprano en WHERE\nSELECT * FROM events WHERE event_type = 'purchase' AND value > 100;\n\n-- MAL: filtra despu√©s con HAVING sin necesidad\nSELECT event_type, SUM(value) FROM events GROUP BY event_type HAVING event_type = 'purchase';\n\`\`\`\n\n### M√©tricas a monitorear\n- Data scanned (TB)\n- Query execution time\n- Stage-level metrics`, en: `## Query Optimization\n\n### 1. Partition pruning\n\`\`\`sql\n-- GOOD: use partition filters\nSELECT * FROM events WHERE year='2024' AND month='01';\n\n-- BAD: scans everything\nSELECT * FROM events WHERE timestamp > '2024-01-01';\n\`\`\`\n\n### 2. Column projection\n\`\`\`sql\n-- GOOD: only necessary columns\nSELECT user_id, event_type FROM events;\n\n-- BAD: all columns\nSELECT * FROM events;\n\`\`\`\n\n### 3. Predicate pushdown\n\`\`\`sql\n-- GOOD: filter early in WHERE\nSELECT * FROM events WHERE event_type = 'purchase' AND value > 100;\n\n-- BAD: filter after with unnecessary HAVING\nSELECT event_type, SUM(value) FROM events GROUP BY event_type HAVING event_type = 'purchase';\n\`\`\`\n\n### Metrics to monitor\n- Data scanned (TB)\n- Query execution time\n- Stage-level metrics`, pt: `## Otimiza√ß√£o de Queries\n\n### 1. Partition pruning\n\`\`\`sql\n-- BOM: usa filtros de parti√ß√£o\nSELECT * FROM events WHERE year='2024' AND month='01';\n\n-- RUIM: escaneia tudo\nSELECT * FROM events WHERE timestamp > '2024-01-01';\n\`\`\`\n\n### 2. Column projection\n\`\`\`sql\n-- BOM: s√≥ colunas necess√°rias\nSELECT user_id, event_type FROM events;\n\n-- RUIM: todas as colunas\nSELECT * FROM events;\n\`\`\`\n\n### 3. Predicate pushdown\n\`\`\`sql\n-- BOM: filtra cedo no WHERE\nSELECT * FROM events WHERE event_type = 'purchase' AND value > 100;\n\n-- RUIM: filtra depois com HAVING desnecess√°rio\nSELECT event_type, SUM(value) FROM events GROUP BY event_type HAVING event_type = 'purchase';\n\`\`\`\n\n### M√©tricas a monitorar\n- Data scanned (TB)\n- Query execution time\n- Stage-level metrics` },
    practicalTips: [{ es: 'üìä Compara "Data scanned" antes y despu√©s de optimizar', en: 'üìä Compare "Data scanned" before and after optimizing', pt: 'üìä Compare "Data scanned" antes e depois de otimizar' }],
    externalLinks: [{ title: 'Athena Performance Tuning', url: 'https://docs.aws.amazon.com/athena/latest/ug/performance-tuning.html', type: 'aws_docs' }],
    checkpoint: { es: '‚úÖ ¬øRedujiste el data scanned de una query usando particiones?', en: '‚úÖ Did you reduce data scanned using partitions?', pt: '‚úÖ Voc√™ reduziu o data scanned de uma query usando parti√ß√µes?' },
    xpReward: 65, estimatedMinutes: 35, services: ['Athena']
  },
  {
    id: 'aws-5-4', stepNumber: 41,
    title: { es: 'Workgroups y control de costos', en: 'Workgroups and cost control', pt: 'Workgroups e controle de custos' },
    description: { es: 'Configurar workgroups para separar usuarios y limitar costos.', en: 'Configure workgroups to separate users and limit costs.', pt: 'Configurar workgroups para separar usu√°rios e limitar custos.' },
    theory: { es: `## Athena Workgroups\n\n### ¬øQu√© son?\nAgrupaciones que permiten:\n- Separar usuarios/equipos\n- Configurar l√≠mites de datos\n- Establecer output location por grupo\n- Habilitar query result encryption\n\n### Configuraci√≥n de l√≠mites\n\`\`\`yaml\nWorkgroup: analysts\n  Query result location: s3://athena-results/analysts/\n  Data usage controls:\n    - Per-query limit: 100 GB\n    - Per-workgroup limit: 10 TB/month\n  Enforce workgroup configuration: Yes\n\`\`\`\n\n### M√©tricas por workgroup\n- Total data scanned\n- Number of queries\n- Query execution time average\n- Failed queries`, en: `## Athena Workgroups\n\n### What are they?\nGroupings that allow:\n- Separate users/teams\n- Configure data limits\n- Set output location per group\n- Enable query result encryption\n\n### Limit configuration\n\`\`\`yaml\nWorkgroup: analysts\n  Query result location: s3://athena-results/analysts/\n  Data usage controls:\n    - Per-query limit: 100 GB\n    - Per-workgroup limit: 10 TB/month\n  Enforce workgroup configuration: Yes\n\`\`\`\n\n### Metrics per workgroup\n- Total data scanned\n- Number of queries\n- Query execution time average\n- Failed queries`, pt: `## Athena Workgroups\n\n### O que s√£o?\nAgrupamentos que permitem:\n- Separar usu√°rios/equipes\n- Configurar limites de dados\n- Estabelecer output location por grupo\n- Habilitar query result encryption\n\n### Configura√ß√£o de limites\n\`\`\`yaml\nWorkgroup: analysts\n  Query result location: s3://athena-results/analysts/\n  Data usage controls:\n    - Per-query limit: 100 GB\n    - Per-workgroup limit: 10 TB/month\n  Enforce workgroup configuration: Yes\n\`\`\`\n\n### M√©tricas por workgroup\n- Total data scanned\n- Number of queries\n- Query execution time average\n- Failed queries` },
    practicalTips: [{ es: 'üõ°Ô∏è Crea un workgroup por equipo con l√≠mites apropiados', en: 'üõ°Ô∏è Create a workgroup per team with appropriate limits', pt: 'üõ°Ô∏è Crie um workgroup por equipe com limites apropriados' }],
    externalLinks: [{ title: 'Athena Workgroups', url: 'https://docs.aws.amazon.com/athena/latest/ug/workgroups.html', type: 'aws_docs' }],
    checkpoint: { es: '‚úÖ ¬øCreaste un workgroup con l√≠mite de data scanned?', en: '‚úÖ Did you create a workgroup with data scanned limit?', pt: '‚úÖ Voc√™ criou um workgroup com limite de data scanned?' },
    xpReward: 50, estimatedMinutes: 25, services: ['Athena']
  },
  {
    id: 'aws-5-5', stepNumber: 42,
    title: { es: 'Views y Named Queries', en: 'Views and Named Queries', pt: 'Views e Named Queries' },
    description: { es: 'Crear vistas reutilizables y queries guardadas.', en: 'Create reusable views and saved queries.', pt: 'Criar views reutiliz√°veis e queries salvas.' },
    theory: { es: `## Views en Athena\n\n### Crear una vista\n\`\`\`sql\nCREATE OR REPLACE VIEW daily_revenue AS\nSELECT \n  DATE(timestamp) as date,\n  SUM(value) as revenue,\n  COUNT(*) as transactions\nFROM events\nWHERE event_type = 'purchase'\nGROUP BY DATE(timestamp);\n\n-- Usar la vista\nSELECT * FROM daily_revenue WHERE date >= DATE '2024-01-01';\n\`\`\`\n\n### Named Queries\nQueries guardadas en la consola para reutilizar:\n- No ejecutan autom√°ticamente\n- √ötiles para queries frecuentes\n- Se pueden compartir v√≠a URL\n\n### Prepared Statements\n\`\`\`sql\nPREPARE my_query FROM\nSELECT * FROM events WHERE user_id = ?;\n\nEXECUTE my_query USING 'user_123';\n\`\`\``, en: `## Views in Athena\n\n### Create a view\n\`\`\`sql\nCREATE OR REPLACE VIEW daily_revenue AS\nSELECT \n  DATE(timestamp) as date,\n  SUM(value) as revenue,\n  COUNT(*) as transactions\nFROM events\nWHERE event_type = 'purchase'\nGROUP BY DATE(timestamp);\n\n-- Use the view\nSELECT * FROM daily_revenue WHERE date >= DATE '2024-01-01';\n\`\`\`\n\n### Named Queries\nSaved queries in the console for reuse:\n- Don't run automatically\n- Useful for frequent queries\n- Can be shared via URL\n\n### Prepared Statements\n\`\`\`sql\nPREPARE my_query FROM\nSELECT * FROM events WHERE user_id = ?;\n\nEXECUTE my_query USING 'user_123';\n\`\`\``, pt: `## Views no Athena\n\n### Criar uma view\n\`\`\`sql\nCREATE OR REPLACE VIEW daily_revenue AS\nSELECT \n  DATE(timestamp) as date,\n  SUM(value) as revenue,\n  COUNT(*) as transactions\nFROM events\nWHERE event_type = 'purchase'\nGROUP BY DATE(timestamp);\n\n-- Usar a view\nSELECT * FROM daily_revenue WHERE date >= DATE '2024-01-01';\n\`\`\`\n\n### Named Queries\nQueries salvas no console para reutilizar:\n- N√£o executam automaticamente\n- √öteis para queries frequentes\n- Podem ser compartilhadas via URL\n\n### Prepared Statements\n\`\`\`sql\nPREPARE my_query FROM\nSELECT * FROM events WHERE user_id = ?;\n\nEXECUTE my_query USING 'user_123';\n\`\`\`` },
    practicalTips: [{ es: 'üìã Crea views para abstraer complejidad - los analistas no necesitan saber la estructura de S3', en: 'üìã Create views to abstract complexity - analysts don\'t need to know S3 structure', pt: 'üìã Crie views para abstrair complexidade - os analistas n√£o precisam saber a estrutura do S3' }],
    externalLinks: [{ title: 'Athena Views', url: 'https://docs.aws.amazon.com/athena/latest/ug/views.html', type: 'aws_docs' }],
    checkpoint: { es: '‚úÖ ¬øCreaste una vista que simplifica una query compleja?', en: '‚úÖ Did you create a view that simplifies a complex query?', pt: '‚úÖ Voc√™ criou uma view que simplifica uma query complexa?' },
    xpReward: 45, estimatedMinutes: 25, services: ['Athena']
  },
  {
    id: 'aws-5-6', stepNumber: 43,
    title: { es: 'CTAS: Create Table As Select', en: 'CTAS: Create Table As Select', pt: 'CTAS: Create Table As Select' },
    description: { es: 'Materializar queries como nuevas tablas en formato optimizado.', en: 'Materialize queries as new tables in optimized format.', pt: 'Materializar queries como novas tabelas em formato otimizado.' },
    theory: { es: `## CTAS - Materializaci√≥n de Queries\n\n### ¬øQu√© es CTAS?\nCrear nuevas tablas a partir de queries, convirtiendo formatos y a√±adiendo particiones.\n\n### Ejemplo: CSV a Parquet particionado\n\`\`\`sql\nCREATE TABLE processed_events\nWITH (\n  format = 'PARQUET',\n  parquet_compression = 'SNAPPY',\n  partitioned_by = ARRAY['year', 'month'],\n  external_location = 's3://bucket/processed/events_v2/'\n) AS\nSELECT \n  event_id, user_id, event_type, value, timestamp,\n  CAST(year(timestamp) AS VARCHAR) as year,\n  CAST(month(timestamp) AS VARCHAR) as month\nFROM raw_events;\n\`\`\`\n\n### Casos de uso\n1. Convertir CSV/JSON a Parquet\n2. A√±adir particionamiento\n3. Agregar/filtrar datos\n4. Crear snapshots de tablas\n\n### ‚ö†Ô∏è Limitaciones\n- No puede actualizar tablas existentes\n- M√°ximo 100 particiones por query`, en: `## CTAS - Query Materialization\n\n### What is CTAS?\nCreate new tables from queries, converting formats and adding partitions.\n\n### Example: CSV to partitioned Parquet\n\`\`\`sql\nCREATE TABLE processed_events\nWITH (\n  format = 'PARQUET',\n  parquet_compression = 'SNAPPY',\n  partitioned_by = ARRAY['year', 'month'],\n  external_location = 's3://bucket/processed/events_v2/'\n) AS\nSELECT \n  event_id, user_id, event_type, value, timestamp,\n  CAST(year(timestamp) AS VARCHAR) as year,\n  CAST(month(timestamp) AS VARCHAR) as month\nFROM raw_events;\n\`\`\`\n\n### Use cases\n1. Convert CSV/JSON to Parquet\n2. Add partitioning\n3. Aggregate/filter data\n4. Create table snapshots\n\n### ‚ö†Ô∏è Limitations\n- Cannot update existing tables\n- Maximum 100 partitions per query`, pt: `## CTAS - Materializa√ß√£o de Queries\n\n### O que √© CTAS?\nCriar novas tabelas a partir de queries, convertendo formatos e adicionando parti√ß√µes.\n\n### Exemplo: CSV para Parquet particionado\n\`\`\`sql\nCREATE TABLE processed_events\nWITH (\n  format = 'PARQUET',\n  parquet_compression = 'SNAPPY',\n  partitioned_by = ARRAY['year', 'month'],\n  external_location = 's3://bucket/processed/events_v2/'\n) AS\nSELECT \n  event_id, user_id, event_type, value, timestamp,\n  CAST(year(timestamp) AS VARCHAR) as year,\n  CAST(month(timestamp) AS VARCHAR) as month\nFROM raw_events;\n\`\`\`\n\n### Casos de uso\n1. Converter CSV/JSON para Parquet\n2. Adicionar particionamento\n3. Agregar/filtrar dados\n4. Criar snapshots de tabelas\n\n### ‚ö†Ô∏è Limita√ß√µes\n- N√£o pode atualizar tabelas existentes\n- M√°ximo 100 parti√ß√µes por query` },
    practicalTips: [{ es: 'üîÑ CTAS es perfecto para ETL simple sin necesidad de Glue', en: 'üîÑ CTAS is perfect for simple ETL without needing Glue', pt: 'üîÑ CTAS √© perfeito para ETL simples sem precisar do Glue' }],
    externalLinks: [{ title: 'CTAS in Athena', url: 'https://docs.aws.amazon.com/athena/latest/ug/ctas.html', type: 'aws_docs' }],
    checkpoint: { es: '‚úÖ ¬øUsaste CTAS para convertir CSV a Parquet particionado?', en: '‚úÖ Did you use CTAS to convert CSV to partitioned Parquet?', pt: '‚úÖ Voc√™ usou CTAS para converter CSV para Parquet particionado?' },
    xpReward: 60, estimatedMinutes: 35, services: ['Athena', 'S3']
  },
  {
    id: 'aws-5-7', stepNumber: 44,
    title: { es: 'Athena Federated Query', en: 'Athena Federated Query', pt: 'Athena Federated Query' },
    description: { es: 'Consultar m√∫ltiples fuentes de datos desde Athena.', en: 'Query multiple data sources from Athena.', pt: 'Consultar m√∫ltiplas fontes de dados do Athena.' },
    theory: { es: `## Athena Federated Query\n\n### ¬øQu√© es?\nExtensi√≥n que permite consultar datos fuera de S3:\n- DynamoDB\n- RDS/Aurora\n- Redshift\n- CloudWatch Logs\n- APIs custom\n\n### Data Source Connectors\nLambda functions que traducen queries:\n\`\`\`yaml\nConnector: athena-dynamodb-connector\n  Lambda: arn:aws:lambda:...:function:AthenaConnector\n  Catalog: dynamodb_catalog\n\`\`\`\n\n### Query multi-source\n\`\`\`sql\n-- S3 + DynamoDB en un query\nSELECT s.*, d.user_name\nFROM s3_catalog.db.events s\nJOIN dynamodb_catalog.users d ON s.user_id = d.user_id\nWHERE s.year = '2024';\n\`\`\`\n\n### Connectors disponibles\n- AWS: DynamoDB, CloudWatch, DocDB, Neptune\n- Databases: MySQL, PostgreSQL, SQL Server, Oracle\n- SaaS: Snowflake, Google BigQuery`, en: `## Athena Federated Query\n\n### What is it?\nExtension that allows querying data outside S3:\n- DynamoDB\n- RDS/Aurora\n- Redshift\n- CloudWatch Logs\n- Custom APIs\n\n### Data Source Connectors\nLambda functions that translate queries:\n\`\`\`yaml\nConnector: athena-dynamodb-connector\n  Lambda: arn:aws:lambda:...:function:AthenaConnector\n  Catalog: dynamodb_catalog\n\`\`\`\n\n### Multi-source query\n\`\`\`sql\n-- S3 + DynamoDB in one query\nSELECT s.*, d.user_name\nFROM s3_catalog.db.events s\nJOIN dynamodb_catalog.users d ON s.user_id = d.user_id\nWHERE s.year = '2024';\n\`\`\`\n\n### Available connectors\n- AWS: DynamoDB, CloudWatch, DocDB, Neptune\n- Databases: MySQL, PostgreSQL, SQL Server, Oracle\n- SaaS: Snowflake, Google BigQuery`, pt: `## Athena Federated Query\n\n### O que √©?\nExtens√£o que permite consultar dados fora do S3:\n- DynamoDB\n- RDS/Aurora\n- Redshift\n- CloudWatch Logs\n- APIs custom\n\n### Data Source Connectors\nLambda functions que traduzem queries:\n\`\`\`yaml\nConnector: athena-dynamodb-connector\n  Lambda: arn:aws:lambda:...:function:AthenaConnector\n  Catalog: dynamodb_catalog\n\`\`\`\n\n### Query multi-source\n\`\`\`sql\n-- S3 + DynamoDB em uma query\nSELECT s.*, d.user_name\nFROM s3_catalog.db.events s\nJOIN dynamodb_catalog.users d ON s.user_id = d.user_id\nWHERE s.year = '2024';\n\`\`\`\n\n### Connectors dispon√≠veis\n- AWS: DynamoDB, CloudWatch, DocDB, Neptune\n- Databases: MySQL, PostgreSQL, SQL Server, Oracle\n- SaaS: Snowflake, Google BigQuery` },
    practicalTips: [{ es: 'üîó Federated Queries son m√°s lentas que S3 nativo - √∫salas para datos peque√±os o lookup tables', en: 'üîó Federated Queries are slower than native S3 - use them for small data or lookup tables', pt: 'üîó Federated Queries s√£o mais lentas que S3 nativo - use-as para dados pequenos ou lookup tables' }],
    externalLinks: [{ title: 'Athena Federated Query', url: 'https://docs.aws.amazon.com/athena/latest/ug/connect-to-a-data-source.html', type: 'aws_docs' }],
    checkpoint: { es: '‚úÖ ¬øConfiguraste un connector y consultaste una fuente externa?', en: '‚úÖ Did you configure a connector and query an external source?', pt: '‚úÖ Voc√™ configurou um connector e consultou uma fonte externa?' },
    xpReward: 55, estimatedMinutes: 40, services: ['Athena', 'Lambda']
  },
  {
    id: 'aws-5-8', stepNumber: 45,
    title: { es: 'Athena desde c√≥digo (boto3/SDK)', en: 'Athena from code (boto3/SDK)', pt: 'Athena via c√≥digo (boto3/SDK)' },
    description: { es: 'Ejecutar queries de Athena program√°ticamente.', en: 'Run Athena queries programmatically.', pt: 'Executar queries do Athena programaticamente.' },
    theory: { es: `## Athena con boto3\n\n### Ejecutar query y esperar resultado\n\`\`\`python\nimport boto3\nimport time\n\nathena = boto3.client('athena')\n\ndef run_athena_query(query, database, output_location):\n    response = athena.start_query_execution(\n        QueryString=query,\n        QueryExecutionContext={'Database': database},\n        ResultConfiguration={'OutputLocation': output_location}\n    )\n    query_id = response['QueryExecutionId']\n    \n    # Esperar a que termine\n    while True:\n        status = athena.get_query_execution(QueryExecutionId=query_id)\n        state = status['QueryExecution']['Status']['State']\n        if state in ['SUCCEEDED', 'FAILED', 'CANCELLED']:\n            break\n        time.sleep(1)\n    \n    if state == 'SUCCEEDED':\n        results = athena.get_query_results(QueryExecutionId=query_id)\n        return results['ResultSet']['Rows']\n    else:\n        raise Exception(f"Query failed: {state}")\n\n# Uso\nrows = run_athena_query(\n    "SELECT * FROM events LIMIT 10",\n    "my_database",\n    "s3://bucket/athena-results/"\n)\n\`\`\``, en: `## Athena with boto3\n\n### Run query and wait for result\n\`\`\`python\nimport boto3\nimport time\n\nathena = boto3.client('athena')\n\ndef run_athena_query(query, database, output_location):\n    response = athena.start_query_execution(\n        QueryString=query,\n        QueryExecutionContext={'Database': database},\n        ResultConfiguration={'OutputLocation': output_location}\n    )\n    query_id = response['QueryExecutionId']\n    \n    # Wait for completion\n    while True:\n        status = athena.get_query_execution(QueryExecutionId=query_id)\n        state = status['QueryExecution']['Status']['State']\n        if state in ['SUCCEEDED', 'FAILED', 'CANCELLED']:\n            break\n        time.sleep(1)\n    \n    if state == 'SUCCEEDED':\n        results = athena.get_query_results(QueryExecutionId=query_id)\n        return results['ResultSet']['Rows']\n    else:\n        raise Exception(f"Query failed: {state}")\n\n# Usage\nrows = run_athena_query(\n    "SELECT * FROM events LIMIT 10",\n    "my_database",\n    "s3://bucket/athena-results/"\n)\n\`\`\``, pt: `## Athena com boto3\n\n### Executar query e esperar resultado\n\`\`\`python\nimport boto3\nimport time\n\nathena = boto3.client('athena')\n\ndef run_athena_query(query, database, output_location):\n    response = athena.start_query_execution(\n        QueryString=query,\n        QueryExecutionContext={'Database': database},\n        ResultConfiguration={'OutputLocation': output_location}\n    )\n    query_id = response['QueryExecutionId']\n    \n    # Esperar conclus√£o\n    while True:\n        status = athena.get_query_execution(QueryExecutionId=query_id)\n        state = status['QueryExecution']['Status']['State']\n        if state in ['SUCCEEDED', 'FAILED', 'CANCELLED']:\n            break\n        time.sleep(1)\n    \n    if state == 'SUCCEEDED':\n        results = athena.get_query_results(QueryExecutionId=query_id)\n        return results['ResultSet']['Rows']\n    else:\n        raise Exception(f"Query failed: {state}")\n\n# Uso\nrows = run_athena_query(\n    "SELECT * FROM events LIMIT 10",\n    "my_database",\n    "s3://bucket/athena-results/"\n)\n\`\`\`` },
    practicalTips: [{ es: '‚ö° Usa PyAthena (awswrangler) para una API m√°s simple y compatibilidad con Pandas', en: '‚ö° Use PyAthena (awswrangler) for simpler API and Pandas compatibility', pt: '‚ö° Use PyAthena (awswrangler) para uma API mais simples e compatibilidade com Pandas' }],
    externalLinks: [{ title: 'Athena API Reference', url: 'https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/athena.html', type: 'aws_docs' }],
    checkpoint: { es: '‚úÖ ¬øEjecutaste una query de Athena desde Python?', en: '‚úÖ Did you run an Athena query from Python?', pt: '‚úÖ Voc√™ executou uma query do Athena via Python?' },
    xpReward: 60, estimatedMinutes: 35, services: ['Athena']
  }
];








