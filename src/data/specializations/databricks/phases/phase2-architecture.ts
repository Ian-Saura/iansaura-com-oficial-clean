/**
 * FASE 2: Arquitectura de Databricks
 * 9 pasos para entender cÃ³mo funciona Databricks por dentro
 * 
 * ACTUALIZADO: Enero 2026 - Incluye arquitectura serverless y Free Edition
 */

import { DatabricksPhase } from '../types';

export const PHASE_2_ARCHITECTURE: DatabricksPhase = {
  id: 'db-phase-2',
  number: 2,
  title: {
    es: 'Arquitectura de Databricks',
    en: 'Databricks Architecture',
    pt: 'Arquitetura do Databricks'
  },
  subtitle: {
    es: 'EntendÃ© cÃ³mo funciona por dentro',
    en: 'Understand how it works internally',
    pt: 'Entenda como funciona por dentro'
  },
  description: {
    es: 'Conocer la arquitectura de Databricks te permite tomar mejores decisiones de diseÃ±o, optimizar costos y resolver problemas de performance. Esta fase cubre tanto la arquitectura enterprise (planes pagos) como serverless (Free Edition).',
    en: 'Knowing Databricks architecture allows you to make better design decisions, optimize costs and solve performance problems. This phase covers both enterprise architecture (paid plans) and serverless (Free Edition).',
    pt: 'Conhecer a arquitetura do Databricks permite tomar melhores decisÃµes de design, otimizar custos e resolver problemas de performance. Esta fase cobre tanto a arquitetura enterprise (planos pagos) quanto serverless (Free Edition).'
  },
  icon: 'ğŸ—ï¸',
  color: 'blue',
  estimatedDays: '3-4 dÃ­as',
  steps: [
    {
      id: 'db-2-1',
      title: {
        es: 'Control Plane vs Data Plane',
        en: 'Control Plane vs Data Plane',
        pt: 'Control Plane vs Data Plane'
      },
      description: {
        es: 'Databricks separa la gestiÃ³n (control) del procesamiento (data). EntendÃ© por quÃ© esto importa.',
        en: 'Databricks separates management (control) from processing (data). Understand why this matters.',
        pt: 'O Databricks separa a gestÃ£o (control) do processamento (data). Entenda por que isso importa.'
      },
      theory: {
        es: `## Control Plane vs Data Plane

Databricks tiene una arquitectura Ãºnica de dos planos:

### Control Plane (gestionado por Databricks)
\`\`\`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         CONTROL PLANE               â”‚
â”‚    (Databricks Cloud Account)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Web Application (UI)              â”‚
â”‚ â€¢ Notebook Service                  â”‚
â”‚ â€¢ Job Scheduler                     â”‚
â”‚ â€¢ Cluster Manager                   â”‚
â”‚ â€¢ Identity & Access Management      â”‚
â”‚ â€¢ Billing & Usage Tracking          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

### Data Plane (en TU cuenta de cloud)
\`\`\`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          DATA PLANE                 â”‚
â”‚    (Tu cuenta AWS/Azure/GCP)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Clusters (EC2, VMs)               â”‚
â”‚ â€¢ Storage (S3, ADLS, GCS)           â”‚
â”‚ â€¢ Networking (VPC, VNet)            â”‚
â”‚ â€¢ TUS DATOS (nunca salen)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

### Â¿Por quÃ© esta separaciÃ³n?

1. **Seguridad**: Tus datos NUNCA pasan por servidores de Databricks
2. **Compliance**: CumplÃ­s regulaciones (GDPR, HIPAA) mÃ¡s fÃ¡cilmente
3. **Control**: UsÃ¡s tu propia infraestructura de cloud
4. **Costos**: PagÃ¡s compute directamente a AWS/Azure/GCP

### Flujo de una operaciÃ³n tÃ­pica:

\`\`\`
Usuario â†’ Control Plane â†’ Inicia Cluster
                        â†“
              Data Plane (tu cloud)
                        â†“
              Cluster lee datos de TU S3/ADLS
                        â†“
              Procesa datos
                        â†“
              Escribe resultados en TU storage
\`\`\``,
        en: `## Control Plane vs Data Plane

Databricks has a unique two-plane architecture:

### Control Plane (managed by Databricks)
\`\`\`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         CONTROL PLANE               â”‚
â”‚    (Databricks Cloud Account)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Web Application (UI)              â”‚
â”‚ â€¢ Notebook Service                  â”‚
â”‚ â€¢ Job Scheduler                     â”‚
â”‚ â€¢ Cluster Manager                   â”‚
â”‚ â€¢ Identity & Access Management      â”‚
â”‚ â€¢ Billing & Usage Tracking          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

### Data Plane (in YOUR cloud account)
\`\`\`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          DATA PLANE                 â”‚
â”‚    (Your AWS/Azure/GCP account)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Clusters (EC2, VMs)               â”‚
â”‚ â€¢ Storage (S3, ADLS, GCS)           â”‚
â”‚ â€¢ Networking (VPC, VNet)            â”‚
â”‚ â€¢ YOUR DATA (never leaves)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

### Why this separation?

1. **Security**: Your data NEVER passes through Databricks servers
2. **Compliance**: Easier to meet regulations (GDPR, HIPAA)
3. **Control**: Use your own cloud infrastructure
4. **Costs**: Pay compute directly to AWS/Azure/GCP

### Flow of a typical operation:

\`\`\`
User â†’ Control Plane â†’ Starts Cluster
                     â†“
           Data Plane (your cloud)
                     â†“
           Cluster reads data from YOUR S3/ADLS
                     â†“
           Processes data
                     â†“
           Writes results to YOUR storage
\`\`\``,
        pt: `## Control Plane vs Data Plane

O Databricks tem uma arquitetura Ãºnica de dois planos:

### Control Plane (gerenciado pelo Databricks)
\`\`\`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         CONTROL PLANE               â”‚
â”‚    (Databricks Cloud Account)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Web Application (UI)              â”‚
â”‚ â€¢ Notebook Service                  â”‚
â”‚ â€¢ Job Scheduler                     â”‚
â”‚ â€¢ Cluster Manager                   â”‚
â”‚ â€¢ Identity & Access Management      â”‚
â”‚ â€¢ Billing & Usage Tracking          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

### Data Plane (na SUA conta de cloud)
\`\`\`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          DATA PLANE                 â”‚
â”‚    (Sua conta AWS/Azure/GCP)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Clusters (EC2, VMs)               â”‚
â”‚ â€¢ Storage (S3, ADLS, GCS)           â”‚
â”‚ â€¢ Networking (VPC, VNet)            â”‚
â”‚ â€¢ SEUS DADOS (nunca saem)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

### Por que essa separaÃ§Ã£o?

1. **SeguranÃ§a**: Seus dados NUNCA passam por servidores do Databricks
2. **Compliance**: Mais fÃ¡cil cumprir regulaÃ§Ãµes (GDPR, HIPAA)
3. **Controle**: Use sua prÃ³pria infraestrutura de cloud
4. **Custos**: Pague compute diretamente para AWS/Azure/GCP

### Fluxo de uma operaÃ§Ã£o tÃ­pica:

\`\`\`
UsuÃ¡rio â†’ Control Plane â†’ Inicia Cluster
                        â†“
              Data Plane (seu cloud)
                        â†“
              Cluster lÃª dados do SEU S3/ADLS
                        â†“
              Processa dados
                        â†“
              Escreve resultados no SEU storage
\`\`\``
      },
      practicalTips: [
        {
          es: 'ğŸ”’ Esta arquitectura es clave para aprobar auditorÃ­as de seguridad. Memorizala.',
          en: 'ğŸ”’ This architecture is key to passing security audits. Memorize it.',
          pt: 'ğŸ”’ Esta arquitetura Ã© chave para passar auditorias de seguranÃ§a. Memorize-a.'
        },
        {
          es: 'ğŸ’° En entrevistas, mencionar esta separaciÃ³n muestra que entendÃ©s Databricks a fondo.',
          en: 'ğŸ’° In interviews, mentioning this separation shows you understand Databricks deeply.',
          pt: 'ğŸ’° Em entrevistas, mencionar esta separaÃ§Ã£o mostra que vocÃª entende Databricks profundamente.'
        },
        {
          es: 'ğŸ“Œ En Free Edition, Databricks gestiona todo (control + data plane). Esta arquitectura aplica a planes enterprise.',
          en: 'ğŸ“Œ In Free Edition, Databricks manages everything (control + data plane). This architecture applies to enterprise plans.',
          pt: 'ğŸ“Œ No Free Edition, o Databricks gerencia tudo (control + data plane). Esta arquitetura aplica-se a planos enterprise.'
        }
      ],
      externalLinks: [
        {
          title: 'Databricks Architecture Overview',
          url: 'https://docs.databricks.com/getting-started/overview.html',
          type: 'docs'
        },
        {
          title: 'Security & Trust Center',
          url: 'https://www.databricks.com/trust',
          type: 'article'
        }
      ],
      checkpoint: {
        es: 'ğŸ¤” Si un cliente te pregunta "Â¿mis datos pasan por servidores de Databricks?", Â¿quÃ© respondÃ©s?',
        en: 'ğŸ¤” If a client asks "does my data pass through Databricks servers?", what do you answer?',
        pt: 'ğŸ¤” Se um cliente perguntar "meus dados passam por servidores do Databricks?", o que vocÃª responde?'
      },
      xpReward: 20,
      estimatedMinutes: 20
    },
    {
      id: 'db-2-2',
      title: {
        es: 'Databricks en AWS, Azure y GCP',
        en: 'Databricks on AWS, Azure and GCP',
        pt: 'Databricks na AWS, Azure e GCP'
      },
      description: {
        es: 'Databricks corre en los 3 clouds principales. ConocÃ© las diferencias.',
        en: 'Databricks runs on all 3 major clouds. Learn the differences.',
        pt: 'O Databricks roda nos 3 principais clouds. ConheÃ§a as diferenÃ§as.'
      },
      theory: {
        es: `## Databricks en Cada Cloud

### AWS (el mÃ¡s maduro)
\`\`\`
Storage: S3
Compute: EC2
Network: VPC
Identity: IAM
IntegraciÃ³n nativa: Glue, Redshift, Kinesis
\`\`\`
**Pros:** MÃ¡s features, mÃ¡s documentaciÃ³n
**Contras:** Setup mÃ¡s manual

### Azure (partnership con Microsoft)
\`\`\`
Storage: ADLS Gen2, Blob Storage
Compute: Azure VMs
Network: VNet
Identity: Azure AD (SSO nativo!)
IntegraciÃ³n nativa: Synapse, Data Factory, Power BI
\`\`\`
**Pros:** SSO con Azure AD, integraciÃ³n Office 365
**Contras:** Algunas features llegan despuÃ©s que AWS

### GCP (el mÃ¡s nuevo)
\`\`\`
Storage: GCS
Compute: GCE
Network: VPC
Identity: Google IAM
IntegraciÃ³n nativa: BigQuery, Dataflow
\`\`\`
**Pros:** Mejor pricing de compute
**Contras:** Menos features que AWS/Azure

### Comparativa de Servicios:

| Feature | AWS | Azure | GCP |
|---------|-----|-------|-----|
| Storage | S3 | ADLS | GCS |
| Unity Catalog | âœ… | âœ… | âœ… |
| Photon Engine | âœ… | âœ… | âœ… |
| Serverless SQL | âœ… | âœ… | âœ… |
| SSO Nativo | IAM | Azure AD | Google |
| Madurez | â­â­â­ | â­â­â­ | â­â­ |`,
        en: `## Databricks on Each Cloud

### AWS (most mature)
\`\`\`
Storage: S3
Compute: EC2
Network: VPC
Identity: IAM
Native integration: Glue, Redshift, Kinesis
\`\`\`
**Pros:** More features, more documentation
**Cons:** More manual setup

### Azure (Microsoft partnership)
\`\`\`
Storage: ADLS Gen2, Blob Storage
Compute: Azure VMs
Network: VNet
Identity: Azure AD (native SSO!)
Native integration: Synapse, Data Factory, Power BI
\`\`\`
**Pros:** SSO with Azure AD, Office 365 integration
**Cons:** Some features arrive later than AWS

### GCP (newest)
\`\`\`
Storage: GCS
Compute: GCE
Network: VPC
Identity: Google IAM
Native integration: BigQuery, Dataflow
\`\`\`
**Pros:** Better compute pricing
**Cons:** Fewer features than AWS/Azure

### Service Comparison:

| Feature | AWS | Azure | GCP |
|---------|-----|-------|-----|
| Storage | S3 | ADLS | GCS |
| Unity Catalog | âœ… | âœ… | âœ… |
| Photon Engine | âœ… | âœ… | âœ… |
| Serverless SQL | âœ… | âœ… | âœ… |
| Native SSO | IAM | Azure AD | Google |
| Maturity | â­â­â­ | â­â­â­ | â­â­ |`,
        pt: `## Databricks em Cada Cloud

### AWS (mais maduro)
\`\`\`
Storage: S3
Compute: EC2
Network: VPC
Identity: IAM
IntegraÃ§Ã£o nativa: Glue, Redshift, Kinesis
\`\`\`
**PrÃ³s:** Mais features, mais documentaÃ§Ã£o
**Contras:** Setup mais manual

### Azure (parceria com Microsoft)
\`\`\`
Storage: ADLS Gen2, Blob Storage
Compute: Azure VMs
Network: VNet
Identity: Azure AD (SSO nativo!)
IntegraÃ§Ã£o nativa: Synapse, Data Factory, Power BI
\`\`\`
**PrÃ³s:** SSO com Azure AD, integraÃ§Ã£o Office 365
**Contras:** Algumas features chegam depois da AWS

### GCP (mais novo)
\`\`\`
Storage: GCS
Compute: GCE
Network: VPC
Identity: Google IAM
IntegraÃ§Ã£o nativa: BigQuery, Dataflow
\`\`\`
**PrÃ³s:** Melhor pricing de compute
**Contras:** Menos features que AWS/Azure

### ComparaÃ§Ã£o de ServiÃ§os:

| Feature | AWS | Azure | GCP |
|---------|-----|-------|-----|
| Storage | S3 | ADLS | GCS |
| Unity Catalog | âœ… | âœ… | âœ… |
| Photon Engine | âœ… | âœ… | âœ… |
| Serverless SQL | âœ… | âœ… | âœ… |
| SSO Nativo | IAM | Azure AD | Google |
| Maturidade | â­â­â­ | â­â­â­ | â­â­ |`
      },
      practicalTips: [
        {
          es: 'ğŸ¯ Si buscÃ¡s trabajo, enfocate en AWS o Azure. Son los mÃ¡s demandados.',
          en: 'ğŸ¯ If you\'re job hunting, focus on AWS or Azure. They\'re most in-demand.',
          pt: 'ğŸ¯ Se vocÃª estÃ¡ procurando emprego, foque em AWS ou Azure. SÃ£o os mais demandados.'
        }
      ],
      externalLinks: [
        {
          title: 'Databricks on AWS',
          url: 'https://docs.databricks.com/administration-guide/cloud-configurations/aws/index.html',
          type: 'docs'
        },
        {
          title: 'Azure Databricks',
          url: 'https://docs.microsoft.com/en-us/azure/databricks/',
          type: 'docs'
        }
      ],
      checkpoint: {
        es: 'ğŸ¤” Â¿En quÃ© cloud trabaja la empresa donde querÃ©s aplicar? Investigalo.',
        en: 'ğŸ¤” What cloud does the company you want to apply to use? Research it.',
        pt: 'ğŸ¤” Em qual cloud trabalha a empresa onde vocÃª quer aplicar? Pesquise.'
      },
      xpReward: 15,
      estimatedMinutes: 15
    },
    {
      id: 'db-2-3',
      title: {
        es: 'Tipos de Compute: Serverless, All-Purpose y Job Clusters',
        en: 'Compute Types: Serverless, All-Purpose and Job Clusters',
        pt: 'Tipos de Compute: Serverless, All-Purpose e Job Clusters'
      },
      description: {
        es: 'Databricks ofrece diferentes opciones de compute. Elegir correctamente impacta en costos y performance.',
        en: 'Databricks offers different compute options. Choosing correctly impacts costs and performance.',
        pt: 'O Databricks oferece diferentes opÃ§Ãµes de compute. Escolher corretamente impacta em custos e performance.'
      },
      theory: {
        es: `## Tipos de Compute en Databricks

### ğŸ†• Serverless Compute (Free Edition y planes pagos)
\`\`\`
âœ… Para: Desarrollo rÃ¡pido, SQL analytics, notebooks
âœ… Disponible en: Free Edition (Ãºnico tipo disponible)
ğŸ’° Costo: Por uso (sin costo en Free Edition)
â±ï¸ Inicio: Segundos (sin esperas)
\`\`\`

**CaracterÃ­sticas:**
- Se activa automÃ¡ticamente al ejecutar cÃ³digo
- Sin configuraciÃ³n manual
- Recursos administrados por Databricks
- Incluye Photon para queries SQL
- Lenguajes: Python y SQL (en Free Edition)

### All-Purpose Clusters (Solo planes pagos)
\`\`\`
âœ… Para: Desarrollo, exploraciÃ³n, notebooks colaborativos
âŒ No para: Jobs de producciÃ³n
ğŸ’° Costo: MÃ¡s caro (DBU premium)
â±ï¸ DuraciÃ³n: Pueden estar encendidos mucho tiempo
\`\`\`

**CaracterÃ­sticas:**
- MÃºltiples usuarios pueden conectarse
- ConfiguraciÃ³n personalizada (RAM, cores, GPU)
- Lenguajes: Python, SQL, R, Scala
- Persisten despuÃ©s de ejecutar cÃ³digo

### Job Clusters (Solo planes pagos)
\`\`\`
âœ… Para: Jobs de producciÃ³n, pipelines schedulados
âŒ No para: Desarrollo interactivo
ğŸ’° Costo: MÃ¡s barato (~50% menos DBUs que All-Purpose)
â±ï¸ DuraciÃ³n: Se crean y destruyen automÃ¡ticamente
\`\`\`

**CaracterÃ­sticas:**
- Un cluster por job
- Se destruyen al terminar el job
- ConfiguraciÃ³n vÃ­a API/UI de Jobs
- Optimizados para batch processing

### Comparativa Completa:

| Tipo | Disponibilidad | DBU/hora | Inicio | Lenguajes |
|------|---------------|----------|--------|-----------|
| Serverless | Free + Pagos | Por uso | Segundos | Python, SQL |
| All-Purpose | Solo Pagos | ~1.0 | 3-5 min | Python, SQL, R, Scala |
| Job | Solo Pagos | ~0.5 | 3-5 min | Python, SQL, R, Scala |

### Best Practices:

1. **Free Edition**: UsÃ¡ serverless (es automÃ¡tico)
2. **Desarrollo (pagos)**: All-Purpose con auto-terminate (30 min)
3. **ProducciÃ³n (pagos)**: Job clusters o Serverless Jobs
4. **Costos**: Monitorear con Tags por proyecto/equipo`,
        en: `## Compute Types in Databricks

### ğŸ†• Serverless Compute (Free Edition and paid plans)
\`\`\`
âœ… For: Quick development, SQL analytics, notebooks
âœ… Available in: Free Edition (only type available)
ğŸ’° Cost: Per use (no cost in Free Edition)
â±ï¸ Startup: Seconds (no waiting)
\`\`\`

**Features:**
- Activates automatically when running code
- No manual configuration
- Resources managed by Databricks
- Includes Photon for SQL queries
- Languages: Python and SQL (in Free Edition)

### All-Purpose Clusters (Paid plans only)
\`\`\`
âœ… For: Development, exploration, collaborative notebooks
âŒ Not for: Production jobs
ğŸ’° Cost: More expensive (premium DBU)
â±ï¸ Duration: Can stay on for long periods
\`\`\`

**Features:**
- Multiple users can connect
- Custom configuration (RAM, cores, GPU)
- Languages: Python, SQL, R, Scala
- Persist after running code

### Job Clusters (Paid plans only)
\`\`\`
âœ… For: Production jobs, scheduled pipelines
âŒ Not for: Interactive development
ğŸ’° Cost: Cheaper (~50% less DBUs than All-Purpose)
â±ï¸ Duration: Created and destroyed automatically
\`\`\`

**Features:**
- One cluster per job
- Destroyed when job completes
- Configuration via Jobs API/UI
- Optimized for batch processing

### Complete Comparison:

| Type | Availability | DBU/hour | Startup | Languages |
|------|-------------|----------|---------|-----------|
| Serverless | Free + Paid | Per use | Seconds | Python, SQL |
| All-Purpose | Paid only | ~1.0 | 3-5 min | Python, SQL, R, Scala |
| Job | Paid only | ~0.5 | 3-5 min | Python, SQL, R, Scala |

### Best Practices:

1. **Free Edition**: Use serverless (it's automatic)
2. **Development (paid)**: All-Purpose with auto-terminate (30 min)
3. **Production (paid)**: Job clusters or Serverless Jobs
4. **Costs**: Monitor with Tags by project/team`,
        pt: `## Tipos de Compute no Databricks

### ğŸ†• Serverless Compute (Free Edition e planos pagos)
\`\`\`
âœ… Para: Desenvolvimento rÃ¡pido, SQL analytics, notebooks
âœ… DisponÃ­vel em: Free Edition (Ãºnico tipo disponÃ­vel)
ğŸ’° Custo: Por uso (sem custo no Free Edition)
â±ï¸ InÃ­cio: Segundos (sem esperas)
\`\`\`

**CaracterÃ­sticas:**
- Ativa automaticamente ao executar cÃ³digo
- Sem configuraÃ§Ã£o manual
- Recursos gerenciados pelo Databricks
- Inclui Photon para queries SQL
- Linguagens: Python e SQL (no Free Edition)

### All-Purpose Clusters (Apenas planos pagos)
\`\`\`
âœ… Para: Desenvolvimento, exploraÃ§Ã£o, notebooks colaborativos
âŒ NÃ£o para: Jobs de produÃ§Ã£o
ğŸ’° Custo: Mais caro (DBU premium)
â±ï¸ DuraÃ§Ã£o: Podem ficar ligados muito tempo
\`\`\`

**CaracterÃ­sticas:**
- MÃºltiplos usuÃ¡rios podem conectar
- ConfiguraÃ§Ã£o personalizada (RAM, cores, GPU)
- Linguagens: Python, SQL, R, Scala
- Persistem apÃ³s executar cÃ³digo

### Job Clusters (Apenas planos pagos)
\`\`\`
âœ… Para: Jobs de produÃ§Ã£o, pipelines schedulados
âŒ NÃ£o para: Desenvolvimento interativo
ğŸ’° Custo: Mais barato (~50% menos DBUs que All-Purpose)
â±ï¸ DuraÃ§Ã£o: Criados e destruÃ­dos automaticamente
\`\`\`

**CaracterÃ­sticas:**
- Um cluster por job
- DestruÃ­dos ao terminar o job
- ConfiguraÃ§Ã£o via API/UI de Jobs
- Otimizados para batch processing

### ComparaÃ§Ã£o Completa:

| Tipo | Disponibilidade | DBU/hora | InÃ­cio | Linguagens |
|------|-----------------|----------|--------|------------|
| Serverless | Free + Pagos | Por uso | Segundos | Python, SQL |
| All-Purpose | Apenas Pagos | ~1.0 | 3-5 min | Python, SQL, R, Scala |
| Job | Apenas Pagos | ~0.5 | 3-5 min | Python, SQL, R, Scala |

### Melhores PrÃ¡ticas:

1. **Free Edition**: Use serverless (Ã© automÃ¡tico)
2. **Desenvolvimento (pagos)**: All-Purpose com auto-terminate (30 min)
3. **ProduÃ§Ã£o (pagos)**: Job clusters ou Serverless Jobs
4. **Custos**: Monitorar com Tags por projeto/equipe`
      },
      practicalTips: [
        {
          es: 'ğŸ’° Un error comÃºn de principiantes: usar All-Purpose para jobs de producciÃ³n. Cuesta el doble!',
          en: 'ğŸ’° A common beginner mistake: using All-Purpose for production jobs. Costs double!',
          pt: 'ğŸ’° Um erro comum de iniciantes: usar All-Purpose para jobs de produÃ§Ã£o. Custa o dobro!'
        },
        {
          es: 'ğŸ†“ En Free Edition, no te preocupes por elegir - solo tenÃ©s serverless y funciona automÃ¡ticamente.',
          en: 'ğŸ†“ In Free Edition, don\'t worry about choosing - you only have serverless and it works automatically.',
          pt: 'ğŸ†“ No Free Edition, nÃ£o se preocupe em escolher - vocÃª sÃ³ tem serverless e funciona automaticamente.'
        }
      ],
      externalLinks: [
        {
          title: 'Cluster Types',
          url: 'https://docs.databricks.com/clusters/index.html',
          type: 'docs'
        }
      ],
      checkpoint: {
        es: 'ğŸ’¡ Â¿QuÃ© tipo de cluster usarÃ­as para un ETL que corre a las 3am todos los dÃ­as?',
        en: 'ğŸ’¡ What cluster type would you use for an ETL that runs at 3am every day?',
        pt: 'ğŸ’¡ Que tipo de cluster vocÃª usaria para um ETL que roda Ã s 3am todos os dias?'
      },
      xpReward: 20,
      estimatedMinutes: 15
    },
    {
      id: 'db-2-4',
      title: {
        es: 'Databricks Runtime: Versiones y Componentes',
        en: 'Databricks Runtime: Versions and Components',
        pt: 'Databricks Runtime: VersÃµes e Componentes'
      },
      description: {
        es: 'El Runtime es el "sistema operativo" de tu cluster. Elegir bien impacta en compatibilidad y performance.',
        en: 'The Runtime is your cluster\'s "operating system". Choosing well impacts compatibility and performance.',
        pt: 'O Runtime Ã© o "sistema operacional" do seu cluster. Escolher bem impacta em compatibilidade e performance.'
      },
      theory: {
        es: `## Databricks Runtime

El Runtime es un conjunto pre-configurado de:
- Apache Spark
- Bibliotecas de Python/R/Scala
- Optimizaciones de Databricks
- Delta Lake

### Tipos de Runtime:

| Runtime | Incluye | Uso |
|---------|---------|-----|
| Standard | Spark + bibliotecas bÃ¡sicas | General |
| ML | + TensorFlow, PyTorch, Scikit-learn | Machine Learning |
| Photon | + Motor Photon (C++) | Performance mÃ¡xima |
| GPU | + CUDA, cuDNN | Deep Learning |

### Versionado:

\`\`\`
13.3 LTS (Spark 3.4.1, Scala 2.12)
â”‚    â”‚
â”‚    â””â”€â”€ Long Term Support (soporte largo)
â””â”€â”€ VersiÃ³n mayor del Runtime
\`\`\`

### LTS vs Latest:

**LTS (Long Term Support):**
- Soporte por 2 aÃ±os
- MÃ¡s estable
- âœ… Recomendado para producciÃ³n

**Latest:**
- Features mÃ¡s nuevas
- Puede tener bugs
- âœ… Bueno para experimentar

### Componentes del Runtime:

\`\`\`python
# Ver versiÃ³n de Spark
spark.version  # "3.4.1"

# Ver versiÃ³n del Runtime
spark.conf.get("spark.databricks.clusterUsageTags.sparkVersion")

# Ver bibliotecas instaladas
%pip list
\`\`\`

### Best Practices:
1. ProducciÃ³n: Siempre LTS
2. Desarrollo: Puede ser latest
3. Documentar versiÃ³n en cada proyecto`,
        en: `## Databricks Runtime

The Runtime is a pre-configured set of:
- Apache Spark
- Python/R/Scala libraries
- Databricks optimizations
- Delta Lake

### Runtime Types:

| Runtime | Includes | Use |
|---------|----------|-----|
| Standard | Spark + basic libraries | General |
| ML | + TensorFlow, PyTorch, Scikit-learn | Machine Learning |
| Photon | + Photon Engine (C++) | Maximum performance |
| GPU | + CUDA, cuDNN | Deep Learning |

### Versioning:

\`\`\`
13.3 LTS (Spark 3.4.1, Scala 2.12)
â”‚    â”‚
â”‚    â””â”€â”€ Long Term Support
â””â”€â”€ Runtime major version
\`\`\`

### LTS vs Latest:

**LTS (Long Term Support):**
- 2-year support
- More stable
- âœ… Recommended for production

**Latest:**
- Newest features
- May have bugs
- âœ… Good for experimenting

### Runtime Components:

\`\`\`python
# Check Spark version
spark.version  # "3.4.1"

# Check Runtime version
spark.conf.get("spark.databricks.clusterUsageTags.sparkVersion")

# See installed libraries
%pip list
\`\`\`

### Best Practices:
1. Production: Always LTS
2. Development: Can be latest
3. Document version in each project`,
        pt: `## Databricks Runtime

O Runtime Ã© um conjunto prÃ©-configurado de:
- Apache Spark
- Bibliotecas Python/R/Scala
- OtimizaÃ§Ãµes do Databricks
- Delta Lake

### Tipos de Runtime:

| Runtime | Inclui | Uso |
|---------|--------|-----|
| Standard | Spark + bibliotecas bÃ¡sicas | Geral |
| ML | + TensorFlow, PyTorch, Scikit-learn | Machine Learning |
| Photon | + Motor Photon (C++) | Performance mÃ¡xima |
| GPU | + CUDA, cuDNN | Deep Learning |

### Versionamento:

\`\`\`
13.3 LTS (Spark 3.4.1, Scala 2.12)
â”‚    â”‚
â”‚    â””â”€â”€ Long Term Support (suporte longo)
â””â”€â”€ VersÃ£o maior do Runtime
\`\`\`

### LTS vs Latest:

**LTS (Long Term Support):**
- Suporte por 2 anos
- Mais estÃ¡vel
- âœ… Recomendado para produÃ§Ã£o

**Latest:**
- Features mais novas
- Pode ter bugs
- âœ… Bom para experimentar

### Componentes do Runtime:

\`\`\`python
# Ver versÃ£o do Spark
spark.version  # "3.4.1"

# Ver versÃ£o do Runtime
spark.conf.get("spark.databricks.clusterUsageTags.sparkVersion")

# Ver bibliotecas instaladas
%pip list
\`\`\`

### Melhores PrÃ¡ticas:
1. ProduÃ§Ã£o: Sempre LTS
2. Desenvolvimento: Pode ser latest
3. Documentar versÃ£o em cada projeto`
      },
      practicalTips: [
        {
          es: 'âš ï¸ Cambiar de Runtime puede romper cÃ³digo. Siempre testear antes de actualizar en producciÃ³n.',
          en: 'âš ï¸ Changing Runtime can break code. Always test before updating in production.',
          pt: 'âš ï¸ Mudar de Runtime pode quebrar cÃ³digo. Sempre testar antes de atualizar em produÃ§Ã£o.'
        }
      ],
      externalLinks: [
        {
          title: 'Runtime Release Notes',
          url: 'https://docs.databricks.com/release-notes/runtime/releases.html',
          type: 'docs'
        }
      ],
      checkpoint: {
        es: 'ğŸ¤” Â¿QuÃ© Runtime elegirÃ­as para un pipeline de ML en producciÃ³n?',
        en: 'ğŸ¤” What Runtime would you choose for an ML pipeline in production?',
        pt: 'ğŸ¤” Qual Runtime vocÃª escolheria para um pipeline de ML em produÃ§Ã£o?'
      },
      xpReward: 20,
      estimatedMinutes: 20
    },
    {
      id: 'db-2-5',
      title: {
        es: 'Photon Engine: El Acelerador Nativo',
        en: 'Photon Engine: The Native Accelerator',
        pt: 'Photon Engine: O Acelerador Nativo'
      },
      description: {
        es: 'Photon puede hacer tu cÃ³digo 2-8x mÃ¡s rÃ¡pido sin cambiar nada. EntendÃ© cÃ³mo funciona.',
        en: 'Photon can make your code 2-8x faster without changing anything. Understand how it works.',
        pt: 'O Photon pode fazer seu cÃ³digo 2-8x mais rÃ¡pido sem mudar nada. Entenda como funciona.'
      },
      theory: {
        es: `## Photon Engine

Photon es el motor de ejecuciÃ³n nativo de Databricks, escrito en C++ para mÃ¡xima performance.

### Â¿QuÃ© es Photon?

\`\`\`
Spark tradicional:
Python â†’ JVM (Java) â†’ EjecuciÃ³n

Con Photon:
Python â†’ Photon (C++ nativo) â†’ EjecuciÃ³n vectorizada
\`\`\`

### Beneficios:

| MÃ©trica | Sin Photon | Con Photon |
|---------|------------|------------|
| Queries SQL | 1x | 2-8x mÃ¡s rÃ¡pido |
| Agregaciones | 1x | 3-5x mÃ¡s rÃ¡pido |
| Joins | 1x | 2-4x mÃ¡s rÃ¡pido |
| Costo | Base | Similar o menor (menos tiempo) |

### Â¿CuÃ¡ndo usar Photon?

âœ… **SÃ­:**
- SQL Analytics
- ETL con transformaciones SQL
- Agregaciones grandes
- Delta Lake operations

âŒ **No tanto:**
- UDFs de Python puro
- CÃ³digo muy custom
- Clusters pequeÃ±os

### CÃ³mo activar:

1. Al crear cluster, elegir Runtime con "Photon"
2. O seleccionar "Use Photon Acceleration"

### Verificar si estÃ¡ activo:
\`\`\`python
# DeberÃ­a mostrar operaciones con "Photon" en el plan
df.explain()

# O revisar en Spark UI > SQL > Query Details
\`\`\`

### Pricing:
- Photon tiene un costo adicional en DBUs (~1.5x)
- Pero como es mÃ¡s rÃ¡pido, el costo total suele ser igual o menor`,
        en: `## Photon Engine

Photon is Databricks' native execution engine, written in C++ for maximum performance.

### What is Photon?

\`\`\`
Traditional Spark:
Python â†’ JVM (Java) â†’ Execution

With Photon:
Python â†’ Photon (native C++) â†’ Vectorized execution
\`\`\`

### Benefits:

| Metric | Without Photon | With Photon |
|--------|---------------|-------------|
| SQL Queries | 1x | 2-8x faster |
| Aggregations | 1x | 3-5x faster |
| Joins | 1x | 2-4x faster |
| Cost | Base | Similar or less (less time) |

### When to use Photon?

âœ… **Yes:**
- SQL Analytics
- ETL with SQL transformations
- Large aggregations
- Delta Lake operations

âŒ **Not so much:**
- Pure Python UDFs
- Very custom code
- Small clusters

### How to activate:

1. When creating cluster, choose Runtime with "Photon"
2. Or select "Use Photon Acceleration"

### Verify if active:
\`\`\`python
# Should show operations with "Photon" in the plan
df.explain()

# Or check in Spark UI > SQL > Query Details
\`\`\`

### Pricing:
- Photon has additional DBU cost (~1.5x)
- But since it's faster, total cost is usually same or less`,
        pt: `## Photon Engine

O Photon Ã© o motor de execuÃ§Ã£o nativo do Databricks, escrito em C++ para performance mÃ¡xima.

### O que Ã© Photon?

\`\`\`
Spark tradicional:
Python â†’ JVM (Java) â†’ ExecuÃ§Ã£o

Com Photon:
Python â†’ Photon (C++ nativo) â†’ ExecuÃ§Ã£o vetorizada
\`\`\`

### BenefÃ­cios:

| MÃ©trica | Sem Photon | Com Photon |
|---------|------------|------------|
| Queries SQL | 1x | 2-8x mais rÃ¡pido |
| AgregaÃ§Ãµes | 1x | 3-5x mais rÃ¡pido |
| Joins | 1x | 2-4x mais rÃ¡pido |
| Custo | Base | Similar ou menor (menos tempo) |

### Quando usar Photon?

âœ… **Sim:**
- SQL Analytics
- ETL com transformaÃ§Ãµes SQL
- AgregaÃ§Ãµes grandes
- OperaÃ§Ãµes Delta Lake

âŒ **Nem tanto:**
- UDFs de Python puro
- CÃ³digo muito custom
- Clusters pequenos

### Como ativar:

1. Ao criar cluster, escolher Runtime com "Photon"
2. Ou selecionar "Use Photon Acceleration"

### Verificar se estÃ¡ ativo:
\`\`\`python
# Deve mostrar operaÃ§Ãµes com "Photon" no plano
df.explain()

# Ou verificar no Spark UI > SQL > Query Details
\`\`\`

### Pricing:
- Photon tem custo adicional em DBUs (~1.5x)
- Mas como Ã© mais rÃ¡pido, o custo total costuma ser igual ou menor`
      },
      practicalTips: [
        {
          es: 'ğŸš€ Photon estÃ¡ incluido automÃ¡ticamente en serverless compute (Free Edition y planes pagos).',
          en: 'ğŸš€ Photon is automatically included in serverless compute (Free Edition and paid plans).',
          pt: 'ğŸš€ Photon estÃ¡ incluÃ­do automaticamente no serverless compute (Free Edition e planos pagos).'
        },
        {
          es: 'ğŸ’¡ En Free Edition, todas tus queries SQL ya usan Photon sin configuraciÃ³n adicional.',
          en: 'ğŸ’¡ In Free Edition, all your SQL queries already use Photon without additional configuration.',
          pt: 'ğŸ’¡ No Free Edition, todas as suas queries SQL jÃ¡ usam Photon sem configuraÃ§Ã£o adicional.'
        }
      ],
      externalLinks: [
        {
          title: 'Photon Runtime',
          url: 'https://docs.databricks.com/runtime/photon.html',
          type: 'docs'
        }
      ],
      checkpoint: {
        es: 'ğŸ’¡ Â¿En quÃ© tipo de workloads NO usarÃ­as Photon?',
        en: 'ğŸ’¡ What type of workloads would you NOT use Photon for?',
        pt: 'ğŸ’¡ Em que tipo de workloads vocÃª NÃƒO usaria Photon?'
      },
      xpReward: 20,
      estimatedMinutes: 15
    },
    {
      id: 'db-2-6',
      title: {
        es: 'Workspace, Metastore y Catalog: La JerarquÃ­a',
        en: 'Workspace, Metastore and Catalog: The Hierarchy',
        pt: 'Workspace, Metastore e Catalog: A Hierarquia'
      },
      description: {
        es: 'EntendÃ© cÃ³mo se organizan los datos en Databricks: workspace > metastore > catalog > schema > table.',
        en: 'Understand how data is organized in Databricks: workspace > metastore > catalog > schema > table.',
        pt: 'Entenda como os dados sÃ£o organizados no Databricks: workspace > metastore > catalog > schema > table.'
      },
      theory: {
        es: `## JerarquÃ­a de Datos en Databricks

### Modelo de 3 niveles (Unity Catalog):

\`\`\`
                    METASTORE
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚              â”‚              â”‚
      CATALOG 1     CATALOG 2     CATALOG 3
         â”‚              â”‚              â”‚
    â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”
    â”‚    â”‚    â”‚    â”‚    â”‚    â”‚   â”‚    â”‚    â”‚
  SCHEMA SCHEMA  SCHEMA SCHEMA SCHEMA SCHEMA
    â”‚
  TABLES, VIEWS, FUNCTIONS
\`\`\`

### Componentes:

**Metastore:**
- Contenedor de nivel mÃ¡s alto
- Uno por regiÃ³n de cloud
- Almacena metadata de todos los objetos

**Catalog:**
- Agrupa schemas relacionados
- Ejemplo: \`dev\`, \`staging\`, \`prod\`

**Schema (Database):**
- Agrupa tablas relacionadas
- Ejemplo: \`sales\`, \`marketing\`, \`finance\`

**Table:**
- Los datos en sÃ­
- Managed o External

### Nombres completos:

\`\`\`sql
-- Tres partes: catalog.schema.table
SELECT * FROM prod.sales.orders

-- Si estÃ¡s en el catalog/schema correcto
USE CATALOG prod;
USE SCHEMA sales;
SELECT * FROM orders;
\`\`\`

### Hive Metastore (legacy) vs Unity Catalog:

| Feature | Hive | Unity Catalog |
|---------|------|---------------|
| Governance | âŒ | âœ… |
| Cross-workspace | âŒ | âœ… |
| Row-level security | âŒ | âœ… |
| Audit logs | BÃ¡sico | Completo |`,
        en: `## Data Hierarchy in Databricks

### 3-level model (Unity Catalog):

\`\`\`
                    METASTORE
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚              â”‚              â”‚
      CATALOG 1     CATALOG 2     CATALOG 3
         â”‚              â”‚              â”‚
    â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”
    â”‚    â”‚    â”‚    â”‚    â”‚    â”‚   â”‚    â”‚    â”‚
  SCHEMA SCHEMA  SCHEMA SCHEMA SCHEMA SCHEMA
    â”‚
  TABLES, VIEWS, FUNCTIONS
\`\`\`

### Components:

**Metastore:**
- Top-level container
- One per cloud region
- Stores metadata for all objects

**Catalog:**
- Groups related schemas
- Example: \`dev\`, \`staging\`, \`prod\`

**Schema (Database):**
- Groups related tables
- Example: \`sales\`, \`marketing\`, \`finance\`

**Table:**
- The data itself
- Managed or External

### Full names:

\`\`\`sql
-- Three parts: catalog.schema.table
SELECT * FROM prod.sales.orders

-- If you're in the right catalog/schema
USE CATALOG prod;
USE SCHEMA sales;
SELECT * FROM orders;
\`\`\`

### Hive Metastore (legacy) vs Unity Catalog:

| Feature | Hive | Unity Catalog |
|---------|------|---------------|
| Governance | âŒ | âœ… |
| Cross-workspace | âŒ | âœ… |
| Row-level security | âŒ | âœ… |
| Audit logs | Basic | Complete |`,
        pt: `## Hierarquia de Dados no Databricks

### Modelo de 3 nÃ­veis (Unity Catalog):

\`\`\`
                    METASTORE
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚              â”‚              â”‚
      CATALOG 1     CATALOG 2     CATALOG 3
         â”‚              â”‚              â”‚
    â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”
    â”‚    â”‚    â”‚    â”‚    â”‚    â”‚   â”‚    â”‚    â”‚
  SCHEMA SCHEMA  SCHEMA SCHEMA SCHEMA SCHEMA
    â”‚
  TABLES, VIEWS, FUNCTIONS
\`\`\`

### Componentes:

**Metastore:**
- Container de nÃ­vel mais alto
- Um por regiÃ£o de cloud
- Armazena metadata de todos os objetos

**Catalog:**
- Agrupa schemas relacionados
- Exemplo: \`dev\`, \`staging\`, \`prod\`

**Schema (Database):**
- Agrupa tabelas relacionadas
- Exemplo: \`sales\`, \`marketing\`, \`finance\`

**Table:**
- Os dados em si
- Managed ou External

### Nomes completos:

\`\`\`sql
-- TrÃªs partes: catalog.schema.table
SELECT * FROM prod.sales.orders

-- Se vocÃª estÃ¡ no catalog/schema correto
USE CATALOG prod;
USE SCHEMA sales;
SELECT * FROM orders;
\`\`\`

### Hive Metastore (legacy) vs Unity Catalog:

| Feature | Hive | Unity Catalog |
|---------|------|---------------|
| Governance | âŒ | âœ… |
| Cross-workspace | âŒ | âœ… |
| Row-level security | âŒ | âœ… |
| Audit logs | BÃ¡sico | Completo |`
      },
      practicalTips: [
        {
          es: 'ğŸ¯ Unity Catalog es el futuro. Si tu empresa aÃºn usa Hive Metastore, planificÃ¡ la migraciÃ³n.',
          en: 'ğŸ¯ Unity Catalog is the future. If your company still uses Hive Metastore, plan the migration.',
          pt: 'ğŸ¯ Unity Catalog Ã© o futuro. Se sua empresa ainda usa Hive Metastore, planeje a migraÃ§Ã£o.'
        }
      ],
      externalLinks: [
        {
          title: 'Unity Catalog Overview',
          url: 'https://docs.databricks.com/data-governance/unity-catalog/index.html',
          type: 'docs'
        }
      ],
      checkpoint: {
        es: 'ğŸ¤” Â¿CuÃ¡l es la diferencia entre un Catalog y un Schema?',
        en: 'ğŸ¤” What\'s the difference between a Catalog and a Schema?',
        pt: 'ğŸ¤” Qual Ã© a diferenÃ§a entre um Catalog e um Schema?'
      },
      xpReward: 20,
      estimatedMinutes: 20
    },
    {
      id: 'db-2-7',
      title: {
        es: 'Managed vs External Tables',
        en: 'Managed vs External Tables',
        pt: 'Managed vs External Tables'
      },
      description: {
        es: 'Dos formas de almacenar datos con comportamientos muy diferentes. ElegÃ­ bien.',
        en: 'Two ways to store data with very different behaviors. Choose wisely.',
        pt: 'Duas formas de armazenar dados com comportamentos muito diferentes. Escolha bem.'
      },
      theory: {
        es: `## Managed vs External Tables

### Managed Tables (Default)
\`\`\`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         MANAGED TABLE            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Databricks controla los datos  â”‚
â”‚ â€¢ UbicaciÃ³n: metastore default   â”‚
â”‚ â€¢ DROP TABLE = borra datos       â”‚
â”‚ â€¢ Ideal para datos intermedios   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

\`\`\`sql
-- Crear managed table
CREATE TABLE mi_tabla (
  id INT,
  nombre STRING
);

-- Los datos se guardan en ubicaciÃ³n default
-- dbfs:/user/hive/warehouse/mi_tabla
\`\`\`

### External Tables
\`\`\`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        EXTERNAL TABLE            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Vos controlÃ¡s la ubicaciÃ³n     â”‚
â”‚ â€¢ UbicaciÃ³n: donde vos digas     â”‚
â”‚ â€¢ DROP TABLE = solo borra metadata â”‚
â”‚ â€¢ Ideal para data lake           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

\`\`\`sql
-- Crear external table
CREATE TABLE mi_tabla_ext (
  id INT,
  nombre STRING
)
LOCATION 's3://mi-bucket/datos/mi_tabla';

-- DROP solo borra la definiciÃ³n, no los archivos
\`\`\`

### ComparaciÃ³n:

| Aspecto | Managed | External |
|---------|---------|----------|
| Control ubicaciÃ³n | Databricks | Usuario |
| DROP TABLE | Borra todo | Solo metadata |
| Backup | MÃ¡s complejo | FÃ¡cil (tu storage) |
| Costo storage | DBU incluido | Tu cuenta cloud |
| Compartir datos | DifÃ­cil | FÃ¡cil |

### Â¿CuÃ¡ndo usar cada una?

**Managed:**
- Tablas temporales
- Resultados intermedios de ETL
- Datos que no necesitÃ¡s fuera de Databricks

**External:**
- Data Lake
- Datos compartidos entre herramientas
- Datos que ya existen en S3/ADLS/GCS
- ProducciÃ³n`,
        en: `## Managed vs External Tables

### Managed Tables (Default)
\`\`\`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         MANAGED TABLE            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Databricks controls the data   â”‚
â”‚ â€¢ Location: default metastore    â”‚
â”‚ â€¢ DROP TABLE = deletes data      â”‚
â”‚ â€¢ Ideal for intermediate data    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

\`\`\`sql
-- Create managed table
CREATE TABLE my_table (
  id INT,
  name STRING
);

-- Data is saved in default location
-- dbfs:/user/hive/warehouse/my_table
\`\`\`

### External Tables
\`\`\`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        EXTERNAL TABLE            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ You control the location       â”‚
â”‚ â€¢ Location: wherever you say     â”‚
â”‚ â€¢ DROP TABLE = only deletes metadata â”‚
â”‚ â€¢ Ideal for data lake            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

\`\`\`sql
-- Create external table
CREATE TABLE my_ext_table (
  id INT,
  name STRING
)
LOCATION 's3://my-bucket/data/my_table';

-- DROP only deletes definition, not files
\`\`\`

### Comparison:

| Aspect | Managed | External |
|--------|---------|----------|
| Location control | Databricks | User |
| DROP TABLE | Deletes all | Only metadata |
| Backup | More complex | Easy (your storage) |
| Storage cost | DBU included | Your cloud account |
| Share data | Difficult | Easy |

### When to use each?

**Managed:**
- Temporary tables
- Intermediate ETL results
- Data you don't need outside Databricks

**External:**
- Data Lake
- Data shared between tools
- Data already in S3/ADLS/GCS
- Production`,
        pt: `## Managed vs External Tables

### Managed Tables (PadrÃ£o)
\`\`\`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         MANAGED TABLE            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Databricks controla os dados   â”‚
â”‚ â€¢ LocalizaÃ§Ã£o: metastore padrÃ£o  â”‚
â”‚ â€¢ DROP TABLE = apaga dados       â”‚
â”‚ â€¢ Ideal para dados intermediÃ¡riosâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

\`\`\`sql
-- Criar managed table
CREATE TABLE minha_tabela (
  id INT,
  nome STRING
);

-- Os dados sÃ£o salvos na localizaÃ§Ã£o padrÃ£o
-- dbfs:/user/hive/warehouse/minha_tabela
\`\`\`

### External Tables
\`\`\`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        EXTERNAL TABLE            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ VocÃª controla a localizaÃ§Ã£o    â”‚
â”‚ â€¢ LocalizaÃ§Ã£o: onde vocÃª disser  â”‚
â”‚ â€¢ DROP TABLE = sÃ³ apaga metadata â”‚
â”‚ â€¢ Ideal para data lake           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

\`\`\`sql
-- Criar external table
CREATE TABLE minha_tabela_ext (
  id INT,
  nome STRING
)
LOCATION 's3://meu-bucket/dados/minha_tabela';

-- DROP sÃ³ apaga a definiÃ§Ã£o, nÃ£o os arquivos
\`\`\`

### ComparaÃ§Ã£o:

| Aspecto | Managed | External |
|---------|---------|----------|
| Controle localizaÃ§Ã£o | Databricks | UsuÃ¡rio |
| DROP TABLE | Apaga tudo | SÃ³ metadata |
| Backup | Mais complexo | FÃ¡cil (seu storage) |
| Custo storage | DBU incluÃ­do | Sua conta cloud |
| Compartilhar dados | DifÃ­cil | FÃ¡cil |

### Quando usar cada uma?

**Managed:**
- Tabelas temporÃ¡rias
- Resultados intermediÃ¡rios de ETL
- Dados que vocÃª nÃ£o precisa fora do Databricks

**External:**
- Data Lake
- Dados compartilhados entre ferramentas
- Dados que jÃ¡ existem no S3/ADLS/GCS
- ProduÃ§Ã£o`
      },
      practicalTips: [
        {
          es: 'âš ï¸ Cuidado con DROP en managed tables en producciÃ³n. Los datos se borran para siempre!',
          en: 'âš ï¸ Be careful with DROP on managed tables in production. Data is deleted forever!',
          pt: 'âš ï¸ Cuidado com DROP em managed tables em produÃ§Ã£o. Os dados sÃ£o apagados para sempre!'
        }
      ],
      externalLinks: [
        {
          title: 'Managed vs External Tables',
          url: 'https://docs.databricks.com/data-governance/unity-catalog/create-tables.html',
          type: 'docs'
        }
      ],
      checkpoint: {
        es: 'ğŸ’¡ Â¿QuÃ© pasa si hago DROP TABLE en una external table?',
        en: 'ğŸ’¡ What happens if I DROP TABLE on an external table?',
        pt: 'ğŸ’¡ O que acontece se eu fizer DROP TABLE em uma external table?'
      },
      xpReward: 20,
      estimatedMinutes: 15
    },
    {
      id: 'db-2-8',
      title: {
        es: 'DBUs: La Moneda de Databricks',
        en: 'DBUs: The Databricks Currency',
        pt: 'DBUs: A Moeda do Databricks'
      },
      description: {
        es: 'EntendÃ© cÃ³mo se cobra Databricks para optimizar costos.',
        en: 'Understand how Databricks charges to optimize costs.',
        pt: 'Entenda como o Databricks cobra para otimizar custos.'
      },
      theory: {
        es: `## DBUs - Databricks Units

Un DBU es la unidad de procesamiento de Databricks. Es como "crÃ©ditos" que consumÃ­s al usar la plataforma.

### FÃ³rmula de costo:

\`\`\`
Costo Total = (DBUs consumidos Ã— Precio por DBU) + Costo de infraestructura cloud
\`\`\`

### Factores que afectan DBUs:

| Factor | Impacto en DBUs |
|--------|-----------------|
| TamaÃ±o del cluster | MÃ¡s grande = mÃ¡s DBUs/hora |
| Tipo de cluster | Job < All-Purpose |
| Runtime | Photon consume mÃ¡s DBUs |
| Tiempo encendido | MÃ¡s tiempo = mÃ¡s DBUs |

### Ejemplo de consumo:

\`\`\`
Cluster i3.xlarge (4 DBUs/hora)
Ã— 8 horas de uso
Ã— $0.40 por DBU (ejemplo)
= $12.80 en DBUs

+ Costo EC2 de AWS
= Costo total
\`\`\`

### Tips para reducir costos:

1. **Auto-terminate**: Siempre configurar (ej: 30 min)
2. **Job clusters**: Para producciÃ³n (50% menos DBUs)
3. **Spot instances**: 60-90% descuento en compute
4. **Right-sizing**: No sobredimensionar clusters
5. **Photon**: Aunque cuesta mÃ¡s DBUs, puede ser mÃ¡s barato por velocidad

### Monitorear costos:

\`\`\`sql
-- Ver uso de DBUs (requiere permisos admin)
SELECT * FROM system.billing.usage
WHERE usage_date >= current_date - 30
\`\`\`

### Tags para tracking:

\`\`\`python
# Al crear cluster, agregar tags
{
  "proyecto": "ventas-etl",
  "equipo": "data-engineering",
  "ambiente": "produccion"
}
\`\`\``,
        en: `## DBUs - Databricks Units

A DBU is Databricks' processing unit. It's like "credits" you consume when using the platform.

### Cost formula:

\`\`\`
Total Cost = (DBUs consumed Ã— Price per DBU) + Cloud infrastructure cost
\`\`\`

### Factors affecting DBUs:

| Factor | DBU Impact |
|--------|------------|
| Cluster size | Bigger = more DBUs/hour |
| Cluster type | Job < All-Purpose |
| Runtime | Photon consumes more DBUs |
| Time running | More time = more DBUs |

### Consumption example:

\`\`\`
i3.xlarge cluster (4 DBUs/hour)
Ã— 8 hours of use
Ã— $0.40 per DBU (example)
= $12.80 in DBUs

+ AWS EC2 cost
= Total cost
\`\`\`

### Tips to reduce costs:

1. **Auto-terminate**: Always configure (e.g., 30 min)
2. **Job clusters**: For production (50% less DBUs)
3. **Spot instances**: 60-90% compute discount
4. **Right-sizing**: Don't over-provision clusters
5. **Photon**: Although it costs more DBUs, can be cheaper due to speed

### Monitor costs:

\`\`\`sql
-- View DBU usage (requires admin permissions)
SELECT * FROM system.billing.usage
WHERE usage_date >= current_date - 30
\`\`\`

### Tags for tracking:

\`\`\`python
# When creating cluster, add tags
{
  "project": "sales-etl",
  "team": "data-engineering",
  "environment": "production"
}
\`\`\``,
        pt: `## DBUs - Databricks Units

Um DBU Ã© a unidade de processamento do Databricks. Ã‰ como "crÃ©ditos" que vocÃª consome ao usar a plataforma.

### FÃ³rmula de custo:

\`\`\`
Custo Total = (DBUs consumidos Ã— PreÃ§o por DBU) + Custo de infraestrutura cloud
\`\`\`

### Fatores que afetam DBUs:

| Fator | Impacto em DBUs |
|-------|-----------------|
| Tamanho do cluster | Maior = mais DBUs/hora |
| Tipo de cluster | Job < All-Purpose |
| Runtime | Photon consome mais DBUs |
| Tempo ligado | Mais tempo = mais DBUs |

### Exemplo de consumo:

\`\`\`
Cluster i3.xlarge (4 DBUs/hora)
Ã— 8 horas de uso
Ã— $0.40 por DBU (exemplo)
= $12.80 em DBUs

+ Custo EC2 da AWS
= Custo total
\`\`\`

### Dicas para reduzir custos:

1. **Auto-terminate**: Sempre configurar (ex: 30 min)
2. **Job clusters**: Para produÃ§Ã£o (50% menos DBUs)
3. **Spot instances**: 60-90% desconto em compute
4. **Right-sizing**: NÃ£o superdimensionar clusters
5. **Photon**: Embora custe mais DBUs, pode ser mais barato pela velocidade

### Monitorar custos:

\`\`\`sql
-- Ver uso de DBUs (requer permissÃµes admin)
SELECT * FROM system.billing.usage
WHERE usage_date >= current_date - 30
\`\`\`

### Tags para tracking:

\`\`\`python
# Ao criar cluster, adicionar tags
{
  "projeto": "vendas-etl",
  "equipe": "data-engineering",
  "ambiente": "producao"
}
\`\`\``
      },
      practicalTips: [
        {
          es: 'ğŸ’° Configurar alertas de billing cuando el consumo supere X%. EvitÃ¡ sorpresas.',
          en: 'ğŸ’° Set billing alerts when consumption exceeds X%. Avoid surprises.',
          pt: 'ğŸ’° Configure alertas de billing quando o consumo ultrapassar X%. Evite surpresas.'
        }
      ],
      externalLinks: [
        {
          title: 'Databricks Pricing',
          url: 'https://www.databricks.com/product/pricing',
          type: 'article'
        },
        {
          title: 'Cost Management',
          url: 'https://docs.databricks.com/administration-guide/account-settings/billable-usage.html',
          type: 'docs'
        }
      ],
      checkpoint: {
        es: 'ğŸ’¡ Â¿CÃ³mo reducirÃ­as el costo de un ETL que corre 4 horas diarias?',
        en: 'ğŸ’¡ How would you reduce the cost of an ETL that runs 4 hours daily?',
        pt: 'ğŸ’¡ Como vocÃª reduziria o custo de um ETL que roda 4 horas por dia?'
      },
      xpReward: 25,
      estimatedMinutes: 20
    },
    {
      id: 'db-2-8b',
      title: {
        es: 'Cluster Policies: Governance de Clusters',
        en: 'Cluster Policies: Cluster Governance',
        pt: 'Cluster Policies: GovernanÃ§a de Clusters'
      },
      description: {
        es: 'Controla quÃ© tipos de clusters pueden crear los usuarios en tu workspace.',
        en: 'Control what types of clusters users can create in your workspace.',
        pt: 'Controle quais tipos de clusters os usuÃ¡rios podem criar no seu workspace.'
      },
      theory: {
        es: `## Cluster Policies: Governance Empresarial

Las Cluster Policies permiten a los admins **controlar y estandarizar** la creaciÃ³n de clusters. Esto es CRÃTICO para:
- Controlar costos
- Garantizar seguridad
- Estandarizar configuraciones

### Â¿Por quÃ© son Importantes?

\`\`\`
Sin Policies:                    Con Policies:
                                 
Usuario A: i3.2xlarge x 10      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
Usuario B: i3.4xlarge x 20      â”‚     CLUSTER POLICY       â”‚
Usuario C: i3.8xlarge x 5       â”‚                          â”‚
         â†“                      â”‚ â€¢ Max 4 workers          â”‚
    COSTOS SIN CONTROL          â”‚ â€¢ Solo i3.xlarge         â”‚
    $$$$$$$                     â”‚ â€¢ Autotermination ON     â”‚
                                â”‚ â€¢ Spot instances         â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â†“
                                  COSTOS CONTROLADOS
                                  $$
\`\`\`

### Estructura de una Policy

\`\`\`json
{
  "name": "Data Engineering Standard",
  "definition": {
    "spark_version": {
      "type": "fixed",
      "value": "14.3.x-scala2.12"
    },
    "node_type_id": {
      "type": "allowlist",
      "values": ["i3.xlarge", "i3.2xlarge"]
    },
    "autoscale.max_workers": {
      "type": "range",
      "maxValue": 10
    },
    "autotermination_minutes": {
      "type": "fixed",
      "value": 30,
      "hidden": true
    },
    "custom_tags.team": {
      "type": "fixed",
      "value": "data-engineering"
    }
  }
}
\`\`\`

### Tipos de Restricciones

| Tipo | DescripciÃ³n | Ejemplo |
|------|-------------|---------|
| \`fixed\` | Valor fijo, no modificable | Runtime especÃ­fico |
| \`allowlist\` | Solo valores de la lista | Tipos de instancia |
| \`blocklist\` | Prohibir valores | No usar GPU |
| \`range\` | Rango numÃ©rico | Max 10 workers |
| \`unlimited\` | Sin restricciÃ³n | Usuario decide |
| \`regex\` | Debe matchear regex | Nombre del cluster |

### Ejemplo: Policy para Desarrollo

\`\`\`json
{
  "name": "Dev - Cost Optimized",
  "description": "Para desarrollo y experimentaciÃ³n",
  "definition": {
    "spark_version": {
      "type": "allowlist",
      "values": ["14.3.x-scala2.12", "14.3.x-scala2.12"],
      "defaultValue": "14.3.x-scala2.12"
    },
    "node_type_id": {
      "type": "allowlist",
      "values": ["i3.xlarge", "m5.large"],
      "defaultValue": "i3.xlarge"
    },
    "driver_node_type_id": {
      "type": "fixed",
      "value": "i3.xlarge"
    },
    "autoscale.min_workers": {
      "type": "fixed",
      "value": 1
    },
    "autoscale.max_workers": {
      "type": "range",
      "maxValue": 4,
      "defaultValue": 2
    },
    "autotermination_minutes": {
      "type": "range",
      "minValue": 10,
      "maxValue": 60,
      "defaultValue": 30
    },
    "aws_attributes.availability": {
      "type": "fixed",
      "value": "SPOT_WITH_FALLBACK"
    }
  }
}
\`\`\`

### Ejemplo: Policy para ProducciÃ³n

\`\`\`json
{
  "name": "Production - High Availability",
  "description": "Para jobs crÃ­ticos de producciÃ³n",
  "definition": {
    "spark_version": {
      "type": "fixed",
      "value": "14.3.x-scala2.12"
    },
    "node_type_id": {
      "type": "fixed",
      "value": "i3.2xlarge"
    },
    "autoscale.min_workers": {
      "type": "range",
      "minValue": 2
    },
    "autoscale.max_workers": {
      "type": "range",
      "maxValue": 20
    },
    "autotermination_minutes": {
      "type": "fixed",
      "value": 0,
      "hidden": true
    },
    "aws_attributes.availability": {
      "type": "fixed",
      "value": "ON_DEMAND"
    },
    "cluster_log_conf.type": {
      "type": "fixed",
      "value": "S3"
    }
  }
}
\`\`\`

### Crear Policy via UI

1. **Compute** â†’ **Cluster Policies** â†’ **Create Policy**
2. Nombrar la policy
3. Definir restricciones en JSON
4. Asignar a grupos de usuarios

### Crear Policy via API

\`\`\`python
import requests

policy = {
    "name": "My Policy",
    "definition": {
        "autoscale.max_workers": {
            "type": "range",
            "maxValue": 5
        }
    }
}

response = requests.post(
    f"{databricks_url}/api/2.0/policies/clusters/create",
    headers={"Authorization": f"Bearer {token}"},
    json=policy
)
\`\`\`

### Instance Pools (Complemento de Policies)

Los Instance Pools pre-aprovisionan VMs para reducir el tiempo de inicio:

\`\`\`
Sin Pool:                       Con Pool:
                               
Crear cluster                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â†“                        â”‚   INSTANCE POOL     â”‚
Solicitar VMs a AWS            â”‚                     â”‚
      â†“ (2-5 min)              â”‚  VM VM VM VM VM     â”‚
VMs listas                     â”‚  (pre-aprovisionadas)â”‚
      â†“                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Cluster listo                           â†“
                                Crear cluster
Total: 3-8 min                         â†“ (30 seg)
                                Cluster listo
                               
                               Total: 30-60 seg
\`\`\`

### Crear un Pool

\`\`\`json
{
  "instance_pool_name": "Data Engineering Pool",
  "node_type_id": "i3.xlarge",
  "min_idle_instances": 2,
  "max_capacity": 20,
  "idle_instance_autotermination_minutes": 30
}
\`\`\``,
        en: `## Cluster Policies: Enterprise Governance

Cluster Policies let admins **control and standardize** cluster creation.

\`\`\`json
{
  "name": "Standard Policy",
  "definition": {
    "autoscale.max_workers": {
      "type": "range",
      "maxValue": 10
    },
    "autotermination_minutes": {
      "type": "fixed",
      "value": 30
    }
  }
}
\`\`\`

### Key Benefits
- Cost control
- Security compliance
- Standardized configurations`,
        pt: `## Cluster Policies: GovernanÃ§a Empresarial

Cluster Policies permitem aos admins **controlar e padronizar** a criaÃ§Ã£o de clusters.

\`\`\`json
{
  "name": "Policy PadrÃ£o",
  "definition": {
    "autoscale.max_workers": {
      "type": "range",
      "maxValue": 10
    }
  }
}
\`\`\``
      },
      practicalTips: [
        { es: 'ğŸ’° Las policies son ESENCIALES para controlar costos en empresas grandes.', en: 'ğŸ’° Policies are ESSENTIAL for cost control in large enterprises.', pt: 'ğŸ’° Policies sÃ£o ESSENCIAIS para controle de custos em grandes empresas.' },
        { es: 'ğŸ”’ Usa "fixed" + "hidden" para configuraciones que los usuarios no deben cambiar.', en: 'ğŸ”’ Use "fixed" + "hidden" for settings users should not change.', pt: 'ğŸ”’ Use "fixed" + "hidden" para configuraÃ§Ãµes que os usuÃ¡rios nÃ£o devem alterar.' },
        { es: 'âš¡ Instance Pools + Policies = clusters rÃ¡pidos y controlados.', en: 'âš¡ Instance Pools + Policies = fast and controlled clusters.', pt: 'âš¡ Instance Pools + Policies = clusters rÃ¡pidos e controlados.' }
      ],
      externalLinks: [
        { title: 'Cluster Policies', url: 'https://docs.databricks.com/administration-guide/clusters/policies.html', type: 'docs' },
        { title: 'Instance Pools', url: 'https://docs.databricks.com/clusters/instance-pools/index.html', type: 'docs' }
      ],
      checkpoint: {
        es: 'âœ… Â¿SabÃ©s quÃ© restricciones pondrÃ­as en una policy de desarrollo vs producciÃ³n?',
        en: 'âœ… Do you know what restrictions you would put in a dev vs production policy?',
        pt: 'âœ… VocÃª sabe quais restriÃ§Ãµes colocaria em uma policy de dev vs produÃ§Ã£o?'
      },
      xpReward: 25,
      estimatedMinutes: 25
    },
    {
      id: 'db-2-9',
      title: {
        es: 'Quiz: Arquitectura de Databricks',
        en: 'Quiz: Databricks Architecture',
        pt: 'Quiz: Arquitetura do Databricks'
      },
      description: {
        es: 'PonÃ© a prueba lo que aprendiste sobre la arquitectura.',
        en: 'Test what you learned about architecture.',
        pt: 'Teste o que vocÃª aprendeu sobre arquitetura.'
      },
      theory: {
        es: `## ğŸ“ Quiz de Arquitectura

RespondÃ© estas preguntas para verificar tu comprensiÃ³n:

### Pregunta 1:
Â¿DÃ³nde corren tus clusters de Databricks?
- a) En servidores de Databricks
- b) En tu cuenta de cloud (AWS/Azure/GCP)
- c) En ambos

### Pregunta 2:
Â¿QuÃ© pasa cuando hacÃ©s DROP TABLE en una managed table?
- a) Solo se borra la metadata
- b) Se borran los datos y la metadata
- c) Se mueven los datos a backup

### Pregunta 3:
Â¿QuÃ© tipo de cluster usarÃ­as para un job de producciÃ³n schedulado?
- a) All-Purpose cluster
- b) Job cluster
- c) Cualquiera da igual

### Pregunta 4:
Photon Engine es mÃ¡s rÃ¡pido porque:
- a) Usa mÃ¡s memoria
- b) EstÃ¡ escrito en C++ con ejecuciÃ³n vectorizada
- c) Usa GPUs

### Pregunta 5:
Â¿CuÃ¡l es el orden correcto de la jerarquÃ­a de datos en Unity Catalog?
- a) Schema > Catalog > Table
- b) Catalog > Schema > Table
- c) Table > Schema > Catalog

---

### Respuestas:
1. b) En tu cuenta de cloud
2. b) Se borran datos y metadata
3. b) Job cluster (mÃ¡s barato)
4. b) C++ con ejecuciÃ³n vectorizada
5. b) Catalog > Schema > Table

### Â¿CuÃ¡ntas acertaste?
- 5/5: ğŸ† Excelente! EntendÃ©s la arquitectura
- 3-4/5: ğŸ‘ Bien, repasÃ¡ los puntos que fallaste
- 0-2/5: ğŸ“š VolvÃ© a leer la fase antes de continuar`,
        en: `## ğŸ“ Architecture Quiz

Answer these questions to verify your understanding:

### Question 1:
Where do your Databricks clusters run?
- a) On Databricks servers
- b) In your cloud account (AWS/Azure/GCP)
- c) In both

### Question 2:
What happens when you DROP TABLE on a managed table?
- a) Only metadata is deleted
- b) Data and metadata are deleted
- c) Data is moved to backup

### Question 3:
What cluster type would you use for a scheduled production job?
- a) All-Purpose cluster
- b) Job cluster
- c) Either one is fine

### Question 4:
Photon Engine is faster because:
- a) It uses more memory
- b) It's written in C++ with vectorized execution
- c) It uses GPUs

### Question 5:
What's the correct order of data hierarchy in Unity Catalog?
- a) Schema > Catalog > Table
- b) Catalog > Schema > Table
- c) Table > Schema > Catalog

---

### Answers:
1. b) In your cloud account
2. b) Data and metadata are deleted
3. b) Job cluster (cheaper)
4. b) C++ with vectorized execution
5. b) Catalog > Schema > Table

### How many did you get right?
- 5/5: ğŸ† Excellent! You understand the architecture
- 3-4/5: ğŸ‘ Good, review the points you missed
- 0-2/5: ğŸ“š Re-read the phase before continuing`,
        pt: `## ğŸ“ Quiz de Arquitetura

Responda estas perguntas para verificar sua compreensÃ£o:

### Pergunta 1:
Onde seus clusters do Databricks rodam?
- a) Em servidores do Databricks
- b) Na sua conta de cloud (AWS/Azure/GCP)
- c) Em ambos

### Pergunta 2:
O que acontece quando vocÃª faz DROP TABLE em uma managed table?
- a) SÃ³ a metadata Ã© deletada
- b) Os dados e a metadata sÃ£o deletados
- c) Os dados sÃ£o movidos para backup

### Pergunta 3:
Que tipo de cluster vocÃª usaria para um job de produÃ§Ã£o schedulado?
- a) All-Purpose cluster
- b) Job cluster
- c) Qualquer um serve

### Pergunta 4:
Photon Engine Ã© mais rÃ¡pido porque:
- a) Usa mais memÃ³ria
- b) Ã‰ escrito em C++ com execuÃ§Ã£o vetorizada
- c) Usa GPUs

### Pergunta 5:
Qual Ã© a ordem correta da hierarquia de dados no Unity Catalog?
- a) Schema > Catalog > Table
- b) Catalog > Schema > Table
- c) Table > Schema > Catalog

---

### Respostas:
1. b) Na sua conta de cloud
2. b) Dados e metadata sÃ£o deletados
3. b) Job cluster (mais barato)
4. b) C++ com execuÃ§Ã£o vetorizada
5. b) Catalog > Schema > Table

### Quantas vocÃª acertou?
- 5/5: ğŸ† Excelente! VocÃª entende a arquitetura
- 3-4/5: ğŸ‘ Bom, revise os pontos que errou
- 0-2/5: ğŸ“š Releia a fase antes de continuar`
      },
      practicalTips: [
        {
          es: 'ğŸ“ Estas preguntas son similares a las del examen de certificaciÃ³n.',
          en: 'ğŸ“ These questions are similar to certification exam questions.',
          pt: 'ğŸ“ Estas perguntas sÃ£o similares Ã s do exame de certificaÃ§Ã£o.'
        }
      ],
      externalLinks: [
        {
          title: 'Databricks Certification Prep',
          url: 'https://www.databricks.com/learn/certification',
          type: 'article'
        }
      ],
      checkpoint: {
        es: 'ğŸ† Â¿Acertaste 4 o mÃ¡s? Si no, repasÃ¡ antes de seguir.',
        en: 'ğŸ† Did you get 4 or more right? If not, review before continuing.',
        pt: 'ğŸ† VocÃª acertou 4 ou mais? Se nÃ£o, revise antes de continuar.'
      },
      xpReward: 30,
      estimatedMinutes: 15
    }
  ]
};


