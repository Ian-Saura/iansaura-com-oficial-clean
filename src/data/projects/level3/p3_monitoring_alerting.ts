import { Project } from '../../../types/members';

export const p3MonitoringAlerting: Project = {
  id: 'p3-monitoring-alerting',
  level: 3,
  title: {
    es: 'Monitoring y Alertas para Pipelines',
    pt: 'Monitoramento e Alertas para Pipelines'
  },
  description: {
    es: 'ImplementÃ¡ observabilidad completa. Un Senior sabe cuando algo falla ANTES de que el usuario lo reporte.',
    pt: 'Implemente observabilidade completa. Um SÃªnior sabe quando algo falha ANTES que o usuÃ¡rio reporte.'
  },
  difficulty: 'Expert',
  duration: '5-6 horas',
  skills: [
    { es: 'Monitoring', pt: 'Monitoramento' },
    { es: 'Prometheus', pt: 'Prometheus' },
    { es: 'Grafana', pt: 'Grafana' },
    { es: 'Alerting', pt: 'Alertas' },
    { es: 'Observability', pt: 'Observabilidade' }
  ],
  icon: 'ğŸ“Š',
  color: 'purple',
  prerequisites: ['p6-airflow-orchestration', 'p7-data-quality'],
  estimatedLines: 150,
  realWorldExample: {
    es: 'AsÃ­ monitorea el equipo de Data Platform de Netflix sus pipelines',
    pt: 'Assim a equipe de Data Platform da Netflix monitora seus pipelines'
  },
  usedBy: ['Netflix', 'Datadog', 'Grafana Labs', 'New Relic'],
  expectedOutputs: [
    {
      step: 4,
      description: { es: 'Dashboard de Grafana', pt: 'Dashboard do Grafana' },
      example: `â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ETL Pipeline Dashboard                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Throughput   â”‚ Error Rate   â”‚ Latency   â”‚
â”‚ 1.2K/s  â†‘5%  â”‚ 0.02%   âœ“    â”‚ p99: 2.3s â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [Graph: Records/sec over 24h]           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Active Alerts: 0  â”‚  Last run: 2m ago   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
    },
  ],
  learningObjectives: [
    { es: 'Definir mÃ©tricas clave (SLIs/SLOs)', pt: 'Definir mÃ©tricas chave (SLIs/SLOs)' },
    { es: 'Instrumentar cÃ³digo con mÃ©tricas', pt: 'Instrumentar cÃ³digo com mÃ©tricas' },
    { es: 'Crear dashboards informativos', pt: 'Criar dashboards informativos' },
    { es: 'Configurar alertas accionables', pt: 'Configurar alertas acionÃ¡veis' },
    { es: 'Escribir runbooks para incidentes', pt: 'Escrever runbooks para incidentes' },
  ],
  interviewStory: {
    hook: {
      es: "ImplementÃ© observabilidad completa que redujo el tiempo de detecciÃ³n de incidentes de 4 horas a 2 minutos.",
      pt: "Implementei observabilidade completa que reduziu o tempo de detecÃ§Ã£o de incidentes de 4 horas para 2 minutos."
    },
    situation: {
      es: "Los pipelines fallaban y nadie se enteraba hasta que el equipo de negocio preguntaba por quÃ© los dashboards estaban vacÃ­os. No habÃ­a monitoreo.",
      pt: "Os pipelines falhavam e ninguÃ©m ficava sabendo atÃ© que a equipe de negÃ³cios perguntasse por que os dashboards estavam vazios. NÃ£o havia monitoramento."
    },
    task: {
      es: "Implementar observabilidad end-to-end: mÃ©tricas, dashboards, alertas y runbooks.",
      pt: "Implementar observabilidade end-to-end: mÃ©tricas, dashboards, alertas e runbooks."
    },
    actions: [
      { es: "DefinÃ­ SLIs/SLOs con el equipo de producto (latencia <5min, error rate <0.1%)", pt: "Defini SLIs/SLOs com a equipe de produto (latÃªncia <5min, taxa de erro <0.1%)" },
      { es: "InstrumentÃ© pipelines con Prometheus: throughput, latencia, errores", pt: "Instrumentei pipelines com Prometheus: throughput, latÃªncia, erros" },
      { es: "CreÃ© dashboards en Grafana con las mÃ©tricas mÃ¡s importantes", pt: "Criei dashboards no Grafana com as mÃ©tricas mais importantes" },
      { es: "ConfigurÃ© alertas con PagerDuty: crÃ­ticas despiertan, warnings esperan", pt: "Configurei alertas com PagerDuty: crÃ­ticas acordam, warnings esperam" },
      { es: "EscribÃ­ runbooks para cada alerta con pasos de diagnÃ³stico y resoluciÃ³n", pt: "Escrevi runbooks para cada alerta com passos de diagnÃ³stico e resoluÃ§Ã£o" }
    ],
    results: [
      { es: "Tiempo de detecciÃ³n: de 4 horas a 2 minutos", pt: "Tempo de detecÃ§Ã£o: de 4 horas para 2 minutos" },
      { es: "MTTR (tiempo de resoluciÃ³n): de 2 horas a 15 minutos con runbooks", pt: "MTTR (tempo de resoluÃ§Ã£o): de 2 horas para 15 minutos com runbooks" },
      { es: "SLO de 99.9% cumplido por 6 meses consecutivos", pt: "SLO de 99.9% cumprido por 6 meses consecutivos" },
      { es: "El equipo de negocio confÃ­a en que los datos estÃ¡n frescos", pt: "A equipe de negÃ³cios confia que os dados estÃ£o frescos" }
    ],
    learnings: [
      { es: "Las alertas deben ser accionables - si no sabÃ©s quÃ© hacer, no alertes", pt: "Os alertas devem ser acionÃ¡veis - se nÃ£o sabe o que fazer, nÃ£o alerte" },
      { es: "Menos mÃ©tricas es mÃ¡s - 5 mÃ©tricas bien elegidas > 50 mÃ©tricas random", pt: "Menos mÃ©tricas Ã© mais - 5 mÃ©tricas bem escolhidas > 50 mÃ©tricas aleatÃ³rias" },
      { es: "Los runbooks se escriben ANTES del incidente, no durante", pt: "Os runbooks sÃ£o escritos ANTES do incidente, nÃ£o durante" }
    ],
    possibleQuestions: [
      {
        question: { es: "Â¿QuÃ© mÃ©tricas monitoreas para un pipeline de datos?", pt: "Quais mÃ©tricas vocÃª monitora para um pipeline de dados?" },
        answer: { es: "Los 4 golden signals: latencia (p50, p99), throughput (records/sec), error rate, y data freshness. EspecÃ­fico de data: data quality score y schema drift.", pt: "Os 4 golden signals: latÃªncia (p50, p99), throughput (registros/seg), taxa de erro, e data freshness. EspecÃ­fico de data: pontuaÃ§Ã£o de qualidade de dados e schema drift." }
      },
      {
        question: { es: "Â¿CÃ³mo evitÃ¡s alert fatigue?", pt: "Como vocÃª evita a fadiga de alertas?" },
        answer: { es: "1) Solo alertas accionables, 2) Agregar delays para evitar flapping, 3) Diferentes severidades (crÃ­tico despierta, warning espera), 4) Revisar y eliminar alertas inÃºtiles.", pt: "1) Apenas alertas acionÃ¡veis, 2) Adicionar delays para evitar flapping, 3) Diferentes severidades (crÃ­tico acorda, warning espera), 4) Revisar e eliminar alertas inÃºteis." }
      },
      {
        question: { es: "Â¿QuÃ© es un SLO y cÃ³mo lo definÃ­s?", pt: "O que Ã© um SLO e como vocÃª o define?" },
        answer: { es: "SLO = objetivo de nivel de servicio. Lo defino con el negocio: '99.9% de los datos disponibles en <5 minutos'. El SLI es la mÃ©trica que mido, el SLO es el objetivo.", pt: "SLO = objetivo de nÃ­vel de serviÃ§o. Defino com o negÃ³cio: '99.9% dos dados disponÃ­veis em <5 minutos'. O SLI Ã© a mÃ©trica que meÃ§o, o SLO Ã© o objetivo." }
      }
    ],
    closingStatement: { es: "Sin observabilidad, estÃ¡s volando a ciegas. Es lo primero que implemento en cualquier sistema.", pt: "Sem observabilidade, vocÃª estÃ¡ voando Ã s cegas. Ã‰ a primeira coisa que implemento em qualquer sistema." }
  },
  steps: [
    {
      order: 1,
      text: { es: 'ğŸ“Š DefinÃ­ mÃ©tricas clave', pt: 'ğŸ“Š Defina mÃ©tricas chave' },
      explanation: {
        es: `**SLIs (Service Level Indicators):**
- **Latencia**: Â¿CuÃ¡nto tarda el pipeline?
- **Throughput**: Â¿CuÃ¡ntos registros/segundo?
- **Error Rate**: Â¿QuÃ© % falla?
- **Data Freshness**: Â¿QuÃ© tan actualizados estÃ¡n los datos?

**SLOs (Service Level Objectives):**
- Latencia p99 < 5 minutos
- Error rate < 1%
- Data freshness < 1 hora
- Disponibilidad > 99.9%`,
        pt: `**SLIs (Service Level Indicators):**
- **LatÃªncia**: Quanto demora o pipeline?
- **Throughput**: Quantos registros/segundo?
- **Taxa de Erro**: Qual % falha?
- **Data Freshness**: QuÃ£o atualizados estÃ£o os dados?

**SLOs (Service Level Objectives):**
- LatÃªncia p99 < 5 minutos
- Taxa de erro < 1%
- Data freshness < 1 hora
- Disponibilidade > 99.9%`
      },
      checkpoint: { es: 'Â¿Definiste SLIs y SLOs para tu pipeline?', pt: 'Definiu SLIs e SLOs para seu pipeline?' }
    },
    {
      order: 2,
      text: { es: 'ğŸ³ LevantÃ¡ Prometheus + Grafana', pt: 'ğŸ³ Levante Prometheus + Grafana' },
      code: `# docker-compose.yml
version: '3.8'
services:
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin`,
      explanation: { es: 'Prometheus recolecta mÃ©tricas, Grafana las visualiza.', pt: 'Prometheus coleta mÃ©tricas, Grafana as visualiza.' },
      checkpoint: { es: 'Â¿PodÃ©s acceder a Grafana en http://localhost:3000?', pt: 'Consegue acessar Grafana em http://localhost:3000?' }
    },
    {
      order: 3,
      text: { es: 'ğŸ“ˆ InstrumentÃ¡ tu pipeline', pt: 'ğŸ“ˆ Instrumente seu pipeline' },
      code: `# metrics.py
from prometheus_client import Counter, Histogram, Gauge, start_http_server

# MÃ©tricas
RECORDS_PROCESSED = Counter(
    'pipeline_records_processed_total',
    'Total records processed',
    ['pipeline', 'status']
)

PROCESSING_TIME = Histogram(
    'pipeline_processing_seconds',
    'Time spent processing',
    ['pipeline'],
    buckets=[1, 5, 10, 30, 60, 120, 300]
)

DATA_FRESHNESS = Gauge(
    'pipeline_data_freshness_seconds',
    'Seconds since last data update',
    ['pipeline']
)

# Usar en el cÃ³digo
def process_batch(records):
    with PROCESSING_TIME.labels(pipeline='etl').time():
        for record in records:
            try:
                process(record)
                RECORDS_PROCESSED.labels(pipeline='etl', status='success').inc()
            except Exception as e:
                RECORDS_PROCESSED.labels(pipeline='etl', status='error').inc()
                raise`,
      explanation: { es: 'prometheus_client expone mÃ©tricas que Prometheus recolecta.', pt: 'prometheus_client expÃµe mÃ©tricas que Prometheus coleta.' },
      tip: { es: 'UsÃ¡ labels para segmentar mÃ©tricas (por pipeline, por status, etc).', pt: 'Use labels para segmentar mÃ©tricas (por pipeline, por status, etc).' }
    },
    {
      order: 4,
      text: { es: 'ğŸ“Š CreÃ¡ dashboard en Grafana', pt: 'ğŸ“Š Crie dashboard no Grafana' },
      explanation: {
        es: `CreÃ¡ un dashboard con:

**Panel 1: Throughput**
- Query: rate(pipeline_records_processed_total[5m])
- Tipo: Graph

**Panel 2: Error Rate**
- Query: rate(pipeline_records_processed_total{status="error"}[5m]) / rate(pipeline_records_processed_total[5m])
- Tipo: Gauge

**Panel 3: Latencia (p99)**
- Query: histogram_quantile(0.99, rate(pipeline_processing_seconds_bucket[5m]))
- Tipo: Graph

**Panel 4: Data Freshness**
- Query: pipeline_data_freshness_seconds
- Tipo: Stat`,
        pt: `Crie um dashboard com:

**Painel 1: Throughput**
- Query: rate(pipeline_records_processed_total[5m])
- Tipo: Graph

**Painel 2: Taxa de Erro**
- Query: rate(pipeline_records_processed_total{status="error"}[5m]) / rate(pipeline_records_processed_total[5m])
- Tipo: Gauge

**Painel 3: LatÃªncia (p99)**
- Query: histogram_quantile(0.99, rate(pipeline_processing_seconds_bucket[5m]))
- Tipo: Graph

**Painel 4: Data Freshness**
- Query: pipeline_data_freshness_seconds
- Tipo: Stat`
      },
      checkpoint: { es: 'Â¿Tu dashboard muestra las 4 mÃ©tricas clave?', pt: 'Seu dashboard mostra as 4 mÃ©tricas chave?' }
    },
    {
      order: 5,
      text: { es: 'ğŸ”” ConfigurÃ¡ alertas', pt: 'ğŸ”” Configure alertas' },
      code: `# alerting_rules.yml
groups:
  - name: pipeline_alerts
    rules:
      - alert: HighErrorRate
        expr: rate(pipeline_records_processed_total{status="error"}[5m]) / rate(pipeline_records_processed_total[5m]) > 0.01
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate in pipeline"
          description: "Error rate is {{ $value | humanizePercentage }}"
      
      - alert: DataStale
        expr: pipeline_data_freshness_seconds > 3600
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Data is stale"
          description: "Data is {{ $value | humanizeDuration }} old"`,
      explanation: { es: 'Las alertas deben ser accionables. Si no sabÃ©s quÃ© hacer cuando suena, no sirve.', pt: 'Os alertas devem ser acionÃ¡veis. Se nÃ£o sabe o que fazer quando toca, nÃ£o serve.' },
      tip: { es: 'UsÃ¡ "for: 5m" para evitar alertas por picos momentÃ¡neos.', pt: 'Use "for: 5m" para evitar alertas por picos momentÃ¢neos.' }
    },
    {
      order: 6,
      text: { es: 'ğŸ“ ImplementÃ¡ logging estructurado', pt: 'ğŸ“ Implemente logging estruturado' },
      code: `import logging
import json
from datetime import datetime

class StructuredLogger:
    def __init__(self, name: str):
        self.logger = logging.getLogger(name)
        self.logger.setLevel(logging.INFO)
        handler = logging.StreamHandler()
        handler.setFormatter(logging.Formatter('%(message)s'))
        self.logger.addHandler(handler)
    
    def log(self, level: str, message: str, **kwargs):
        log_entry = {
            'timestamp': datetime.utcnow().isoformat(),
            'level': level,
            'message': message,
            **kwargs
        }
        self.logger.info(json.dumps(log_entry))

# Uso
logger = StructuredLogger('pipeline')
logger.log('INFO', 'Processing batch', batch_id=123, records=1000)
logger.log('ERROR', 'Failed to process', batch_id=123, error='Connection timeout')`,
      explanation: { es: 'Logs estructurados (JSON) son mÃ¡s fÃ¡ciles de buscar y analizar.', pt: 'Logs estruturados (JSON) sÃ£o mais fÃ¡ceis de buscar e analisar.' }
    },
    {
      order: 7,
      text: { es: 'ğŸ“š EscribÃ­ runbooks', pt: 'ğŸ“š Escreva runbooks' },
      code: `# Runbook: HighErrorRate Alert

## DescripciÃ³n
El pipeline tiene error rate > 1% por mÃ¡s de 5 minutos.

## Impacto
Datos no se procesan correctamente. Dashboards pueden mostrar datos incompletos.

## DiagnÃ³stico
1. Ver logs del pipeline: \`kubectl logs -l app=pipeline\`
2. Buscar errores especÃ­ficos: \`grep "ERROR" logs | tail -50\`
3. Verificar dependencias (API, DB): \`curl health-check-url\`

## ResoluciÃ³n

### Si es error de conexiÃ³n a API
1. Verificar status de la API externa
2. Si estÃ¡ caÃ­da, esperar o escalar

### Si es error de datos
1. Identificar registros problemÃ¡ticos
2. Filtrarlos temporalmente
3. Crear ticket para fix

### Si es error de memoria
1. Verificar uso de memoria: \`kubectl top pods\`
2. Escalar si es necesario: \`kubectl scale deployment pipeline --replicas=3\`

## EscalaciÃ³n
Si no se resuelve en 30 min, escalar a @data-platform-oncall`,
      explanation: { es: 'Un runbook dice exactamente quÃ© hacer cuando suena una alerta.', pt: 'Um runbook diz exatamente o que fazer quando toca um alerta.' },
      checkpoint: { es: 'Â¿Tus runbooks son claros y accionables?', pt: 'Seus runbooks sÃ£o claros e acionÃ¡veis?' }
    },
  ],
  deliverable: { es: 'docker-compose + cÃ³digo instrumentado + dashboards + runbooks', pt: 'docker-compose + cÃ³digo instrumentado + dashboards + runbooks' },
  evaluation: [
    { es: 'Â¿Las mÃ©tricas cubren los casos crÃ­ticos?', pt: 'As mÃ©tricas cobrem os casos crÃ­ticos?' },
    { es: 'Â¿Las alertas son accionables?', pt: 'Os alertas sÃ£o acionÃ¡veis?' },
    { es: 'Â¿Los dashboards muestran el estado del sistema?', pt: 'Os dashboards mostram o estado do sistema?' },
    { es: 'Â¿Los runbooks son claros?', pt: 'Os runbooks sÃ£o claros?' },
    { es: 'Â¿Los logs son estructurados y buscables?', pt: 'Os logs sÃ£o estruturados e buscÃ¡veis?' },
  ],
  theory: {
    es: `## Los 3 Pilares de Observabilidad

### 1. Logs
- QuÃ© pasÃ³ (texto)
- Estructurados (JSON) para bÃºsqueda
- Niveles: DEBUG, INFO, WARN, ERROR

### 2. Metrics
- CuÃ¡nto/cuÃ¡ndo (nÃºmeros)
- Agregables (promedios, percentiles)
- Tipos: Counter, Gauge, Histogram

### 3. Traces
- CÃ³mo fluyÃ³ (request path)
- Distribuidos (entre servicios)
- Ãštil para debugging

## MÃ©tricas Clave para Pipelines

| MÃ©trica | Tipo | QuÃ© mide |
|---------|------|----------|
| Throughput | Counter | Registros/segundo |
| Latency | Histogram | Tiempo de procesamiento |
| Error Rate | Counter | % de errores |
| Data Freshness | Gauge | Edad de los datos |

## Alertas Efectivas

âœ… Accionables: SabÃ©s quÃ© hacer
âœ… EspecÃ­ficas: Dicen quÃ© estÃ¡ mal
âœ… Con contexto: Links a dashboards/runbooks

âŒ Ruidosas: Suenan sin ser problema
âŒ Vagas: "Algo estÃ¡ mal"
âŒ Sin runbook: No sabÃ©s quÃ© hacer`,
    pt: `## Os 3 Pilares da Observabilidade

### 1. Logs
- O que aconteceu (texto)
- Estruturados (JSON) para busca
- NÃ­veis: DEBUG, INFO, WARN, ERROR

### 2. Metrics
- Quanto/quando (nÃºmeros)
- AgregÃ¡veis (mÃ©dias, percentis)
- Tipos: Counter, Gauge, Histogram

### 3. Traces
- Como fluiu (request path)
- DistribuÃ­dos (entre serviÃ§os)
- Ãštil para debugging

## MÃ©tricas Chave para Pipelines

| MÃ©trica | Tipo | O que mede |
|---------|------|----------|
| Throughput | Counter | Registros/segundo |
| LatÃªncia | Histogram | Tempo de processamento |
| Taxa de Erro | Counter | % de erros |
| Data Freshness | Gauge | Idade dos dados |

## Alertas Efetivos

âœ… AcionÃ¡veis: Sabe o que fazer
âœ… EspecÃ­ficos: Dizem o que estÃ¡ errado
âœ… Com contexto: Links para dashboards/runbooks

âŒ Ruidosos: Tocam sem ser problema
âŒ Vagos: "Algo estÃ¡ errado"
âŒ Sem runbook: NÃ£o sabe o que fazer`
  },
};


