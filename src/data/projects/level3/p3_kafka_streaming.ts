import { Project } from '../../../types/members';

export const p3KafkaStreaming: Project = {
  id: 'p3-kafka-streaming',
  level: 3,
  title: {
    es: 'Pipeline de Streaming con Apache Kafka',
    pt: 'Pipeline de Streaming com Apache Kafka'
  },
  description: {
    es: 'Constru√≠ un pipeline de streaming real que procesa eventos en tiempo real. Kafka es el est√°ndar de la industria para streaming.',
    pt: 'Construa um pipeline de streaming real que processa eventos em tempo real. Kafka √© o padr√£o da ind√∫stria para streaming.'
  },
  difficulty: 'Expert',
  duration: '6-8 horas',
  skills: [
    { es: 'Kafka', pt: 'Kafka' },
    { es: 'Python', pt: 'Python' },
    { es: 'Streaming', pt: 'Streaming' },
    { es: 'Docker', pt: 'Docker' },
    { es: 'Real-time Processing', pt: 'Processamento em Tempo Real' }
  ],
  icon: 'üì°',
  color: 'orange',
  datasetId: 'iot',
  estimatedLines: 200,
  realWorldExample: {
    es: 'As√≠ procesa LinkedIn billones de mensajes por d√≠a con Kafka',
    pt: 'Assim o LinkedIn processa bilh√µes de mensagens por dia com Kafka'
  },
  usedBy: ['LinkedIn', 'Uber', 'Netflix', 'Airbnb', 'Confluent'],
  expectedOutputs: [
    {
      step: 5,
      description: { es: 'Consumer procesando eventos', pt: 'Consumer processando eventos' },
      example: `Starting consumer...
Device device_42: avg_temp=24.35¬∞C (n=15)
Device device_17: avg_temp=22.80¬∞C (n=12)
Device device_89: avg_temp=26.10¬∞C (n=8)
...
Processed 1000 events in 10 seconds
Throughput: 100 events/second`
    },
  ],
  learningObjectives: [
    { es: 'Entender arquitectura de Kafka (topics, partitions, consumer groups)', pt: 'Entender arquitetura do Kafka (topics, partitions, consumer groups)' },
    { es: 'Implementar producers y consumers', pt: 'Implementar producers e consumers' },
    { es: 'Manejar offsets correctamente', pt: 'Lidar com offsets corretamente' },
    { es: 'Procesar en ventanas de tiempo', pt: 'Processar em janelas de tempo' },
    { es: 'Garantizar procesamiento sin p√©rdida', pt: 'Garantir processamento sem perda' },
  ],
  interviewStory: {
    hook: {
      es: "Implement√© Kafka para procesar 1 mill√≥n de eventos por minuto con latencia sub-segundo y cero p√©rdida de datos.",
      pt: "Implementei Kafka para processar 1 milh√£o de eventos por minuto com lat√™ncia sub-segundo e zero perda de dados."
    },
    situation: {
      es: "El sistema de batch procesaba eventos con 24 horas de delay. El negocio necesitaba reaccionar en tiempo real a comportamiento de usuarios.",
      pt: "O sistema de batch processava eventos com 24 horas de delay. O neg√≥cio precisava reagir em tempo real ao comportamento dos usu√°rios."
    },
    task: {
      es: "Migrar de batch a streaming con Kafka para procesamiento en tiempo real.",
      pt: "Migrar de batch para streaming com Kafka para processamento em tempo real."
    },
    actions: [
      { es: "Dise√±√© la arquitectura: topics por tipo de evento, particiones por user_id", pt: "Projetei a arquitetura: topics por tipo de evento, particiones por user_id" },
      { es: "Implement√© producers con acknowledgments para garantizar entrega", pt: "Implementei producers com acknowledgments para garantir entrega" },
      { es: "Cre√© consumer groups para procesamiento paralelo y fault-tolerant", pt: "Criei consumer groups para processamento paralelo e fault-tolerant" },
      { es: "Implement√© exactly-once semantics con transacciones de Kafka", pt: "Implementei exactly-once semantics com transa√ß√µes do Kafka" },
      { es: "Agregu√© monitoreo con m√©tricas de lag y throughput", pt: "Adicionei monitoramento com m√©tricas de lag e throughput" }
    ],
    results: [
      { es: "Latencia: de 24 horas a <1 segundo", pt: "Lat√™ncia: de 24 horas para <1 segundo" },
      { es: "Throughput: 1M eventos/minuto sin problemas", pt: "Throughput: 1M eventos/minuto sem problemas" },
      { es: "Cero p√©rdida de datos gracias a replicaci√≥n y acks", pt: "Zero perda de dados gra√ßas a replica√ß√£o e acks" },
      { es: "El equipo de producto puede reaccionar en tiempo real", pt: "A equipe de produto pode reagir em tempo real" }
    ],
    learnings: [
      { es: "El particionamiento es cr√≠tico - mal particionado = hotspots", pt: "O particionamento √© cr√≠tico - mal particionado = hotspots" },
      { es: "Consumer lag es LA m√©trica a monitorear", pt: "Consumer lag √© A m√©trica a monitorar" },
      { es: "Exactly-once es posible pero tiene costo de performance", pt: "Exactly-once √© poss√≠vel mas tem custo de performance" }
    ],
    possibleQuestions: [
      {
        question: { es: "¬øC√≥mo garantiz√°s que no se pierdan mensajes?", pt: "Como voc√™ garante que n√£o se percam mensagens?" },
        answer: { es: "Tres niveles: 1) acks=all en producer, 2) replication.factor=3, 3) min.insync.replicas=2. Si un broker cae, los otros tienen la copia.", pt: "Tr√™s n√≠veis: 1) acks=all no producer, 2) replication.factor=3, 3) min.insync.replicas=2. Se um broker cair, os outros t√™m a c√≥pia." }
      },
      {
        question: { es: "¬øQu√© pasa si un consumer se cae?", pt: "O que acontece se um consumer cair?" },
        answer: { es: "El consumer group rebalancea y otro consumer toma sus particiones. El offset est√° guardado en Kafka, as√≠ que retoma desde donde qued√≥.", pt: "O consumer group rebalanceia e outro consumer toma suas particiones. O offset est√° guardado no Kafka, ent√£o retoma de onde parou." }
      },
      {
        question: { es: "¬øCu√°ntas particiones deber√≠a tener un topic?", pt: "Quantas particiones deveria ter um topic?" },
        answer: { es: "Regla general: particiones >= n√∫mero de consumers. M√°s particiones = m√°s paralelismo pero m√°s overhead. Empiezo con 10-20 y ajusto seg√∫n throughput.", pt: "Regra geral: particiones >= n√∫mero de consumers. Mais particiones = mais paralelismo mas mais overhead. Come√ßo com 10-20 e ajusto segundo throughput." }
      }
    ],
    closingStatement: { es: "Kafka es el backbone de cualquier arquitectura de datos moderna - dominarlo es esencial.", pt: "Kafka √© o backbone de qualquer arquitetura de dados moderna - domin√°-lo √© essencial." }
  },
  prerequisites: ['p2-streaming-basics'],
  steps: [
    {
      order: 1,
      text: { es: 'üìñ Entend√© conceptos de Kafka', pt: 'üìñ Entenda conceitos de Kafka' },
      explanation: {
        es: `**Topic**: Canal donde se publican mensajes (ej: "iot-events")
**Partition**: Divisi√≥n del topic para paralelismo
**Producer**: Env√≠a mensajes a topics
**Consumer**: Lee mensajes de topics
**Consumer Group**: Grupo de consumers que comparten la carga
**Offset**: Posici√≥n del consumer en el topic`,
        pt: `**Topic**: Canal onde se publicam mensagens (ex: "iot-events")
**Partition**: Divis√£o do topic para paralelismo
**Producer**: Envia mensagens para topics
**Consumer**: L√™ mensagens de topics
**Consumer Group**: Grupo de consumers que compartilham a carga
**Offset**: Posi√ß√£o do consumer no topic`
      },
      checkpoint: { es: '¬øPod√©s explicar qu√© es un consumer group?', pt: 'Pode explicar o que √© um consumer group?' }
    },
    {
      order: 2,
      text: { es: 'üê≥ Levant√° Kafka con Docker', pt: 'üê≥ Levante Kafka com Docker' },
      code: `# docker-compose.yml
version: '3.8'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092`,
      explanation: { es: 'Kafka UI te permite ver topics, mensajes, y consumer groups visualmente.', pt: 'Kafka UI permite ver topics, mensagens, e consumer groups visualmente.' },
      checkpoint: { es: '¬øPod√©s acceder a Kafka UI en http://localhost:8080?', pt: 'Consegue acessar Kafka UI em http://localhost:8080?' }
    },
    {
      order: 3,
      text: { es: 'üìù Cre√° el topic', pt: 'üìù Crie o topic' },
      code: `# Instalar kafka-python
pip install kafka-python

# Crear topic desde Python
from kafka.admin import KafkaAdminClient, NewTopic

admin = KafkaAdminClient(bootstrap_servers='localhost:9092')

topic = NewTopic(
    name='iot-events',
    num_partitions=3,
    replication_factor=1
)

admin.create_topics([topic])
print("Topic creado!")`,
      explanation: { es: '3 particiones permiten 3 consumers en paralelo.', pt: '3 particiones permitem 3 consumers em paralelo.' },
      tip: { es: 'En producci√≥n, usar√≠as m√°s particiones y replication_factor > 1.', pt: 'Em produ√ß√£o, usaria mais particiones e replication_factor > 1.' }
    },
    {
      order: 4,
      text: { es: 'üì§ Implement√° el Producer', pt: 'üì§ Implemente o Producer' },
      code: `# producer.py
import json
import time
import random
from datetime import datetime
from kafka import KafkaProducer

producer = KafkaProducer(
    bootstrap_servers='localhost:9092',
    value_serializer=lambda v: json.dumps(v).encode('utf-8'),
    key_serializer=lambda k: k.encode('utf-8') if k else None
)

def generate_event():
    return {
        "device_id": f"device_{random.randint(1, 100)}",
        "temperature": round(random.uniform(20, 30), 2),
        "humidity": round(random.uniform(40, 80), 2),
        "timestamp": datetime.now().isoformat()
    }

def produce_events(events_per_second: int = 10):
    print("Starting producer...")
    while True:
        event = generate_event()
        
        # Usar device_id como key para ordering
        producer.send(
            'iot-events',
            key=event['device_id'],
            value=event
        )
        
        print(f"Sent: {event['device_id']}")
        time.sleep(1 / events_per_second)

if __name__ == "__main__":
    produce_events()`,
      explanation: { es: 'La key determina a qu√© partici√≥n va el mensaje. Misma key = misma partici√≥n = orden garantizado.', pt: 'A key determina para qual partici√≥n vai a mensagem. Mesma key = mesma partici√≥n = ordem garantida.' },
      tip: { es: 'Us√° device_id como key para que todos los eventos de un device vayan a la misma partici√≥n.', pt: 'Use device_id como key para que todos os eventos de um device v√£o para a mesma partici√≥n.' }
    },
    {
      order: 5,
      text: { es: 'üì• Implement√° el Consumer', pt: 'üì• Implemente o Consumer' },
      code: `# consumer.py
import json
from collections import defaultdict
from kafka import KafkaConsumer

consumer = KafkaConsumer(
    'iot-events',
    bootstrap_servers='localhost:9092',
    group_id='iot-processor',
    auto_offset_reset='earliest',
    enable_auto_commit=True,
    value_deserializer=lambda m: json.loads(m.decode('utf-8'))
)

def process_events():
    print("Starting consumer...")
    
    # Agregaciones en memoria
    stats = defaultdict(lambda: {'count': 0, 'sum_temp': 0})
    
    for message in consumer:
        event = message.value
        device_id = event['device_id']
        
        # Actualizar stats
        stats[device_id]['count'] += 1
        stats[device_id]['sum_temp'] += event['temperature']
        
        avg_temp = stats[device_id]['sum_temp'] / stats[device_id]['count']
        
        print(f"Device {device_id}: avg_temp={avg_temp:.2f}¬∞C (n={stats[device_id]['count']})")

if __name__ == "__main__":
    process_events()`,
      explanation: { es: 'auto_offset_reset="earliest" lee desde el principio si es un consumer nuevo.', pt: 'auto_offset_reset="earliest" l√™ do in√≠cio se for um consumer novo.' },
      checkpoint: { es: '¬øEl consumer recibe mensajes del producer?', pt: 'O consumer recebe mensagens do producer?' }
    },
    {
      order: 6,
      text: { es: 'ü™ü Implement√° windowing', pt: 'ü™ü Implemente windowing' },
      code: `# consumer_windowed.py
import json
import time
from collections import defaultdict
from kafka import KafkaConsumer

consumer = KafkaConsumer(
    'iot-events',
    bootstrap_servers='localhost:9092',
    group_id='iot-windowed',
    auto_offset_reset='earliest',
    enable_auto_commit=False,  # Commit manual
    value_deserializer=lambda m: json.loads(m.decode('utf-8'))
)

WINDOW_SECONDS = 10

def process_with_windows():
    print(f"Processing with {WINDOW_SECONDS}s windows...")
    
    window_data = defaultdict(list)
    window_start = time.time()
    
    for message in consumer:
        event = message.value
        window_data[event['device_id']].append(event['temperature'])
        
        # Emitir cada WINDOW_SECONDS
        if time.time() - window_start >= WINDOW_SECONDS:
            print(f"\\n=== Window {time.strftime('%H:%M:%S')} ===")
            
            for device_id, temps in window_data.items():
                avg = sum(temps) / len(temps)
                print(f"{device_id}: avg={avg:.2f}¬∞C ({len(temps)} events)")
            
            # Commit offsets despu√©s de procesar
            consumer.commit()
            
            # Reset window
            window_data.clear()
            window_start = time.time()

if __name__ == "__main__":
    process_with_windows()`,
      explanation: { es: 'Commit manual te da control sobre cu√°ndo marcar mensajes como procesados.', pt: 'Commit manual te d√° controle sobre quando marcar mensagens como processadas.' },
      warning: { es: 'Si no hac√©s commit, vas a reprocesar mensajes si el consumer se reinicia.', pt: 'Se n√£o fizer commit, vai reprocessar mensagens se o consumer reiniciar.' }
    },
    {
      order: 7,
      text: { es: 'üíæ Guard√° resultados', pt: 'üíæ Guarde resultados' },
      code: `# Agregar al consumer
import os
from datetime import datetime

def save_window_results(window_data: dict, output_dir: str = 'output'):
    os.makedirs(output_dir, exist_ok=True)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f"{output_dir}/window_{timestamp}.json"
    
    results = {
        'timestamp': datetime.now().isoformat(),
        'window_seconds': WINDOW_SECONDS,
        'aggregations': {
            device_id: {
                'avg_temperature': sum(temps) / len(temps),
                'min_temperature': min(temps),
                'max_temperature': max(temps),
                'event_count': len(temps)
            }
            for device_id, temps in window_data.items()
        }
    }
    
    with open(filename, 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"Saved to {filename}")`,
      explanation: { es: 'Guard√° resultados de cada ventana para an√°lisis posterior.', pt: 'Guarde resultados de cada janela para an√°lise posterior.' }
    },
    {
      order: 8,
      text: { es: '‚ö†Ô∏è Implement√° graceful shutdown', pt: '‚ö†Ô∏è Implemente graceful shutdown' },
      code: `import signal
import sys

def shutdown_handler(signum, frame):
    print("\\nShutting down gracefully...")
    consumer.commit()  # Commit pending offsets
    consumer.close()
    sys.exit(0)

signal.signal(signal.SIGINT, shutdown_handler)
signal.signal(signal.SIGTERM, shutdown_handler)`,
      explanation: { es: 'Graceful shutdown evita perder mensajes cuando par√°s el consumer.', pt: 'Graceful shutdown evita perder mensagens quando para o consumer.' },
      tip: { es: 'Siempre hac√© commit antes de cerrar.', pt: 'Sempre fa√ßa commit antes de fechar.' }
    },
    {
      order: 9,
      text: { es: 'üìä Verific√° en Kafka UI', pt: 'üìä Verifique no Kafka UI' },
      explanation: {
        es: `En http://localhost:8080:
1. Ver el topic "iot-events"
2. Ver mensajes
3. Ver consumer groups y su lag
4. Ver particiones`,
        pt: `Em http://localhost:8080:
1. Ver o topic "iot-events"
2. Ver mensagens
3. Ver consumer groups e seu lag
4. Ver particiones`
      },
      checkpoint: { es: '¬øPod√©s ver el lag del consumer group en Kafka UI?', pt: 'Consegue ver o lag do consumer group no Kafka UI?' }
    },
  ],
  deliverable: { es: 'Repo con docker-compose + producer + consumer + documentaci√≥n', pt: 'Repo com docker-compose + producer + consumer + documenta√ß√£o' },
  evaluation: [
    { es: '¬øEl producer env√≠a eventos sin errores?', pt: 'O producer envia eventos sem erros?' },
    { es: '¬øEl consumer procesa sin perder eventos?', pt: 'O consumer processa sem perder eventos?' },
    { es: '¬øManej√°s offsets correctamente?', pt: 'Lida com offsets corretamente?' },
    { es: '¬øImplementaste graceful shutdown?', pt: 'Implementou graceful shutdown?' },
    { es: '¬øEl sistema se recupera de crashes?', pt: 'O sistema se recupera de crashes?' },
  ],
  theory: {
    es: `## Arquitectura de Kafka

\`\`\`
[Producers] ‚Üí [Kafka Cluster] ‚Üí [Consumers]
                    |
              [Zookeeper]
\`\`\`

**Topic**: Canal de mensajes
**Partition**: Divisi√≥n para paralelismo
**Replica**: Copia para durabilidad
**Consumer Group**: Grupo que comparte la carga

## Garant√≠as de Entrega

| Garant√≠a | Descripci√≥n | C√≥mo lograrla |
|----------|-------------|---------------|
| At-most-once | Puede perder | auto_commit=True |
| At-least-once | Puede duplicar | Commit despu√©s de procesar |
| Exactly-once | Ni p√©rdida ni duplicados | Transacciones + idempotencia |

## Partitioning

- Mensajes con misma key van a misma partici√≥n
- Orden garantizado solo dentro de partici√≥n
- M√°s particiones = m√°s paralelismo`,
    pt: `## Arquitetura do Kafka

\`\`\`
[Producers] ‚Üí [Kafka Cluster] ‚Üí [Consumers]
                    |
              [Zookeeper]
\`\`\`

**Topic**: Canal de mensagens
**Partition**: Divis√£o para paralelismo
**Replica**: C√≥pia para durabilidade
**Consumer Group**: Grupo que compartilha a carga

## Garantias de Entrega

| Garantia | Descri√ß√£o | Como conseguir |
|----------|-------------|---------------|
| At-most-once | Pode perder | auto_commit=True |
| At-least-once | Pode duplicar | Commit depois de processar |
| Exactly-once | Nem perda nem duplicados | Transa√ß√µes + idempot√™ncia |

## Partitioning

- Mensagens com mesma key v√£o para mesma parti√ß√£o
- Ordem garantida apenas dentro de parti√ß√£o
- Mais parti√ß√µes = mais paralelismo`
  },
};


