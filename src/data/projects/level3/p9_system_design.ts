import { Project } from '../../../types/members';

export const p9SystemDesign: Project = {
  id: 'p9-system-design',
  level: 3,
  title: {
    es: 'DiseÃ±o de Sistema: Analytics Platform',
    pt: 'Design de Sistema: Analytics Platform'
  },
  description: {
    es: 'DiseÃ±Ã¡ una plataforma de analytics como la de Spotify o Netflix. Este es exactamente el tipo de ejercicio que te hacen en entrevistas Senior.',
    pt: 'Projete uma plataforma de analytics como a do Spotify ou Netflix. Este Ã© exatamente o tipo de exercÃ­cio feito em entrevistas SÃªnior.'
  },
  difficulty: 'Expert',
  duration: '6-8 horas',
  skills: [
    { es: 'System Design', pt: 'Design de Sistema' },
    { es: 'Arquitectura', pt: 'Arquitetura' },
    { es: 'Escalabilidad', pt: 'Escalabilidade' },
    { es: 'Trade-offs', pt: 'Trade-offs' },
    { es: 'DocumentaciÃ³n', pt: 'DocumentaÃ§Ã£o' }
  ],
  icon: 'ğŸ—ï¸',
  color: 'purple',
  prerequisites: ['p4-data-warehouse', 'p6-airflow-orchestration', 'p5-aws-pipeline'],
  estimatedLines: 50,
  realWorldExample: {
    es: 'AsÃ­ diseÃ±aron el sistema de analytics de Spotify que procesa 100B+ eventos/dÃ­a',
    pt: 'Assim projetaram o sistema de analytics do Spotify que processa 100B+ eventos/dia'
  },
  usedBy: ['Spotify', 'Netflix', 'Uber', 'Meta', 'Google'],
  learningObjectives: [
    { es: 'Clarificar requisitos antes de diseÃ±ar', pt: 'Clarificar requisitos antes de projetar' },
    { es: 'Estimar escala (back-of-envelope)', pt: 'Estimar escala (back-of-envelope)' },
    { es: 'DiseÃ±ar componentes de ingesta, storage, procesamiento', pt: 'Projetar componentes de ingestÃ£o, armazenamento, processamento' },
    { es: 'Identificar y comunicar trade-offs', pt: 'Identificar e comunicar trade-offs' },
    { es: 'Considerar operaciones (monitoring, alertas)', pt: 'Considerar operaÃ§Ãµes (monitoramento, alertas)' },
  ],
  commonMistakes: [
    {
      mistake: { es: 'Empezar a diseÃ±ar sin clarificar requisitos', pt: 'ComeÃ§ar a projetar sem clarificar requisitos' },
      why: { es: 'Vas a diseÃ±ar algo que no resuelve el problema', pt: 'VocÃª vai projetar algo que nÃ£o resolve o problema' },
      solution: { es: 'Primero: Â¿QuÃ©? Â¿Para quiÃ©n? Â¿CuÃ¡ntos usuarios?', pt: 'Primeiro: O quÃª? Para quem? Quantos usuÃ¡rios?' },
    },
    {
      mistake: { es: 'No estimar escala', pt: 'NÃ£o estimar escala' },
      why: { es: 'La soluciÃ³n para 1000 usuarios â‰  1M usuarios', pt: 'A soluÃ§Ã£o para 1000 usuÃ¡rios â‰  1M usuÃ¡rios' },
      solution: { es: 'Back-of-envelope: eventos/dÃ­a, storage/aÃ±o, queries/segundo', pt: 'Back-of-envelope: eventos/dia, storage/ano, queries/segundo' },
    },
    {
      mistake: { es: 'Ignorar casos de falla', pt: 'Ignorar casos de falha' },
      why: { es: 'En producciÃ³n, TODO falla eventualmente', pt: 'Em produÃ§Ã£o, TUDO falha eventualmente' },
      solution: { es: 'Preguntate: Â¿QuÃ© pasa si X muere? Â¿CÃ³mo recupero?', pt: 'Pergunte-se: O que acontece se X morrer? Como recupero?' },
    },
  ],
  expectedOutputs: [
    {
      step: 5,
      description: { es: 'Diagrama de arquitectura', pt: 'Diagrama de arquitetura' },
      example: `â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Clients   â”‚â”€â”€â”€â”€â–¶â”‚    Kafka    â”‚â”€â”€â”€â”€â–¶â”‚   Spark     â”‚
â”‚  (SDKs)     â”‚     â”‚  (ingesta)  â”‚     â”‚ (proceso)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                               â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                    â”‚   Presto    â”‚â—€â”€â”€â”€â”€â”‚     S3      â”‚
                    â”‚  (queries)  â”‚     â”‚  (storage)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                    â”‚  Dashboard  â”‚
                    â”‚  (Superset) â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
    },
  ],
  interviewStory: {
    hook: {
      es: "DiseÃ±Ã© una plataforma de analytics que procesa 100 millones de eventos diarios con latencia sub-segundo para queries.",
      pt: "Projetei uma plataforma de analytics que processa 100 milhÃµes de eventos diÃ¡rios com latÃªncia sub-segundo para queries."
    },
    situation: {
      es: "La empresa necesitaba analytics en tiempo real para 50 millones de usuarios. El sistema existente no escalaba y las queries tardaban minutos.",
      pt: "A empresa precisava de analytics em tempo real para 50 milhÃµes de usuÃ¡rios. O sistema existente nÃ£o escalava e as queries demoravam minutos."
    },
    task: {
      es: "DiseÃ±ar una arquitectura de analytics desde cero que soportara la escala actual y 10x de crecimiento.",
      pt: "Projetar uma arquitetura de analytics do zero que suportasse a escala atual e 10x de crescimento."
    },
    actions: [
      { es: "ClarifiquÃ© requisitos: 100M eventos/dÃ­a, queries en <1s, retenciÃ³n 2 aÃ±os", pt: "Clarifiquei requisitos: 100M eventos/dia, queries em <1s, retenÃ§Ã£o 2 anos" },
      { es: "Hice estimaciones back-of-envelope: 1.2KB/evento = 120GB/dÃ­a = 44TB/aÃ±o", pt: "Fiz estimativas back-of-envelope: 1.2KB/evento = 120GB/dia = 44TB/ano" },
      { es: "DiseÃ±Ã© ingesta con Kafka para buffering y desacople", pt: "Projetei ingestÃ£o com Kafka para buffering e desacoplamento" },
      { es: "ElegÃ­ Spark Streaming para procesamiento y S3/Delta Lake para storage", pt: "Escolhi Spark Streaming para processamento e S3/Delta Lake para armazenamento" },
      { es: "AgreguÃ© capa de serving con Presto para queries interactivas", pt: "Adicionei camada de serving com Presto para queries interativas" }
    ],
    results: [
      { es: "Sistema en producciÃ³n procesando 100M+ eventos/dÃ­a", pt: "Sistema em produÃ§Ã£o processando 100M+ eventos/dia" },
      { es: "Latencia de queries: p99 < 1 segundo", pt: "LatÃªncia de queries: p99 < 1 segundo" },
      { es: "Costo: 60% menos que la soluciÃ³n anterior (Redshift)", pt: "Custo: 60% menos que a soluÃ§Ã£o anterior (Redshift)" },
      { es: "Escalable: el mismo diseÃ±o soportarÃ­a 1B eventos/dÃ­a", pt: "EscalÃ¡vel: o mesmo design suportaria 1B eventos/dia" }
    ],
    learnings: [
      { es: "Siempre clarificar requisitos antes de diseÃ±ar - el diseÃ±o para 1M usuarios â‰  100M", pt: "Sempre clarificar requisitos antes de projetar - o design para 1M usuÃ¡rios â‰  100M" },
      { es: "Back-of-envelope calculations son esenciales para no over/under-engineer", pt: "CÃ¡lculos back-of-envelope sÃ£o essenciais para nÃ£o over/under-engineer" },
      { es: "Los trade-offs son inevitables - hay que comunicarlos claramente", pt: "Os trade-offs sÃ£o inevitÃ¡veis - Ã© preciso comunicÃ¡-los claramente" }
    ],
    possibleQuestions: [
      {
        question: { es: "Â¿Por quÃ© Kafka + Spark en vez de solo Kinesis?", pt: "Por que Kafka + Spark em vez de apenas Kinesis?" },
        answer: { es: "Kafka nos da mÃ¡s control: retenciÃ³n configurable, replay, mÃºltiples consumers. Kinesis es mÃ¡s managed pero menos flexible. Para esta escala, el control vale la pena.", pt: "Kafka nos dÃ¡ mais controle: retenÃ§Ã£o configurÃ¡vel, replay, mÃºltiplos consumidores. Kinesis Ã© mais gerenciado, mas menos flexÃ­vel. Para esta escala, o controle vale a pena." }
      },
      {
        question: { es: "Â¿CÃ³mo manejÃ¡s el cold start de queries?", pt: "Como vocÃª lida com o cold start de queries?" },
        answer: { es: "Pre-agregaciones para queries comunes (cubos OLAP). Las queries ad-hoc van directo a Presto sobre Parquet. Balance entre latencia y flexibilidad.", pt: "PrÃ©-agregaÃ§Ãµes para queries comuns (cubos OLAP). As queries ad-hoc vÃ£o direto para Presto sobre Parquet. BalanÃ§o entre latÃªncia e flexibilidade." }
      },
      {
        question: { es: "Â¿QuÃ© pasa si Kafka se cae?", pt: "O que acontece se o Kafka cair?" },
        answer: { es: "Kafka es un cluster de 3+ brokers con replicaciÃ³n. Si un broker cae, los otros siguen. Si todo cae, los producers buffean localmente y reintentan. DiseÃ±o para fallas.", pt: "Kafka Ã© um cluster de 3+ brokers com replicaÃ§Ã£o. Se um broker cair, os outros continuam. Se tudo cair, os producers fazem buffer localmente e tentam novamente. Design para falhas." }
      }
    ],
    closingStatement: { es: "System Design es el skill que te hace Senior - no es solo cÃ³digo, es entender trade-offs y comunicarlos.", pt: "System Design Ã© a habilidade que te torna SÃªnior - nÃ£o Ã© apenas cÃ³digo, Ã© entender trade-offs e comunicÃ¡-los." }
  },
  steps: [
    {
      order: 1,
      text: { es: 'ğŸ“‹ ClarificÃ¡ requisitos funcionales', pt: 'ğŸ“‹ Clarifique requisitos funcionais' },
      explanation: {
        es: `Antes de diseÃ±ar, hacÃ© estas preguntas:

**Funcionales:**
- Â¿QuÃ© eventos vamos a trackear? (page views, clicks, purchases)
- Â¿QuÃ© queries necesitan los usuarios? (dashboards, ad-hoc, ML)
- Â¿Necesitamos real-time o batch estÃ¡ bien?
- Â¿CuÃ¡nto historial guardamos?

**Ejemplo de respuestas:**
- Trackear: page views, clicks, purchases, searches
- Queries: dashboards diarios, reportes mensuales, ML features
- Latencia: dashboards pueden tener 5 min de delay
- Historial: 2 aÃ±os`,
        pt: `Antes de projetar, faÃ§a estas perguntas:

**Funcionais:**
- Que eventos vamos rastrear? (page views, clicks, purchases)
- Que queries os usuÃ¡rios precisam? (dashboards, ad-hoc, ML)
- Precisamos de real-time ou batch estÃ¡ bom?
- Quanto histÃ³rico guardamos?

**Exemplo de respostas:**
- Rastrear: page views, clicks, purchases, searches
- Queries: dashboards diÃ¡rios, relatÃ³rios mensais, ML features
- LatÃªncia: dashboards podem ter 5 min de delay
- HistÃ³rico: 2 anos`
      },
      tip: { es: 'En una entrevista, hacÃ© estas preguntas antes de dibujar nada.', pt: 'Em uma entrevista, faÃ§a estas perguntas antes de desenhar qualquer coisa.' },
      checkpoint: { es: 'Â¿TenÃ©s claros los requisitos funcionales?', pt: 'VocÃª tem claros os requisitos funcionais?' }
    },
    {
      order: 2,
      text: { es: 'ğŸ“Š EstimÃ¡ escala (back-of-envelope)', pt: 'ğŸ“Š Estime a escala (back-of-envelope)' },
      code: `# Estimaciones de escala

## Usuarios
- 10M usuarios activos diarios (DAU)
- Promedio 50 eventos/usuario/dÃ­a
- Total: 500M eventos/dÃ­a

## Throughput
- 500M eventos / 86400 segundos = ~6000 eventos/segundo
- Pico (2x promedio) = 12000 eventos/segundo

## Storage
- TamaÃ±o promedio evento: 500 bytes
- Diario: 500M * 500B = 250GB/dÃ­a
- Anual: 250GB * 365 = ~90TB/aÃ±o
- 2 aÃ±os: ~180TB

## Queries
- 100 analistas
- 10 queries/analista/dÃ­a = 1000 queries/dÃ­a
- Pico: 100 queries/hora`,
      explanation: { es: 'Back-of-envelope te da orden de magnitud. No necesitÃ¡s ser exacto.', pt: 'Back-of-envelope te dÃ¡ ordem de grandeza. NÃ£o precisa ser exato.' },
      tip: { es: 'Siempre calculÃ¡ pico (2-3x promedio) para dimensionar.', pt: 'Sempre calcule o pico (2-3x mÃ©dia) para dimensionar.' }
    },
    {
      order: 3,
      text: { es: 'ğŸ“ DiseÃ±o high-level', pt: 'ğŸ“ Design high-level' },
      explanation: {
        es: `DibujÃ¡ los componentes principales:

\`\`\`
[Clients] â†’ [API Gateway] â†’ [Kafka] â†’ [Flink] â†’ [S3 Data Lake]
                                          â†“
                                    [Spark Jobs]
                                          â†“
                                    [Snowflake DW]
                                          â†“
                                    [Dashboards]
\`\`\`

**Componentes:**
1. **Ingesta**: API Gateway + Kafka (buffer + desacople)
2. **Procesamiento**: Flink (streaming) + Spark (batch)
3. **Storage**: S3 (raw) + Snowflake (analytics)
4. **Serving**: APIs + Dashboards`,
        pt: `Desenhe os componentes principais:

\`\`\`
[Clients] â†’ [API Gateway] â†’ [Kafka] â†’ [Flink] â†’ [S3 Data Lake]
                                          â†“
                                    [Spark Jobs]
                                          â†“
                                    [Snowflake DW]
                                          â†“
                                    [Dashboards]
\`\`\`

**Componentes:**
1. **IngestÃ£o**: API Gateway + Kafka (buffer + desacoplamento)
2. **Processamento**: Flink (streaming) + Spark (batch)
3. **Armazenamento**: S3 (raw) + Snowflake (analytics)
4. **Serving**: APIs + Dashboards`
      },
      checkpoint: { es: 'Â¿Tu diagrama tiene ingesta, procesamiento, storage y serving?', pt: 'Seu diagrama tem ingestÃ£o, processamento, armazenamento e serving?' }
    },
    {
      order: 4,
      text: { es: 'ğŸ“¥ Deep dive: Ingesta', pt: 'ğŸ“¥ Deep dive: IngestÃ£o' },
      explanation: {
        es: `**Decisiones clave:**

1. **Â¿Por quÃ© Kafka?**
   - Buffer ante picos de trÃ¡fico
   - Desacopla productores de consumidores
   - Replay si algo falla
   - MÃºltiples consumidores

2. **Particionamiento:**
   - Por event_type (para procesamiento paralelo)
   - O por user_id (para ordenamiento por usuario)

3. **RetenciÃ³n:**
   - 7 dÃ­as en Kafka (para replay)
   - DespuÃ©s va a S3

4. **Schema:**
   - Usar Avro o Protobuf (tipado, evoluciÃ³n)
   - Schema Registry para compatibilidad`,
        pt: `**DecisÃµes chave:**

1. **Por que Kafka?**
   - Buffer ante picos de trÃ¡fego
   - Desacopla produtores de consumidores
   - Replay se algo falhar
   - MÃºltiplos consumidores

2. **Particionamento:**
   - Por event_type (para processamento paralelo)
   - Ou por user_id (para ordenaÃ§Ã£o por usuÃ¡rio)

3. **RetenÃ§Ã£o:**
   - 7 dias no Kafka (para replay)
   - Depois vai para S3

4. **Schema:**
   - Usar Avro ou Protobuf (tipado, evoluÃ§Ã£o)
   - Schema Registry para compatibilidade`
      },
      tip: { es: 'Siempre justificÃ¡ por quÃ© elegiste cada tecnologÃ­a.', pt: 'Sempre justifique por que escolheu cada tecnologia.' }
    },
    {
      order: 5,
      text: { es: 'ğŸ’¾ Deep dive: Storage', pt: 'ğŸ’¾ Deep dive: Armazenamento' },
      explanation: {
        es: `**Data Lake (S3):**
\`\`\`
s3://analytics-lake/
â”œâ”€â”€ raw/                    # Eventos crudos (Avro)
â”‚   â””â”€â”€ events/
â”‚       â””â”€â”€ year=2024/month=01/day=15/
â”œâ”€â”€ processed/              # Eventos limpios (Parquet)
â”‚   â””â”€â”€ events/
â”‚       â””â”€â”€ event_type=page_view/year=2024/
â””â”€â”€ aggregated/             # MÃ©tricas pre-calculadas
    â””â”€â”€ daily_metrics/
\`\`\`

**Data Warehouse (Snowflake):**
- Modelo dimensional (star schema)
- Tablas mÃ¡s consultadas
- Agregaciones pre-calculadas

**Trade-off:** 
- Data Lake: Barato, flexible, lento
- Data Warehouse: Caro, estructurado, rÃ¡pido`,
        pt: `**Data Lake (S3):**
\`\`\`
s3://analytics-lake/
â”œâ”€â”€ raw/                    # Eventos crus (Avro)
â”‚   â””â”€â”€ events/
â”‚       â””â”€â”€ year=2024/month=01/day=15/
â”œâ”€â”€ processed/              # Eventos limpos (Parquet)
â”‚   â””â”€â”€ events/
â”‚       â””â”€â”€ event_type=page_view/year=2024/
â””â”€â”€ aggregated/             # MÃ©tricas prÃ©-calculadas
    â””â”€â”€ daily_metrics/
\`\`\`

**Data Warehouse (Snowflake):**
- Modelo dimensional (star schema)
- Tabelas mais consultadas
- AgregaÃ§Ãµes prÃ©-calculadas

**Trade-off:** 
- Data Lake: Barato, flexÃ­vel, lento
- Data Warehouse: Caro, estruturado, rÃ¡pido`
      },
      checkpoint: { es: 'Â¿Explicaste por quÃ© usÃ¡s Data Lake + Data Warehouse?', pt: 'Explicou por que usa Data Lake + Data Warehouse?' }
    },
    {
      order: 6,
      text: { es: 'ğŸ”„ Deep dive: Procesamiento', pt: 'ğŸ”„ Deep dive: Processamento' },
      explanation: {
        es: `**Streaming (Flink):**
- ValidaciÃ³n de eventos
- Enriquecimiento (user info, geo)
- MÃ©tricas real-time (Ãºltimos 5 min)
- Escribir a S3 (raw)

**Batch (Spark):**
- Agregaciones diarias
- Features para ML
- Backfill si hay errores
- Escribir a Snowflake

**Trade-off:**
- Streaming: Baja latencia, mÃ¡s complejo
- Batch: Simple, alta latencia`,
        pt: `**Streaming (Flink):**
- ValidaÃ§Ã£o de eventos
- Enriquecimento (user info, geo)
- MÃ©tricas real-time (Ãºltimos 5 min)
- Escrever para S3 (raw)

**Batch (Spark):**
- AgregaÃ§Ãµes diÃ¡rias
- Features para ML
- Backfill se houver erros
- Escrever para Snowflake

**Trade-off:**
- Streaming: Baixa latÃªncia, mais complexo
- Batch: Simples, alta latÃªncia`
      },
      tip: { es: 'Lambda architecture: Streaming + Batch. Kappa: Solo streaming.', pt: 'Arquitetura Lambda: Streaming + Batch. Kappa: Apenas streaming.' }
    },
    {
      order: 7,
      text: { es: 'âš–ï¸ IdentificÃ¡ trade-offs', pt: 'âš–ï¸ Identifique trade-offs' },
      explanation: {
        es: `**Trade-offs clave:**

1. **Consistencia vs Latencia**
   - Elegimos: Eventual consistency (5 min delay OK)
   - RazÃ³n: Dashboards no necesitan real-time

2. **Costo vs Performance**
   - Elegimos: S3 + Snowflake (no todo en Snowflake)
   - RazÃ³n: S3 es 10x mÃ¡s barato para storage

3. **Simplicidad vs Flexibilidad**
   - Elegimos: Schema Registry (mÃ¡s setup, menos bugs)
   - RazÃ³n: Evita problemas de schema evolution

4. **Compra vs Build**
   - Elegimos: Snowflake (no self-hosted DW)
   - RazÃ³n: Menos ops, mÃ¡s caro pero vale la pena`,
        pt: `**Trade-offs chave:**

1. **ConsistÃªncia vs LatÃªncia**
   - Escolhemos: ConsistÃªncia eventual (5 min delay OK)
   - RazÃ£o: Dashboards nÃ£o precisam de real-time

2. **Custo vs Performance**
   - Escolhemos: S3 + Snowflake (nem tudo no Snowflake)
   - RazÃ£o: S3 Ã© 10x mais barato para armazenamento

3. **Simplicidade vs Flexibilidade**
   - Escolhemos: Schema Registry (mais configuraÃ§Ã£o, menos bugs)
   - RazÃ£o: Evita problemas de evoluÃ§Ã£o de schema

4. **Comprar vs Construir**
   - Escolhemos: Snowflake (nÃ£o self-hosted DW)
   - RazÃ£o: Menos ops, mais caro mas vale a pena`
      },
      checkpoint: { es: 'Â¿PodÃ©s defender cada trade-off?', pt: 'Consegue defender cada trade-off?' }
    },
    {
      order: 8,
      text: { es: 'ğŸ”’ Seguridad y compliance', pt: 'ğŸ”’ SeguranÃ§a e compliance' },
      explanation: {
        es: `**Consideraciones:**

1. **AutenticaciÃ³n**: API keys + OAuth para dashboards
2. **AutorizaciÃ³n**: RBAC (roles por equipo)
3. **EncriptaciÃ³n**: 
   - En trÃ¡nsito: TLS
   - En reposo: S3 SSE, Snowflake encryption
4. **PII**: 
   - Hashear user_id en raw
   - Acceso restringido a datos sensibles
5. **Audit**: Logs de quiÃ©n accede a quÃ©`,
        pt: `**ConsideraÃ§Ãµes:**

1. **AutenticaÃ§Ã£o**: API keys + OAuth para dashboards
2. **AutorizaÃ§Ã£o**: RBAC (papÃ©is por equipe)
3. **Criptografia**: 
   - Em trÃ¢nsito: TLS
   - Em repouso: S3 SSE, Snowflake encryption
4. **PII**: 
   - Hashear user_id em raw
   - Acesso restrito a dados sensÃ­veis
5. **Auditoria**: Logs de quem acessa o quÃª`
      },
      tip: { es: 'En entrevistas Senior, mencionar seguridad te diferencia.', pt: 'Em entrevistas SÃªnior, mencionar seguranÃ§a te diferencia.' }
    },
    {
      order: 9,
      text: { es: 'ğŸ“ˆ Operaciones y monitoring', pt: 'ğŸ“ˆ OperaÃ§Ãµes e monitoramento' },
      explanation: {
        es: `**MÃ©tricas clave:**
- Ingesta: eventos/segundo, latencia p99
- Procesamiento: jobs fallidos, lag de Kafka
- Storage: GB/dÃ­a, queries/hora
- Serving: latencia de dashboards

**Alertas:**
- Lag de Kafka > 5 min
- Jobs fallidos > 2 consecutivos
- Latencia p99 > 5s

**Runbooks:**
- QuÃ© hacer si Kafka estÃ¡ laggeado
- CÃ³mo hacer backfill
- CÃ³mo escalar Flink`,
        pt: `**MÃ©tricas chave:**
- IngestÃ£o: eventos/segundo, latÃªncia p99
- Processamento: jobs falhados, lag do Kafka
- Armazenamento: GB/dia, queries/hora
- Serving: latÃªncia de dashboards

**Alertas:**
- Lag do Kafka > 5 min
- Jobs falhados > 2 consecutivos
- LatÃªncia p99 > 5s

**Runbooks:**
- O que fazer se Kafka estiver com lag
- Como fazer backfill
- Como escalar Flink`
      },
      checkpoint: { es: 'Â¿Tu diseÃ±o incluye cÃ³mo operarlo?', pt: 'Seu design inclui como operÃ¡-lo?' }
    },
    {
      order: 10,
      text: { es: 'ğŸ“ DocumentÃ¡ el diseÃ±o', pt: 'ğŸ“ Documente o design' },
      explanation: {
        es: `CreÃ¡ un documento con:

1. **Resumen ejecutivo**: QuÃ© problema resuelve
2. **Requisitos**: Funcionales y no funcionales
3. **Estimaciones**: Escala y costos
4. **Arquitectura**: Diagrama + explicaciÃ³n
5. **Trade-offs**: Decisiones y justificaciÃ³n
6. **Operaciones**: Monitoring y alertas
7. **Plan de implementaciÃ³n**: Fases

UsÃ¡ draw.io o Excalidraw para diagramas.`,
        pt: `Crie um documento com:

1. **Resumo executivo**: Que problema resolve
2. **Requisitos**: Funcionais e nÃ£o funcionais
3. **Estimativas**: Escala e custos
4. **Arquitetura**: Diagrama + explicaÃ§Ã£o
5. **Trade-offs**: DecisÃµes e justificativa
6. **OperaÃ§Ãµes**: Monitoramento e alertas
7. **Plano de implementaÃ§Ã£o**: Fases

Use draw.io ou Excalidraw para diagramas.`
      },
      checkpoint: { es: 'Â¿Alguien puede entender tu diseÃ±o sin que lo expliques?', pt: 'AlguÃ©m consegue entender seu design sem que vocÃª o explique?' }
    },
  ],
  deliverable: { es: 'Documento de diseÃ±o completo + diagrama de arquitectura', pt: 'Documento de design completo + diagrama de arquitetura' },
  evaluation: [
    { es: 'Â¿Clarificaste requisitos antes de diseÃ±ar?', pt: 'Clarificou requisitos antes de projetar?' },
    { es: 'Â¿Estimaste escala correctamente?', pt: 'Estimou escala corretamente?' },
    { es: 'Â¿Identificaste y justificaste trade-offs?', pt: 'Identificou e justificou trade-offs?' },
    { es: 'Â¿Consideraste operaciones (monitoring, alertas)?', pt: 'Considerou operaÃ§Ãµes (monitoramento, alertas)?' },
    { es: 'Â¿El diseÃ±o es realista e implementable?', pt: 'O design Ã© realista e implementÃ¡vel?' },
  ],
  theory: {
    es: `## Framework para System Design

### 1. Clarificar (5 min)
- Â¿QuÃ© problema resolvemos?
- Â¿QuiÃ©nes son los usuarios?
- Â¿QuÃ© funcionalidades son crÃ­ticas?

### 2. Estimar (5 min)
- Usuarios, eventos, storage
- Throughput (eventos/segundo)
- Latencia requerida

### 3. High-level design (10 min)
- Componentes principales
- Flujo de datos
- TecnologÃ­as candidatas

### 4. Deep dive (20 min)
- 2-3 componentes crÃ­ticos
- Decisiones de diseÃ±o
- Trade-offs

### 5. Wrap-up (5 min)
- Resumen de trade-offs
- Puntos de falla
- CÃ³mo escalar

## TecnologÃ­as Comunes

| Componente | Opciones |
|------------|----------|
| Ingesta | Kafka, Kinesis, Pub/Sub |
| Procesamiento | Spark, Flink, dbt |
| Storage | S3, Snowflake, BigQuery |
| Serving | APIs, Dashboards, ML |`,
    pt: `## Framework para System Design

### 1. Clarificar (5 min)
- Que problema resolvemos?
- Quem sÃ£o os usuÃ¡rios?
- Que funcionalidades sÃ£o crÃ­ticas?

### 2. Estimar (5 min)
- UsuÃ¡rios, eventos, armazenamento
- Throughput (eventos/segundo)
- LatÃªncia requerida

### 3. High-level design (10 min)
- Componentes principais
- Fluxo de dados
- Tecnologias candidatas

### 4. Deep dive (20 min)
- 2-3 componentes crÃ­ticos
- DecisÃµes de design
- Trade-offs

### 5. Wrap-up (5 min)
- Resumo de trade-offs
- Pontos de falha
- Como escalar

## Tecnologias Comuns

| Componente | OpÃ§Ãµes |
|------------|----------|
| IngestÃ£o | Kafka, Kinesis, Pub/Sub |
| Processamento | Spark, Flink, dbt |
| Armazenamento | S3, Snowflake, BigQuery |
| Serving | APIs, Dashboards, ML |`
  },
  nextSteps: [
    { es: 'PracticÃ¡ con otros escenarios: e-commerce, social media, IoT', pt: 'Pratique com outros cenÃ¡rios: e-commerce, social media, IoT' },
    { es: 'HacÃ© mock interviews con otros', pt: 'FaÃ§a mock interviews com outros' },
    { es: 'EstudiÃ¡ arquitecturas reales (Netflix, Uber, Spotify)', pt: 'Estude arquiteturas reais (Netflix, Uber, Spotify)' },
  ],
};


