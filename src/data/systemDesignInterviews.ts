/**
 * System Design Interviews for Data Engineering
 * 
 * Estructura: Cada interview simula una entrevista real con:
 * - Contexto del problema
 * - Preguntas clarificadoras que deberÃ­as hacer
 * - SoluciÃ³n paso a paso
 * - Diagramas (descripciÃ³n)
 * - Trade-offs a discutir
 * - Errores comunes a evitar
 */

export interface SystemDesignInterview {
  id: string;
  title: {
    es: string;
    en: string;
    pt: string;
  };
  company: string; // Tipo de empresa (no nombre real)
  difficulty: 'junior' | 'mid' | 'senior';
  duration: string; // "45 min"
  tags: string[];
  problem: {
    es: string;
    en: string;
    pt: string;
  };
  clarifyingQuestions: {
    question: { es: string; en: string; pt: string };
    whyAsk: { es: string; en: string; pt: string };
    typicalAnswer: { es: string; en: string; pt: string };
  }[];
  requirements: {
    functional: { es: string; en: string; pt: string }[];
    nonFunctional: { es: string; en: string; pt: string }[];
  };
  solution: {
    step: number;
    title: { es: string; en: string; pt: string };
    description: { es: string; en: string; pt: string };
    components: string[];
    diagram?: string; // ASCII art or description
  }[];
  tradeoffs: {
    decision: { es: string; en: string; pt: string };
    option1: { es: string; en: string; pt: string };
    option2: { es: string; en: string; pt: string };
    recommendation: { es: string; en: string; pt: string };
  }[];
  commonMistakes: {
    es: string;
    en: string;
    pt: string;
  }[];
  interviewerTips: {
    es: string;
    en: string;
    pt: string;
  }[];
  relatedTopics: string[];
  estimatedXP: number;
}

export const SYSTEM_DESIGN_INTERVIEWS: SystemDesignInterview[] = [
  // ============ INTERVIEW 1: E-COMMERCE PIPELINE ============
  {
    id: 'sd-ecommerce-pipeline',
    title: {
      es: 'Pipeline de Datos para E-commerce',
      en: 'E-commerce Data Pipeline',
      pt: 'Pipeline de Dados para E-commerce'
    },
    company: 'E-commerce (estilo Mercado Libre/Amazon)',
    difficulty: 'junior',
    duration: '45 min',
    tags: ['ETL', 'Data Warehouse', 'Batch Processing', 'AWS'],
    problem: {
      es: `Sos el primer Data Engineer de una startup de e-commerce que estÃ¡ creciendo rÃ¡pido. 
Tienen 100,000 transacciones por dÃ­a y necesitan:
1. Un dashboard para el equipo de ventas con mÃ©tricas diarias
2. Reportes semanales para inversores
3. Datos histÃ³ricos para anÃ¡lisis de tendencias

El CTO te pregunta: "Â¿CÃ³mo diseÃ±arÃ­as el pipeline de datos?"`,
      en: `You're the first Data Engineer at a fast-growing e-commerce startup.
They have 100,000 transactions per day and need:
1. A dashboard for the sales team with daily metrics
2. Weekly reports for investors
3. Historical data for trend analysis

The CTO asks: "How would you design the data pipeline?"`,
      pt: `VocÃª Ã© o primeiro Data Engineer de uma startup de e-commerce que estÃ¡ crescendo rÃ¡pido.
Eles tÃªm 100.000 transaÃ§Ãµes por dia e precisam de:
1. Um dashboard para o time de vendas com mÃ©tricas diÃ¡rias
2. RelatÃ³rios semanais para investidores
3. Dados histÃ³ricos para anÃ¡lise de tendÃªncias

O CTO pergunta: "Como vocÃª projetaria o pipeline de dados?"`
    },
    clarifyingQuestions: [
      {
        question: {
          es: 'Â¿De dÃ³nde vienen los datos? Â¿QuÃ© sistemas fuente tienen?',
          en: 'Where does the data come from? What source systems do you have?',
          pt: 'De onde vÃªm os dados? Quais sistemas fonte vocÃªs tÃªm?'
        },
        whyAsk: {
          es: 'NecesitÃ¡s saber si es PostgreSQL, MySQL, APIs, archivos, etc. para elegir el mÃ©todo de extracciÃ³n.',
          en: 'You need to know if it\'s PostgreSQL, MySQL, APIs, files, etc. to choose the extraction method.',
          pt: 'VocÃª precisa saber se Ã© PostgreSQL, MySQL, APIs, arquivos, etc. para escolher o mÃ©todo de extraÃ§Ã£o.'
        },
        typicalAnswer: {
          es: 'PostgreSQL para transacciones, MongoDB para catÃ¡logo de productos, y algunos CSVs de proveedores.',
          en: 'PostgreSQL for transactions, MongoDB for product catalog, and some CSVs from suppliers.',
          pt: 'PostgreSQL para transaÃ§Ãµes, MongoDB para catÃ¡logo de produtos, e alguns CSVs de fornecedores.'
        }
      },
      {
        question: {
          es: 'Â¿QuÃ© latencia es aceptable? Â¿Los datos pueden tener unas horas de delay?',
          en: 'What latency is acceptable? Can the data have a few hours of delay?',
          pt: 'Qual latÃªncia Ã© aceitÃ¡vel? Os dados podem ter algumas horas de atraso?'
        },
        whyAsk: {
          es: 'Define si necesitÃ¡s streaming (tiempo real) o batch (cada X horas). Cambia completamente la arquitectura.',
          en: 'Defines if you need streaming (real-time) or batch (every X hours). Completely changes the architecture.',
          pt: 'Define se vocÃª precisa de streaming (tempo real) ou batch (a cada X horas). Muda completamente a arquitetura.'
        },
        typicalAnswer: {
          es: 'El dashboard puede actualizarse cada hora. Los reportes son semanales.',
          en: 'The dashboard can update every hour. Reports are weekly.',
          pt: 'O dashboard pode atualizar a cada hora. Os relatÃ³rios sÃ£o semanais.'
        }
      },
      {
        question: {
          es: 'Â¿QuÃ© presupuesto y equipo tienen? Â¿Puedo usar servicios managed?',
          en: 'What budget and team do you have? Can I use managed services?',
          pt: 'Qual orÃ§amento e equipe vocÃªs tÃªm? Posso usar serviÃ§os gerenciados?'
        },
        whyAsk: {
          es: 'Airflow self-hosted vs MWAA, Spark cluster vs Glue. El presupuesto define la complejidad.',
          en: 'Self-hosted Airflow vs MWAA, Spark cluster vs Glue. Budget defines complexity.',
          pt: 'Airflow self-hosted vs MWAA, cluster Spark vs Glue. O orÃ§amento define a complexidade.'
        },
        typicalAnswer: {
          es: 'Startup con funding, podemos gastar en cloud. Solo vos como DE por ahora.',
          en: 'Funded startup, we can spend on cloud. Just you as DE for now.',
          pt: 'Startup com funding, podemos gastar em cloud. SÃ³ vocÃª como DE por enquanto.'
        }
      },
      {
        question: {
          es: 'Â¿CuÃ¡nto van a crecer? Â¿En 1 aÃ±o serÃ¡n 10x?',
          en: 'How much will you grow? Will you be 10x in 1 year?',
          pt: 'Quanto vÃ£o crescer? Em 1 ano serÃ£o 10x?'
        },
        whyAsk: {
          es: 'Si van a escalar mucho, elegÃ­s tecnologÃ­as que escalen (Spark > Pandas).',
          en: 'If they\'ll scale a lot, you choose technologies that scale (Spark > Pandas).',
          pt: 'Se vÃ£o escalar muito, vocÃª escolhe tecnologias que escalam (Spark > Pandas).'
        },
        typicalAnswer: {
          es: 'Esperamos 5-10x en el prÃ³ximo aÃ±o si todo sale bien.',
          en: 'We expect 5-10x next year if everything goes well.',
          pt: 'Esperamos 5-10x no prÃ³ximo ano se tudo der certo.'
        }
      }
    ],
    requirements: {
      functional: [
        { es: 'Ingestar datos de PostgreSQL, MongoDB y CSVs', en: 'Ingest data from PostgreSQL, MongoDB and CSVs', pt: 'Ingerir dados de PostgreSQL, MongoDB e CSVs' },
        { es: 'Transformar y limpiar datos (deduplicar, validar)', en: 'Transform and clean data (deduplicate, validate)', pt: 'Transformar e limpar dados (deduplicar, validar)' },
        { es: 'Cargar a un Data Warehouse para analytics', en: 'Load to a Data Warehouse for analytics', pt: 'Carregar para um Data Warehouse para analytics' },
        { es: 'ActualizaciÃ³n cada hora para el dashboard', en: 'Hourly update for dashboard', pt: 'AtualizaÃ§Ã£o a cada hora para o dashboard' },
        { es: 'Datos histÃ³ricos de al menos 2 aÃ±os', en: 'Historical data of at least 2 years', pt: 'Dados histÃ³ricos de pelo menos 2 anos' }
      ],
      nonFunctional: [
        { es: 'Escalable a 10x el volumen actual', en: 'Scalable to 10x current volume', pt: 'EscalÃ¡vel a 10x o volume atual' },
        { es: 'RecuperaciÃ³n ante fallos (retry, alertas)', en: 'Failure recovery (retry, alerts)', pt: 'RecuperaÃ§Ã£o de falhas (retry, alertas)' },
        { es: 'Costo optimizado (serverless donde sea posible)', en: 'Cost optimized (serverless where possible)', pt: 'Custo otimizado (serverless onde possÃ­vel)' },
        { es: 'Mantenible por 1 persona', en: 'Maintainable by 1 person', pt: 'ManutenÃ­vel por 1 pessoa' }
      ]
    },
    solution: [
      {
        step: 1,
        title: { es: 'Capa de Ingesta', en: 'Ingestion Layer', pt: 'Camada de IngestÃ£o' },
        description: {
          es: `Extraemos datos de las 3 fuentes hacia S3 (nuestro Data Lake).

PostgreSQL â†’ AWS DMS o Airbyte (CDC para capturar cambios)
MongoDB â†’ Airbyte connector o script Python con pymongo
CSVs â†’ Los proveedores los suben a un bucket S3 dedicado

Todo llega a s3://empresa-data/raw/ con particiones por fecha:
s3://empresa-data/raw/transactions/year=2024/month=12/day=09/`,
          en: `We extract data from the 3 sources to S3 (our Data Lake).

PostgreSQL â†’ AWS DMS or Airbyte (CDC to capture changes)
MongoDB â†’ Airbyte connector or Python script with pymongo
CSVs â†’ Suppliers upload to a dedicated S3 bucket

Everything arrives at s3://company-data/raw/ with date partitions:
s3://company-data/raw/transactions/year=2024/month=12/day=09/`,
          pt: `ExtraÃ­mos dados das 3 fontes para S3 (nosso Data Lake).

PostgreSQL â†’ AWS DMS ou Airbyte (CDC para capturar mudanÃ§as)
MongoDB â†’ Conector Airbyte ou script Python com pymongo
CSVs â†’ Fornecedores sobem para um bucket S3 dedicado

Tudo chega em s3://empresa-data/raw/ com partiÃ§Ãµes por data:
s3://empresa-data/raw/transactions/year=2024/month=12/day=09/`
        },
        components: ['AWS DMS', 'Airbyte', 'S3', 'Python'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL  â”‚     â”‚   MongoDB    â”‚     â”‚  CSV Files   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                    â”‚                    â”‚
       â”‚ DMS/CDC            â”‚ Airbyte            â”‚ S3 Upload
       â”‚                    â”‚                    â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   S3 (Raw)    â”‚
                    â”‚   Data Lake   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      },
      {
        step: 2,
        title: { es: 'Capa de TransformaciÃ³n', en: 'Transformation Layer', pt: 'Camada de TransformaÃ§Ã£o' },
        description: {
          es: `Usamos dbt + Snowflake para transformar los datos.

Â¿Por quÃ© dbt?
- SQL puro (fÃ¡cil de mantener)
- Tests integrados
- DocumentaciÃ³n automÃ¡tica
- Git-friendly

Â¿Por quÃ© Snowflake?
- Serverless (no hay que administrar)
- Escala automÃ¡ticamente
- SeparaciÃ³n storage/compute
- 30 dÃ­as gratis para empezar

Estructura de modelos:
- staging/ â†’ Limpieza bÃ¡sica (tipos, nulls)
- intermediate/ â†’ Joins entre tablas
- marts/ â†’ MÃ©tricas de negocio listas para dashboards`,
          en: `We use dbt + Snowflake to transform the data.

Why dbt?
- Pure SQL (easy to maintain)
- Built-in tests
- Automatic documentation
- Git-friendly

Why Snowflake?
- Serverless (no admin needed)
- Auto-scales
- Storage/compute separation
- 30-day free trial to start

Model structure:
- staging/ â†’ Basic cleaning (types, nulls)
- intermediate/ â†’ Table joins
- marts/ â†’ Business metrics ready for dashboards`,
          pt: `Usamos dbt + Snowflake para transformar os dados.

Por que dbt?
- SQL puro (fÃ¡cil de manter)
- Testes integrados
- DocumentaÃ§Ã£o automÃ¡tica
- Git-friendly

Por que Snowflake?
- Serverless (nÃ£o precisa administrar)
- Escala automaticamente
- SeparaÃ§Ã£o storage/compute
- 30 dias grÃ¡tis para comeÃ§ar

Estrutura de modelos:
- staging/ â†’ Limpeza bÃ¡sica (tipos, nulls)
- intermediate/ â†’ Joins entre tabelas
- marts/ â†’ MÃ©tricas de negÃ³cio prontas para dashboards`
        },
        components: ['dbt', 'Snowflake', 'SQL'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   S3 (Raw)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚ COPY INTO
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Snowflake   â”‚â—„â”€â”€â”€â”€â”€â”‚  dbt (transformations)          â”‚
â”‚   (Warehouse) â”‚      â”‚  â”œâ”€â”€ staging/                   â”‚
â”‚               â”‚      â”‚  â”œâ”€â”€ intermediate/              â”‚
â”‚               â”‚      â”‚  â””â”€â”€ marts/                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      },
      {
        step: 3,
        title: { es: 'Capa de OrquestaciÃ³n', en: 'Orchestration Layer', pt: 'Camada de OrquestraÃ§Ã£o' },
        description: {
          es: `Usamos Airflow (MWAA en AWS) para orquestar todo.

DAG principal (corre cada hora):
1. Trigger ingesta desde fuentes
2. Esperar que datos lleguen a S3
3. Ejecutar dbt run (transformaciones)
4. Ejecutar dbt test (validaciones)
5. Notificar a Slack si hay errores

Â¿Por quÃ© MWAA y no self-hosted?
- Es solo 1 persona manejando todo
- No queremos administrar infraestructura
- MWAA escala automÃ¡ticamente`,
          en: `We use Airflow (MWAA on AWS) to orchestrate everything.

Main DAG (runs every hour):
1. Trigger ingestion from sources
2. Wait for data to arrive in S3
3. Run dbt run (transformations)
4. Run dbt test (validations)
5. Notify Slack if errors

Why MWAA and not self-hosted?
- It's only 1 person managing everything
- We don't want to manage infrastructure
- MWAA scales automatically`,
          pt: `Usamos Airflow (MWAA na AWS) para orquestrar tudo.

DAG principal (roda a cada hora):
1. Trigger ingestÃ£o das fontes
2. Esperar dados chegarem no S3
3. Executar dbt run (transformaÃ§Ãµes)
4. Executar dbt test (validaÃ§Ãµes)
5. Notificar Slack se houver erros

Por que MWAA e nÃ£o self-hosted?
- Ã‰ sÃ³ 1 pessoa gerenciando tudo
- NÃ£o queremos administrar infraestrutura
- MWAA escala automaticamente`
        },
        components: ['Airflow', 'MWAA', 'Slack'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Airflow DAG                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚Ingestâ”‚â”€â”€â–¶â”‚Wait â”‚â”€â”€â–¶â”‚ dbt â”‚â”€â”€â–¶â”‚Test â”‚â”€â”€â–¶â”‚Notifyâ”‚  â”‚
â”‚  â”‚Data â”‚   â”‚ S3  â”‚   â”‚ run â”‚   â”‚     â”‚   â”‚Slack â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
              Corre cada hora (0 * * * *)
        `
      },
      {
        step: 4,
        title: { es: 'Capa de Consumo', en: 'Consumption Layer', pt: 'Camada de Consumo' },
        description: {
          es: `Los datos finales estÃ¡n en Snowflake, listos para consumir:

Dashboard (equipo de ventas):
- Metabase conectado a Snowflake
- MÃ©tricas: ventas diarias, productos top, conversiÃ³n
- ActualizaciÃ³n automÃ¡tica cada hora

Reportes (inversores):
- dbt genera las tablas agregadas
- Export a Google Sheets o PDF automÃ¡tico
- EnvÃ­o semanal por email

AnÃ¡lisis ad-hoc (equipo de datos):
- ConexiÃ³n directa a Snowflake
- Jupyter notebooks para anÃ¡lisis exploratorio`,
          en: `Final data is in Snowflake, ready to consume:

Dashboard (sales team):
- Metabase connected to Snowflake
- Metrics: daily sales, top products, conversion
- Automatic hourly update

Reports (investors):
- dbt generates aggregated tables
- Auto export to Google Sheets or PDF
- Weekly email delivery

Ad-hoc analysis (data team):
- Direct Snowflake connection
- Jupyter notebooks for exploratory analysis`,
          pt: `Os dados finais estÃ£o no Snowflake, prontos para consumir:

Dashboard (time de vendas):
- Metabase conectado ao Snowflake
- MÃ©tricas: vendas diÃ¡rias, produtos top, conversÃ£o
- AtualizaÃ§Ã£o automÃ¡tica a cada hora

RelatÃ³rios (investidores):
- dbt gera as tabelas agregadas
- Export para Google Sheets ou PDF automÃ¡tico
- Envio semanal por email

AnÃ¡lise ad-hoc (time de dados):
- ConexÃ£o direta ao Snowflake
- Jupyter notebooks para anÃ¡lise exploratÃ³ria`
        },
        components: ['Metabase', 'Google Sheets', 'Jupyter'],
        diagram: `
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Snowflake   â”‚
                    â”‚   (marts/)    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                 â”‚                 â”‚
          â–¼                 â–¼                 â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Metabase  â”‚   â”‚  Reports   â”‚   â”‚  Jupyter   â”‚
   â”‚ (Dashboard)â”‚   â”‚  (Weekly)  â”‚   â”‚ (Ad-hoc)   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      }
    ],
    tradeoffs: [
      {
        decision: { es: 'Snowflake vs Redshift vs BigQuery', en: 'Snowflake vs Redshift vs BigQuery', pt: 'Snowflake vs Redshift vs BigQuery' },
        option1: { es: 'Snowflake: MÃ¡s fÃ¡cil, mejor separaciÃ³n compute/storage, caro a escala', en: 'Snowflake: Easier, better compute/storage separation, expensive at scale', pt: 'Snowflake: Mais fÃ¡cil, melhor separaÃ§Ã£o compute/storage, caro em escala' },
        option2: { es: 'Redshift: MÃ¡s barato si ya usÃ¡s AWS, mÃ¡s complejo de administrar', en: 'Redshift: Cheaper if already on AWS, more complex to manage', pt: 'Redshift: Mais barato se jÃ¡ usa AWS, mais complexo de administrar' },
        recommendation: { es: 'Para startup con 1 DE: Snowflake. La simplicidad vale el costo extra.', en: 'For startup with 1 DE: Snowflake. Simplicity is worth the extra cost.', pt: 'Para startup com 1 DE: Snowflake. A simplicidade vale o custo extra.' }
      },
      {
        decision: { es: 'Batch (cada hora) vs Streaming (tiempo real)', en: 'Batch (hourly) vs Streaming (real-time)', pt: 'Batch (a cada hora) vs Streaming (tempo real)' },
        option1: { es: 'Batch: MÃ¡s simple, mÃ¡s barato, suficiente para dashboards', en: 'Batch: Simpler, cheaper, enough for dashboards', pt: 'Batch: Mais simples, mais barato, suficiente para dashboards' },
        option2: { es: 'Streaming: Datos al instante, pero 10x mÃ¡s complejo y caro', en: 'Streaming: Instant data, but 10x more complex and expensive', pt: 'Streaming: Dados instantÃ¢neos, mas 10x mais complexo e caro' },
        recommendation: { es: 'Empezar con batch. Agregar streaming solo cuando haya un caso de uso real que lo requiera.', en: 'Start with batch. Add streaming only when there\'s a real use case that requires it.', pt: 'ComeÃ§ar com batch. Adicionar streaming sÃ³ quando houver um caso de uso real que requeira.' }
      },
      {
        decision: { es: 'Airbyte vs Fivetran vs Scripts custom', en: 'Airbyte vs Fivetran vs Custom scripts', pt: 'Airbyte vs Fivetran vs Scripts custom' },
        option1: { es: 'Airbyte: Open source, gratis, muchos conectores', en: 'Airbyte: Open source, free, many connectors', pt: 'Airbyte: Open source, grÃ¡tis, muitos conectores' },
        option2: { es: 'Fivetran: MÃ¡s robusto, muy caro ($$$)', en: 'Fivetran: More robust, very expensive ($$$)', pt: 'Fivetran: Mais robusto, muito caro ($$$)' },
        recommendation: { es: 'Airbyte para empezar. Si crecen mucho y tienen budget, migrar a Fivetran.', en: 'Airbyte to start. If they grow a lot and have budget, migrate to Fivetran.', pt: 'Airbyte para comeÃ§ar. Se crescerem muito e tiverem budget, migrar para Fivetran.' }
      }
    ],
    commonMistakes: [
      { es: 'âŒ No preguntar sobre latencia y asumir que necesitan real-time', en: 'âŒ Not asking about latency and assuming they need real-time', pt: 'âŒ NÃ£o perguntar sobre latÃªncia e assumir que precisam de real-time' },
      { es: 'âŒ Sobre-ingenierizar: proponer Kafka + Spark para 100K rows/dÃ­a', en: 'âŒ Over-engineering: proposing Kafka + Spark for 100K rows/day', pt: 'âŒ Over-engineering: propor Kafka + Spark para 100K rows/dia' },
      { es: 'âŒ No considerar el equipo: proponer 5 herramientas para 1 persona', en: 'âŒ Not considering the team: proposing 5 tools for 1 person', pt: 'âŒ NÃ£o considerar o time: propor 5 ferramentas para 1 pessoa' },
      { es: 'âŒ Olvidar monitoreo y alertas', en: 'âŒ Forgetting monitoring and alerts', pt: 'âŒ Esquecer monitoramento e alertas' },
      { es: 'âŒ No hablar de costos', en: 'âŒ Not talking about costs', pt: 'âŒ NÃ£o falar de custos' }
    ],
    interviewerTips: [
      { es: 'ğŸ’¡ Siempre empezÃ¡ preguntando requisitos antes de dibujar', en: 'ğŸ’¡ Always start by asking requirements before drawing', pt: 'ğŸ’¡ Sempre comece perguntando requisitos antes de desenhar' },
      { es: 'ğŸ’¡ PensÃ¡ en voz alta - el entrevistador quiere ver tu proceso', en: 'ğŸ’¡ Think out loud - the interviewer wants to see your process', pt: 'ğŸ’¡ Pense em voz alta - o entrevistador quer ver seu processo' },
      { es: 'ğŸ’¡ DibujÃ¡ mientras explicÃ¡s - un diagrama vale mÃ¡s que mil palabras', en: 'ğŸ’¡ Draw while explaining - a diagram is worth a thousand words', pt: 'ğŸ’¡ Desenhe enquanto explica - um diagrama vale mais que mil palavras' },
      { es: 'ğŸ’¡ MencionÃ¡ trade-offs sin que te pregunten - demuestra madurez', en: 'ğŸ’¡ Mention trade-offs without being asked - shows maturity', pt: 'ğŸ’¡ Mencione trade-offs sem que perguntem - demonstra maturidade' },
      { es: 'ğŸ’¡ PreguntÃ¡ si podÃ©s usar servicios managed - es pragmÃ¡tico', en: 'ğŸ’¡ Ask if you can use managed services - it\'s pragmatic', pt: 'ğŸ’¡ Pergunte se pode usar serviÃ§os gerenciados - Ã© pragmÃ¡tico' }
    ],
    relatedTopics: ['ETL', 'Data Warehouse', 'dbt', 'Airflow', 'AWS', 'Snowflake'],
    estimatedXP: 500
  },

  // ============ INTERVIEW 2: REAL-TIME FRAUD DETECTION ============
  {
    id: 'sd-fraud-detection',
    title: {
      es: 'Sistema de DetecciÃ³n de Fraude en Tiempo Real',
      en: 'Real-Time Fraud Detection System',
      pt: 'Sistema de DetecÃ§Ã£o de Fraude em Tempo Real'
    },
    company: 'Fintech / Banco Digital',
    difficulty: 'mid',
    duration: '45 min',
    tags: ['Streaming', 'Kafka', 'Real-time', 'ML', 'AWS'],
    problem: {
      es: `TrabajÃ¡s para un banco digital que procesa 1 millÃ³n de transacciones por dÃ­a.
Necesitan detectar transacciones fraudulentas en menos de 500ms para poder bloquearlas.

Actualmente tienen un sistema batch que detecta fraude 24 horas despuÃ©s (muy tarde).
El negocio estÃ¡ perdiendo $500K/mes en fraude.

El CTO pregunta: "Â¿CÃ³mo diseÃ±arÃ­as un sistema de detecciÃ³n de fraude en tiempo real?"`,
      en: `You work for a digital bank that processes 1 million transactions per day.
They need to detect fraudulent transactions in under 500ms to block them.

Currently they have a batch system that detects fraud 24 hours later (too late).
The business is losing $500K/month to fraud.

The CTO asks: "How would you design a real-time fraud detection system?"`,
      pt: `VocÃª trabalha para um banco digital que processa 1 milhÃ£o de transaÃ§Ãµes por dia.
Eles precisam detectar transaÃ§Ãµes fraudulentas em menos de 500ms para poder bloqueÃ¡-las.

Atualmente tÃªm um sistema batch que detecta fraude 24 horas depois (muito tarde).
O negÃ³cio estÃ¡ perdendo $500K/mÃªs em fraude.

O CTO pergunta: "Como vocÃª projetaria um sistema de detecÃ§Ã£o de fraude em tempo real?"`
    },
    clarifyingQuestions: [
      {
        question: { es: 'Â¿QuÃ© datos tienen sobre cada transacciÃ³n?', en: 'What data do you have about each transaction?', pt: 'Quais dados vocÃªs tÃªm sobre cada transaÃ§Ã£o?' },
        whyAsk: { es: 'Define quÃ© features podÃ©s usar para el modelo de ML', en: 'Defines what features you can use for the ML model', pt: 'Define quais features vocÃª pode usar para o modelo de ML' },
        typicalAnswer: { es: 'Monto, ubicaciÃ³n, merchant, hora, dispositivo, historial del usuario', en: 'Amount, location, merchant, time, device, user history', pt: 'Valor, localizaÃ§Ã£o, merchant, hora, dispositivo, histÃ³rico do usuÃ¡rio' }
      },
      {
        question: { es: 'Â¿Ya tienen un modelo de ML para fraude o hay que crearlo?', en: 'Do you already have an ML model for fraud or does it need to be created?', pt: 'JÃ¡ tÃªm um modelo de ML para fraude ou precisa ser criado?' },
        whyAsk: { es: 'Si ya existe el modelo, solo necesitÃ¡s deployarlo en tiempo real', en: 'If the model exists, you only need to deploy it in real-time', pt: 'Se o modelo jÃ¡ existe, vocÃª sÃ³ precisa deployÃ¡-lo em tempo real' },
        typicalAnswer: { es: 'Tenemos un modelo batch en Python que funciona bien. Necesitamos hacerlo real-time.', en: 'We have a batch Python model that works well. We need to make it real-time.', pt: 'Temos um modelo batch em Python que funciona bem. Precisamos tornÃ¡-lo real-time.' }
      },
      {
        question: { es: 'Â¿CuÃ¡l es el false positive rate aceptable?', en: 'What false positive rate is acceptable?', pt: 'Qual Ã© a taxa de falso positivo aceitÃ¡vel?' },
        whyAsk: { es: 'Bloquear transacciones legÃ­timas es tan malo como dejar pasar fraude', en: 'Blocking legitimate transactions is as bad as letting fraud through', pt: 'Bloquear transaÃ§Ãµes legÃ­timas Ã© tÃ£o ruim quanto deixar passar fraude' },
        typicalAnswer: { es: 'Menos del 1% de false positives. Preferimos dejar pasar algo de fraude que bloquear clientes legÃ­timos.', en: 'Less than 1% false positives. We prefer to let some fraud through than block legitimate customers.', pt: 'Menos de 1% de falsos positivos. Preferimos deixar passar algum fraude do que bloquear clientes legÃ­timos.' }
      },
      {
        question: { es: 'Â¿QuÃ© pasa si el sistema de ML estÃ¡ caÃ­do? Â¿Bloqueamos todo?', en: 'What happens if the ML system is down? Do we block everything?', pt: 'O que acontece se o sistema de ML estiver fora? Bloqueamos tudo?' },
        whyAsk: { es: 'Define la estrategia de fallback - crÃ­tico para sistemas financieros', en: 'Defines fallback strategy - critical for financial systems', pt: 'Define a estratÃ©gia de fallback - crÃ­tico para sistemas financeiros' },
        typicalAnswer: { es: 'Si el sistema estÃ¡ caÃ­do, dejamos pasar transacciones pequeÃ±as (<$100) y bloqueamos grandes.', en: 'If system is down, we let small transactions (<$100) through and block large ones.', pt: 'Se o sistema estiver fora, deixamos passar transaÃ§Ãµes pequenas (<$100) e bloqueamos grandes.' }
      }
    ],
    requirements: {
      functional: [
        { es: 'Procesar cada transacciÃ³n en menos de 500ms', en: 'Process each transaction in under 500ms', pt: 'Processar cada transaÃ§Ã£o em menos de 500ms' },
        { es: 'Aplicar modelo de ML para scoring de riesgo', en: 'Apply ML model for risk scoring', pt: 'Aplicar modelo de ML para scoring de risco' },
        { es: 'Bloquear automÃ¡ticamente transacciones de alto riesgo', en: 'Automatically block high-risk transactions', pt: 'Bloquear automaticamente transaÃ§Ãµes de alto risco' },
        { es: 'Alertar al equipo de fraude para revisiÃ³n manual', en: 'Alert fraud team for manual review', pt: 'Alertar o time de fraude para revisÃ£o manual' },
        { es: 'Guardar historial para reentrenar el modelo', en: 'Save history to retrain the model', pt: 'Salvar histÃ³rico para retreinar o modelo' }
      ],
      nonFunctional: [
        { es: 'Latencia p99 < 500ms', en: 'p99 latency < 500ms', pt: 'LatÃªncia p99 < 500ms' },
        { es: 'Disponibilidad 99.99% (4 minutos de downtime/mes)', en: 'Availability 99.99% (4 minutes downtime/month)', pt: 'Disponibilidade 99.99% (4 minutos de downtime/mÃªs)' },
        { es: 'Escalable a 10M transacciones/dÃ­a', en: 'Scalable to 10M transactions/day', pt: 'EscalÃ¡vel a 10M transaÃ§Ãµes/dia' },
        { es: 'Fallback si el ML falla', en: 'Fallback if ML fails', pt: 'Fallback se o ML falhar' }
      ]
    },
    solution: [
      {
        step: 1,
        title: { es: 'Arquitectura General', en: 'General Architecture', pt: 'Arquitetura Geral' },
        description: {
          es: `El flujo es: TransacciÃ³n â†’ Kafka â†’ ML Service â†’ DecisiÃ³n â†’ Response

Usamos Kafka como message broker porque:
- Puede manejar millones de mensajes/segundo
- Garantiza que no se pierden mensajes
- Permite replay si algo falla
- Desacopla el sistema de pagos del sistema de ML`,
          en: `The flow is: Transaction â†’ Kafka â†’ ML Service â†’ Decision â†’ Response

We use Kafka as message broker because:
- Can handle millions of messages/second
- Guarantees no messages are lost
- Allows replay if something fails
- Decouples payment system from ML system`,
          pt: `O fluxo Ã©: TransaÃ§Ã£o â†’ Kafka â†’ ML Service â†’ DecisÃ£o â†’ Response

Usamos Kafka como message broker porque:
- Pode lidar com milhÃµes de mensagens/segundo
- Garante que nÃ£o se perdem mensagens
- Permite replay se algo falhar
- Desacopla o sistema de pagamentos do sistema de ML`
        },
        components: ['Kafka', 'MSK', 'API Gateway'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Payment    â”‚â”€â”€â”€â”€â–¶â”‚    Kafka     â”‚â”€â”€â”€â”€â–¶â”‚  ML Scoring  â”‚â”€â”€â”€â”€â–¶â”‚   Decision   â”‚
â”‚   Service    â”‚     â”‚    (MSK)     â”‚     â”‚   Service    â”‚     â”‚   Service    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                       â”‚
                                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                                          â”‚                            â”‚
                                          â–¼                            â–¼
                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                   â”‚   BLOCK    â”‚              â”‚   ALLOW    â”‚
                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      },
      {
        step: 2,
        title: { es: 'Feature Store (Datos en Tiempo Real)', en: 'Feature Store (Real-Time Data)', pt: 'Feature Store (Dados em Tempo Real)' },
        description: {
          es: `El modelo de ML necesita features del usuario en tiempo real:
- Cantidad de transacciones en Ãºltimas 24h
- Monto total gastado hoy
- Ubicaciones recientes
- Dispositivos usados

Usamos Redis como Feature Store porque:
- Latencia < 1ms
- Podemos pre-computar features
- TTL para datos que expiran

Cada transacciÃ³n:
1. Llega a Kafka
2. Consulta Redis para features del usuario
3. EnvÃ­a features + transacciÃ³n al modelo`,
          en: `The ML model needs real-time user features:
- Number of transactions in last 24h
- Total amount spent today
- Recent locations
- Devices used

We use Redis as Feature Store because:
- Latency < 1ms
- We can pre-compute features
- TTL for expiring data

Each transaction:
1. Arrives at Kafka
2. Queries Redis for user features
3. Sends features + transaction to model`,
          pt: `O modelo de ML precisa de features do usuÃ¡rio em tempo real:
- Quantidade de transaÃ§Ãµes nas Ãºltimas 24h
- Valor total gasto hoje
- LocalizaÃ§Ãµes recentes
- Dispositivos usados

Usamos Redis como Feature Store porque:
- LatÃªncia < 1ms
- Podemos prÃ©-computar features
- TTL para dados que expiram

Cada transaÃ§Ã£o:
1. Chega no Kafka
2. Consulta Redis para features do usuÃ¡rio
3. Envia features + transaÃ§Ã£o para o modelo`
        },
        components: ['Redis', 'ElastiCache', 'Feature Store'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Transaction â”‚â”€â”€â”€â”€â–¶â”‚    Kafka     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚   Feature    â”‚â”€â”€â”€â”€â–¶â”‚    Redis     â”‚
                     â”‚  Enrichment  â”‚â—€â”€â”€â”€â”€â”‚ (Features)   â”‚
                     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚  ML Service  â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      },
      {
        step: 3,
        title: { es: 'ML Scoring Service', en: 'ML Scoring Service', pt: 'ML Scoring Service' },
        description: {
          es: `El modelo corre en un servicio dedicado:

OpciÃ³n 1: SageMaker Endpoint
- Managed, auto-scaling
- MÃ¡s caro pero menos mantenimiento

OpciÃ³n 2: EKS con modelo en container
- MÃ¡s control, mÃ¡s barato a escala
- Necesita mÃ¡s DevOps

Para empezar: SageMaker Endpoint con auto-scaling.

El servicio:
1. Recibe features
2. Aplica el modelo (inferencia ~50ms)
3. Devuelve score de riesgo (0-100)
4. Score > 80 â†’ BLOCK
5. Score 50-80 â†’ REVIEW
6. Score < 50 â†’ ALLOW`,
          en: `The model runs in a dedicated service:

Option 1: SageMaker Endpoint
- Managed, auto-scaling
- More expensive but less maintenance

Option 2: EKS with model in container
- More control, cheaper at scale
- Needs more DevOps

To start: SageMaker Endpoint with auto-scaling.

The service:
1. Receives features
2. Applies the model (inference ~50ms)
3. Returns risk score (0-100)
4. Score > 80 â†’ BLOCK
5. Score 50-80 â†’ REVIEW
6. Score < 50 â†’ ALLOW`,
          pt: `O modelo roda em um serviÃ§o dedicado:

OpÃ§Ã£o 1: SageMaker Endpoint
- Managed, auto-scaling
- Mais caro mas menos manutenÃ§Ã£o

OpÃ§Ã£o 2: EKS com modelo em container
- Mais controle, mais barato em escala
- Precisa de mais DevOps

Para comeÃ§ar: SageMaker Endpoint com auto-scaling.

O serviÃ§o:
1. Recebe features
2. Aplica o modelo (inferÃªncia ~50ms)
3. Retorna score de risco (0-100)
4. Score > 80 â†’ BLOCK
5. Score 50-80 â†’ REVIEW
6. Score < 50 â†’ ALLOW`
        },
        components: ['SageMaker', 'EKS', 'Docker'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               ML Scoring Service                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ Feature â”‚â”€â”€â–¶â”‚  Model  â”‚â”€â”€â–¶â”‚  Score  â”‚           â”‚
â”‚  â”‚ Vector  â”‚   â”‚Inferenceâ”‚   â”‚ 0-100   â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜           â”‚
â”‚                                   â”‚                 â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚              â”‚                    â”‚                â”‚â”‚
â”‚              â–¼                    â–¼                â–¼â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         â”‚ BLOCK  â”‚          â”‚ REVIEW â”‚       â”‚ ALLOW  â”‚
â”‚         â”‚ (>80)  â”‚          â”‚(50-80) â”‚       â”‚ (<50)  â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      },
      {
        step: 4,
        title: { es: 'Monitoreo y Feedback Loop', en: 'Monitoring and Feedback Loop', pt: 'Monitoramento e Feedback Loop' },
        description: {
          es: `CrÃ­tico para un sistema de ML en producciÃ³n:

Monitoreo en tiempo real:
- Latencia p50, p95, p99
- Tasa de bloqueo vs allow
- False positives reportados
- Drift del modelo (accuracy decayendo)

Feedback loop para mejorar:
1. Transacciones bloqueadas â†’ RevisiÃ³n manual
2. Usuario reporta "no fui yo" â†’ Etiqueta como fraude
3. Datos vuelven al data lake
4. Reentrenamiento del modelo (semanal)

Alertas:
- Si latencia > 400ms
- Si tasa de bloqueo sube 2x
- Si modelo no responde`,
          en: `Critical for an ML system in production:

Real-time monitoring:
- Latency p50, p95, p99
- Block vs allow rate
- Reported false positives
- Model drift (accuracy decaying)

Feedback loop for improvement:
1. Blocked transactions â†’ Manual review
2. User reports "wasn't me" â†’ Label as fraud
3. Data goes back to data lake
4. Model retraining (weekly)

Alerts:
- If latency > 400ms
- If block rate increases 2x
- If model doesn't respond`,
          pt: `CrÃ­tico para um sistema de ML em produÃ§Ã£o:

Monitoramento em tempo real:
- LatÃªncia p50, p95, p99
- Taxa de block vs allow
- Falsos positivos reportados
- Drift do modelo (accuracy decaindo)

Feedback loop para melhorar:
1. TransaÃ§Ãµes bloqueadas â†’ RevisÃ£o manual
2. UsuÃ¡rio reporta "nÃ£o fui eu" â†’ Etiqueta como fraude
3. Dados voltam ao data lake
4. Retreinamento do modelo (semanal)

Alertas:
- Se latÃªncia > 400ms
- Se taxa de block sobe 2x
- Se modelo nÃ£o responde`
        },
        components: ['CloudWatch', 'Grafana', 'PagerDuty'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Feedback Loop                         â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ Blocked  â”‚â”€â”€â”€â–¶â”‚  Manual  â”‚â”€â”€â”€â–¶â”‚  Label   â”‚          â”‚
â”‚  â”‚   Txn    â”‚    â”‚  Review  â”‚    â”‚  Data    â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                       â”‚                 â”‚
â”‚                                       â–¼                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   New    â”‚â—€â”€â”€â”€â”‚ Retrain  â”‚â—€â”€â”€â”€â”‚   Data   â”‚          â”‚
â”‚  â”‚  Model   â”‚    â”‚  Weekly  â”‚    â”‚   Lake   â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      }
    ],
    tradeoffs: [
      {
        decision: { es: 'Kafka vs Kinesis vs SQS', en: 'Kafka vs Kinesis vs SQS', pt: 'Kafka vs Kinesis vs SQS' },
        option1: { es: 'Kafka (MSK): MÃ¡s flexible, replay infinito, mÃ¡s complejo', en: 'Kafka (MSK): More flexible, infinite replay, more complex', pt: 'Kafka (MSK): Mais flexÃ­vel, replay infinito, mais complexo' },
        option2: { es: 'Kinesis: Full AWS, mÃ¡s simple, retenciÃ³n limitada (7 dÃ­as)', en: 'Kinesis: Full AWS, simpler, limited retention (7 days)', pt: 'Kinesis: Full AWS, mais simples, retenÃ§Ã£o limitada (7 dias)' },
        recommendation: { es: 'Para fraude: Kafka por el replay infinito. PodÃ©s re-procesar meses de datos si encontrÃ¡s un bug.', en: 'For fraud: Kafka for infinite replay. You can re-process months of data if you find a bug.', pt: 'Para fraude: Kafka pelo replay infinito. VocÃª pode re-processar meses de dados se encontrar um bug.' }
      },
      {
        decision: { es: 'SageMaker Endpoint vs Self-hosted', en: 'SageMaker Endpoint vs Self-hosted', pt: 'SageMaker Endpoint vs Self-hosted' },
        option1: { es: 'SageMaker: $$$, pero managed, auto-scaling, A/B testing built-in', en: 'SageMaker: $$$, but managed, auto-scaling, A/B testing built-in', pt: 'SageMaker: $$$, mas managed, auto-scaling, A/B testing built-in' },
        option2: { es: 'EKS self-hosted: MÃ¡s barato, mÃ¡s control, mÃ¡s trabajo de DevOps', en: 'EKS self-hosted: Cheaper, more control, more DevOps work', pt: 'EKS self-hosted: Mais barato, mais controle, mais trabalho de DevOps' },
        recommendation: { es: 'Empezar con SageMaker. Migrar a self-hosted solo si el costo se vuelve prohibitivo.', en: 'Start with SageMaker. Migrate to self-hosted only if cost becomes prohibitive.', pt: 'ComeÃ§ar com SageMaker. Migrar para self-hosted sÃ³ se o custo se tornar proibitivo.' }
      }
    ],
    commonMistakes: [
      { es: 'âŒ Olvidar el fallback si ML falla - las transacciones deben seguir procesÃ¡ndose', en: 'âŒ Forgetting fallback if ML fails - transactions must keep processing', pt: 'âŒ Esquecer o fallback se ML falhar - as transaÃ§Ãµes devem continuar sendo processadas' },
      { es: 'âŒ No considerar el cold start - primera request a modelo reciÃ©n deployado es lenta', en: 'âŒ Not considering cold start - first request to newly deployed model is slow', pt: 'âŒ NÃ£o considerar o cold start - primeira request a modelo recÃ©m deployado Ã© lenta' },
      { es: 'âŒ Procesar features en el request path - pre-computar en Redis', en: 'âŒ Computing features in request path - pre-compute in Redis', pt: 'âŒ Processar features no request path - prÃ©-computar no Redis' },
      { es: 'âŒ No tener un feedback loop para mejorar el modelo', en: 'âŒ Not having a feedback loop to improve the model', pt: 'âŒ NÃ£o ter um feedback loop para melhorar o modelo' }
    ],
    interviewerTips: [
      { es: 'ğŸ’¡ MencionÃ¡ latencia especÃ­fica (500ms) y cÃ³mo cada componente contribuye', en: 'ğŸ’¡ Mention specific latency (500ms) and how each component contributes', pt: 'ğŸ’¡ Mencione latÃªncia especÃ­fica (500ms) e como cada componente contribui' },
      { es: 'ğŸ’¡ HablÃ¡ del fallback antes de que te pregunten - es crÃ­tico en fintech', en: 'ğŸ’¡ Talk about fallback before they ask - it\'s critical in fintech', pt: 'ğŸ’¡ Fale do fallback antes que perguntem - Ã© crÃ­tico em fintech' },
      { es: 'ğŸ’¡ MencionÃ¡ compliance (PCI-DSS) si aplica', en: 'ğŸ’¡ Mention compliance (PCI-DSS) if applicable', pt: 'ğŸ’¡ Mencione compliance (PCI-DSS) se aplicÃ¡vel' },
      { es: 'ğŸ’¡ El feedback loop para ML es diferenciador - demuestra que pensÃ¡s a largo plazo', en: 'ğŸ’¡ The ML feedback loop is a differentiator - shows you think long-term', pt: 'ğŸ’¡ O feedback loop para ML Ã© diferenciador - demonstra que vocÃª pensa a longo prazo' }
    ],
    relatedTopics: ['Kafka', 'Streaming', 'ML', 'Redis', 'SageMaker', 'AWS'],
    estimatedXP: 750
  },

  // ============ INTERVIEW 3: DATA LAKE MIGRATION ============
  {
    id: 'sd-data-lake-migration',
    title: {
      es: 'MigraciÃ³n de Data Warehouse a Data Lake',
      en: 'Data Warehouse to Data Lake Migration',
      pt: 'MigraÃ§Ã£o de Data Warehouse para Data Lake'
    },
    company: 'Enterprise / Empresa grande',
    difficulty: 'senior',
    duration: '60 min',
    tags: ['Migration', 'Data Lake', 'Delta Lake', 'Spark', 'Strategy'],
    problem: {
      es: `Una empresa de retail con 15 aÃ±os de historia tiene todo en un Data Warehouse on-premise (Oracle).
Tienen 50TB de datos histÃ³ricos y el sistema estÃ¡ llegando al lÃ­mite de capacidad.
Quieren migrar a la nube y modernizar su arquitectura.

Restricciones:
- No pueden tener downtime - el negocio depende de los reportes diarios
- Tienen 20 aÃ±os de SQL legacy que no pueden reescribir todo
- Budget de $2M para el proyecto
- Timeline: 18 meses

El CTO pregunta: "Â¿CÃ³mo diseÃ±arÃ­as la estrategia de migraciÃ³n?"`,
      en: `A retail company with 15 years of history has everything in an on-premise Data Warehouse (Oracle).
They have 50TB of historical data and the system is reaching capacity limits.
They want to migrate to cloud and modernize their architecture.

Constraints:
- No downtime allowed - business depends on daily reports
- They have 20 years of legacy SQL they can't rewrite entirely
- Budget of $2M for the project
- Timeline: 18 months

The CTO asks: "How would you design the migration strategy?"`,
      pt: `Uma empresa de varejo com 15 anos de histÃ³ria tem tudo em um Data Warehouse on-premise (Oracle).
Eles tÃªm 50TB de dados histÃ³ricos e o sistema estÃ¡ chegando ao limite de capacidade.
Querem migrar para cloud e modernizar sua arquitetura.

RestriÃ§Ãµes:
- NÃ£o podem ter downtime - o negÃ³cio depende dos relatÃ³rios diÃ¡rios
- TÃªm 20 anos de SQL legacy que nÃ£o podem reescrever tudo
- Budget de $2M para o projeto
- Timeline: 18 meses

O CTO pergunta: "Como vocÃª projetaria a estratÃ©gia de migraÃ§Ã£o?"`
    },
    clarifyingQuestions: [
      {
        question: { es: 'Â¿CuÃ¡ntas tablas y procedimientos tienen?', en: 'How many tables and procedures do you have?', pt: 'Quantas tabelas e procedures vocÃªs tÃªm?' },
        whyAsk: { es: 'Define el scope del proyecto y si es viable en 18 meses', en: 'Defines project scope and if it\'s viable in 18 months', pt: 'Define o escopo do projeto e se Ã© viÃ¡vel em 18 meses' },
        typicalAnswer: { es: '500 tablas, 200 stored procedures, 50 ETL jobs en Informatica', en: '500 tables, 200 stored procedures, 50 ETL jobs in Informatica', pt: '500 tabelas, 200 stored procedures, 50 ETL jobs em Informatica' }
      },
      {
        question: { es: 'Â¿QuÃ© tan crÃ­ticos son los datos? Â¿Hay datos que no se pueden perder?', en: 'How critical is the data? Is there data that cannot be lost?', pt: 'QuÃ£o crÃ­ticos sÃ£o os dados? HÃ¡ dados que nÃ£o podem ser perdidos?' },
        whyAsk: { es: 'Define la estrategia de backup y rollback', en: 'Defines backup and rollback strategy', pt: 'Define a estratÃ©gia de backup e rollback' },
        typicalAnswer: { es: 'Datos de ventas y clientes son crÃ­ticos. Logs histÃ³ricos pueden perderse sin impacto.', en: 'Sales and customer data is critical. Historical logs can be lost without impact.', pt: 'Dados de vendas e clientes sÃ£o crÃ­ticos. Logs histÃ³ricos podem ser perdidos sem impacto.' }
      },
      {
        question: { es: 'Â¿Tienen equipo interno o van a contratar?', en: 'Do you have an internal team or will you hire?', pt: 'TÃªm equipe interna ou vÃ£o contratar?' },
        whyAsk: { es: 'Define si pueden hacer el trabajo o necesitan consultora', en: 'Defines if they can do the work or need a consultancy', pt: 'Define se podem fazer o trabalho ou precisam de consultoria' },
        typicalAnswer: { es: '5 DEs internos con conocimiento de Oracle. Podemos contratar 2-3 mÃ¡s.', en: '5 internal DEs with Oracle knowledge. We can hire 2-3 more.', pt: '5 DEs internos com conhecimento de Oracle. Podemos contratar 2-3 mais.' }
      }
    ],
    requirements: {
      functional: [
        { es: 'Migrar 50TB de datos histÃ³ricos a cloud', en: 'Migrate 50TB of historical data to cloud', pt: 'Migrar 50TB de dados histÃ³ricos para cloud' },
        { es: 'Mantener compatibilidad con SQL existente donde sea posible', en: 'Maintain compatibility with existing SQL where possible', pt: 'Manter compatibilidade com SQL existente onde possÃ­vel' },
        { es: 'Zero downtime para reportes del negocio', en: 'Zero downtime for business reports', pt: 'Zero downtime para relatÃ³rios do negÃ³cio' },
        { es: 'Mejorar performance de queries actuales', en: 'Improve performance of current queries', pt: 'Melhorar performance das queries atuais' }
      ],
      nonFunctional: [
        { es: 'Timeline: 18 meses mÃ¡ximo', en: 'Timeline: 18 months maximum', pt: 'Timeline: 18 meses mÃ¡ximo' },
        { es: 'Budget: $2M incluyendo cloud costs del primer aÃ±o', en: 'Budget: $2M including first year cloud costs', pt: 'Budget: $2M incluindo custos de cloud do primeiro ano' },
        { es: 'Capacidad de rollback si algo sale mal', en: 'Rollback capability if something goes wrong', pt: 'Capacidade de rollback se algo der errado' },
        { es: 'Escalable a 500TB en los prÃ³ximos 5 aÃ±os', en: 'Scalable to 500TB in the next 5 years', pt: 'EscalÃ¡vel a 500TB nos prÃ³ximos 5 anos' }
      ]
    },
    solution: [
      {
        step: 1,
        title: { es: 'Fase 0: Assessment y Planning (Mes 1-2)', en: 'Phase 0: Assessment and Planning (Month 1-2)', pt: 'Fase 0: Assessment e Planning (MÃªs 1-2)' },
        description: {
          es: `Antes de migrar nada, necesitamos entender quÃ© tenemos:

1. Inventario de assets:
   - Catalogar las 500 tablas (tamaÃ±o, uso, dependencias)
   - Documentar los 200 stored procedures
   - Mapear los 50 ETL jobs

2. AnÃ¡lisis de uso:
   - Â¿QuÃ© tablas se usan diariamente?
   - Â¿CuÃ¡les no se tocaron en 2 aÃ±os?
   - Â¿QuÃ© queries son mÃ¡s lentos?

3. PriorizaciÃ³n:
   - Tier 1: CrÃ­tico para el negocio (migrar primero)
   - Tier 2: Importante pero no urgente
   - Tier 3: Nice to have / deprecar

Output: Documento de 50 pÃ¡ginas con plan detallado y risks.`,
          en: `Before migrating anything, we need to understand what we have:

1. Asset inventory:
   - Catalog the 500 tables (size, usage, dependencies)
   - Document the 200 stored procedures
   - Map the 50 ETL jobs

2. Usage analysis:
   - What tables are used daily?
   - Which haven't been touched in 2 years?
   - What queries are slowest?

3. Prioritization:
   - Tier 1: Business critical (migrate first)
   - Tier 2: Important but not urgent
   - Tier 3: Nice to have / deprecate

Output: 50-page document with detailed plan and risks.`,
          pt: `Antes de migrar nada, precisamos entender o que temos:

1. InventÃ¡rio de assets:
   - Catalogar as 500 tabelas (tamanho, uso, dependÃªncias)
   - Documentar os 200 stored procedures
   - Mapear os 50 ETL jobs

2. AnÃ¡lise de uso:
   - Quais tabelas sÃ£o usadas diariamente?
   - Quais nÃ£o foram tocadas em 2 anos?
   - Quais queries sÃ£o mais lentas?

3. PriorizaÃ§Ã£o:
   - Tier 1: CrÃ­tico para o negÃ³cio (migrar primeiro)
   - Tier 2: Importante mas nÃ£o urgente
   - Tier 3: Nice to have / deprecar

Output: Documento de 50 pÃ¡ginas com plano detalhado e riscos.`
        },
        components: ['Excel', 'Documentation', 'Stakeholder meetings'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Assessment Output                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Tier 1 (Critical)    â”‚ 50 tables  â”‚ Migrate first  â”‚â”‚
â”‚  â”‚ Tier 2 (Important)   â”‚ 200 tables â”‚ Month 6-12     â”‚â”‚
â”‚  â”‚ Tier 3 (Deprecate)   â”‚ 250 tables â”‚ Archive/delete â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      },
      {
        step: 2,
        title: { es: 'Fase 1: Dual-Write Architecture (Mes 3-6)', en: 'Phase 1: Dual-Write Architecture (Month 3-6)', pt: 'Fase 1: Arquitetura Dual-Write (MÃªs 3-6)' },
        description: {
          es: `La clave para zero downtime: Dual-Write.

Estrategia:
1. Configurar Data Lake en AWS (S3 + Delta Lake)
2. Todos los nuevos datos van a AMBOS sistemas
3. Oracle sigue siendo el "source of truth"
4. El Data Lake es "read replica" por ahora

TecnologÃ­a:
- AWS DMS para CDC (captura de cambios)
- DMS escribe a S3 en formato Parquet
- Delta Lake encima de S3 para ACID transactions
- Databricks/EMR para procesar

Esto nos da:
- Rollback fÃ¡cil (Oracle sigue funcionando)
- Podemos comparar resultados (Oracle vs Data Lake)
- Cero riesgo para el negocio`,
          en: `The key to zero downtime: Dual-Write.

Strategy:
1. Set up Data Lake in AWS (S3 + Delta Lake)
2. All new data goes to BOTH systems
3. Oracle remains the "source of truth"
4. Data Lake is "read replica" for now

Technology:
- AWS DMS for CDC (change data capture)
- DMS writes to S3 in Parquet format
- Delta Lake on top of S3 for ACID transactions
- Databricks/EMR for processing

This gives us:
- Easy rollback (Oracle keeps working)
- We can compare results (Oracle vs Data Lake)
- Zero risk for the business`,
          pt: `A chave para zero downtime: Dual-Write.

EstratÃ©gia:
1. Configurar Data Lake na AWS (S3 + Delta Lake)
2. Todos os novos dados vÃ£o para AMBOS sistemas
3. Oracle continua sendo o "source of truth"
4. O Data Lake Ã© "read replica" por agora

Tecnologia:
- AWS DMS para CDC (captura de mudanÃ§as)
- DMS escreve no S3 em formato Parquet
- Delta Lake em cima do S3 para ACID transactions
- Databricks/EMR para processar

Isso nos dÃ¡:
- Rollback fÃ¡cil (Oracle continua funcionando)
- Podemos comparar resultados (Oracle vs Data Lake)
- Zero risco para o negÃ³cio`
        },
        components: ['AWS DMS', 'S3', 'Delta Lake', 'Databricks'],
        diagram: `
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Source Systems â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚              â”‚              â”‚
              â–¼              â–¼              â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  Oracle  â”‚   â”‚  Oracle  â”‚   â”‚  AWS S3  â”‚
       â”‚  (Live)  â”‚   â”‚  (Live)  â”‚   â”‚(Data Lake)â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â–²              â”‚              â”‚
              â”‚              â”‚ DMS CDC      â”‚
              â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
        Source of Truth
        (for now)
        `
      },
      {
        step: 3,
        title: { es: 'Fase 2: Historical Data Migration (Mes 4-9)', en: 'Phase 2: Historical Data Migration (Month 4-9)', pt: 'Fase 2: MigraÃ§Ã£o de Dados HistÃ³ricos (MÃªs 4-9)' },
        description: {
          es: `Mientras dual-write corre, migramos los 50TB histÃ³ricos:

Estrategia por volumen:
- Tablas < 1GB: Export directo a Parquet
- Tablas 1-10GB: AWS DMS full load
- Tablas > 10GB: Spark job paralelo (particionar por fecha)

Proceso:
1. Exportar tabla de Oracle
2. Convertir a Parquet (mejor compresiÃ³n)
3. Cargar a S3
4. Registrar en Delta Lake
5. Validar conteo de rows
6. Validar checksums en columnas crÃ­ticas

ParalelizaciÃ³n:
- 10 tablas en paralelo
- Corre en horario nocturno (menos impacto)
- Estimado: 6 meses para todo`,
          en: `While dual-write runs, we migrate the 50TB of historical data:

Strategy by volume:
- Tables < 1GB: Direct export to Parquet
- Tables 1-10GB: AWS DMS full load
- Tables > 10GB: Parallel Spark job (partition by date)

Process:
1. Export table from Oracle
2. Convert to Parquet (better compression)
3. Load to S3
4. Register in Delta Lake
5. Validate row count
6. Validate checksums on critical columns

Parallelization:
- 10 tables in parallel
- Runs at night (less impact)
- Estimated: 6 months for everything`,
          pt: `Enquanto dual-write roda, migramos os 50TB histÃ³ricos:

EstratÃ©gia por volume:
- Tabelas < 1GB: Export direto para Parquet
- Tabelas 1-10GB: AWS DMS full load
- Tabelas > 10GB: Spark job paralelo (particionar por data)

Processo:
1. Exportar tabela do Oracle
2. Converter para Parquet (melhor compressÃ£o)
3. Carregar no S3
4. Registrar no Delta Lake
5. Validar contagem de rows
6. Validar checksums em colunas crÃ­ticas

ParalelizaÃ§Ã£o:
- 10 tabelas em paralelo
- Roda em horÃ¡rio noturno (menos impacto)
- Estimado: 6 meses para tudo`
        },
        components: ['Spark', 'Parquet', 'AWS DMS'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Historical Migration Pipeline            â”‚
â”‚                                                       â”‚
â”‚  Oracle â”€â”€â–¶ Export â”€â”€â–¶ Parquet â”€â”€â–¶ S3 â”€â”€â–¶ Validate  â”‚
â”‚    â”‚                                          â”‚       â”‚
â”‚    â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚    â”‚         â–¼                                        â”‚
â”‚    â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚
â”‚    â””â”€â”€â”€â–¶â”‚ Checksum â”‚ â† If mismatch, re-run           â”‚
â”‚         â”‚  Compare â”‚                                 â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      },
      {
        step: 4,
        title: { es: 'Fase 3: Query Migration y Cutover (Mes 10-18)', en: 'Phase 3: Query Migration and Cutover (Month 10-18)', pt: 'Fase 3: MigraÃ§Ã£o de Queries e Cutover (MÃªs 10-18)' },
        description: {
          es: `Una vez que los datos estÃ¡n en el Data Lake, migramos las queries:

Estrategia:
1. Stored procedures crÃ­ticos â†’ dbt models
2. Reportes en SQL â†’ Mantener en SQL (Databricks SQL)
3. ETL en Informatica â†’ Airflow + Spark

Cutover gradual:
- Semana 1-4: 10% del trÃ¡fico al Data Lake
- Semana 5-8: 50% del trÃ¡fico
- Semana 9-12: 90% del trÃ¡fico
- Semana 13+: 100% (apagar Oracle)

Rollback plan:
- Si hay problemas, volver a Oracle en < 1 hora
- Mantener Oracle en "warm standby" por 3 meses post-migraciÃ³n`,
          en: `Once data is in the Data Lake, we migrate queries:

Strategy:
1. Critical stored procedures â†’ dbt models
2. SQL reports â†’ Keep in SQL (Databricks SQL)
3. ETL in Informatica â†’ Airflow + Spark

Gradual cutover:
- Week 1-4: 10% traffic to Data Lake
- Week 5-8: 50% traffic
- Week 9-12: 90% traffic
- Week 13+: 100% (turn off Oracle)

Rollback plan:
- If problems, return to Oracle in < 1 hour
- Keep Oracle in "warm standby" for 3 months post-migration`,
          pt: `Uma vez que os dados estÃ£o no Data Lake, migramos as queries:

EstratÃ©gia:
1. Stored procedures crÃ­ticos â†’ modelos dbt
2. RelatÃ³rios em SQL â†’ Manter em SQL (Databricks SQL)
3. ETL em Informatica â†’ Airflow + Spark

Cutover gradual:
- Semana 1-4: 10% do trÃ¡fego para Data Lake
- Semana 5-8: 50% do trÃ¡fego
- Semana 9-12: 90% do trÃ¡fego
- Semana 13+: 100% (desligar Oracle)

Plano de rollback:
- Se houver problemas, voltar ao Oracle em < 1 hora
- Manter Oracle em "warm standby" por 3 meses pÃ³s-migraÃ§Ã£o`
        },
        components: ['dbt', 'Airflow', 'Databricks SQL'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Gradual Cutover                          â”‚
â”‚                                                          â”‚
â”‚  Week 1-4:    [â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 10%   â†’ Monitor closely      â”‚
â”‚  Week 5-8:    [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘] 50%   â†’ Compare results      â”‚
â”‚  Week 9-12:   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘] 90%   â†’ Confidence high      â”‚
â”‚  Week 13+:    [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100%  â†’ Oracle off           â”‚
â”‚                                                          â”‚
â”‚  âš ï¸ Rollback: Oracle warm standby for 3 months         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      }
    ],
    tradeoffs: [
      {
        decision: { es: 'Big Bang vs Gradual Migration', en: 'Big Bang vs Gradual Migration', pt: 'Big Bang vs MigraÃ§Ã£o Gradual' },
        option1: { es: 'Big Bang: MÃ¡s rÃ¡pido, mÃ¡s riesgo, todo de una vez', en: 'Big Bang: Faster, more risk, all at once', pt: 'Big Bang: Mais rÃ¡pido, mais risco, tudo de uma vez' },
        option2: { es: 'Gradual: MÃ¡s lento, menos riesgo, rollback fÃ¡cil', en: 'Gradual: Slower, less risk, easy rollback', pt: 'Gradual: Mais lento, menos risco, rollback fÃ¡cil' },
        recommendation: { es: 'Para 50TB y 500 tablas: Gradual. El riesgo de big bang es demasiado alto.', en: 'For 50TB and 500 tables: Gradual. Big bang risk is too high.', pt: 'Para 50TB e 500 tabelas: Gradual. O risco de big bang Ã© muito alto.' }
      },
      {
        decision: { es: 'Rewrite vs Lift-and-Shift', en: 'Rewrite vs Lift-and-Shift', pt: 'Rewrite vs Lift-and-Shift' },
        option1: { es: 'Rewrite: Mejor arquitectura, pero 3x tiempo y costo', en: 'Rewrite: Better architecture, but 3x time and cost', pt: 'Rewrite: Melhor arquitetura, mas 3x tempo e custo' },
        option2: { es: 'Lift-and-Shift: MÃ¡s rÃ¡pido, pero arrastrÃ¡s deuda tÃ©cnica', en: 'Lift-and-Shift: Faster, but you carry technical debt', pt: 'Lift-and-Shift: Mais rÃ¡pido, mas arrasta dÃ­vida tÃ©cnica' },
        recommendation: { es: 'HÃ­brido: Lift-and-shift para 80%, rewrite para el 20% crÃ­tico.', en: 'Hybrid: Lift-and-shift for 80%, rewrite for critical 20%.', pt: 'HÃ­brido: Lift-and-shift para 80%, rewrite para os 20% crÃ­ticos.' }
      }
    ],
    commonMistakes: [
      { es: 'âŒ Subestimar el tiempo de validaciÃ³n de datos', en: 'âŒ Underestimating data validation time', pt: 'âŒ Subestimar o tempo de validaÃ§Ã£o de dados' },
      { es: 'âŒ No tener plan de rollback', en: 'âŒ Not having a rollback plan', pt: 'âŒ NÃ£o ter plano de rollback' },
      { es: 'âŒ Intentar migrar todo de una vez', en: 'âŒ Trying to migrate everything at once', pt: 'âŒ Tentar migrar tudo de uma vez' },
      { es: 'âŒ Olvidar los stored procedures y solo pensar en tablas', en: 'âŒ Forgetting stored procedures and only thinking about tables', pt: 'âŒ Esquecer os stored procedures e sÃ³ pensar em tabelas' },
      { es: 'âŒ No involucrar a los usuarios de negocio en las validaciones', en: 'âŒ Not involving business users in validations', pt: 'âŒ NÃ£o envolver os usuÃ¡rios de negÃ³cio nas validaÃ§Ãµes' }
    ],
    interviewerTips: [
      { es: 'ğŸ’¡ EmpezÃ¡ por el assessment - demuestra que no te lanzÃ¡s a codear sin entender', en: 'ğŸ’¡ Start with assessment - shows you don\'t jump to coding without understanding', pt: 'ğŸ’¡ Comece pelo assessment - demonstra que vocÃª nÃ£o pula para codear sem entender' },
      { es: 'ğŸ’¡ Dual-write es la clave para zero downtime - explicalo bien', en: 'ğŸ’¡ Dual-write is the key to zero downtime - explain it well', pt: 'ğŸ’¡ Dual-write Ã© a chave para zero downtime - explique bem' },
      { es: 'ğŸ’¡ MencionÃ¡ validaciÃ³n de datos - es el 50% del trabajo real', en: 'ğŸ’¡ Mention data validation - it\'s 50% of the real work', pt: 'ğŸ’¡ Mencione validaÃ§Ã£o de dados - Ã© 50% do trabalho real' },
      { es: 'ğŸ’¡ Tener un rollback plan demuestra madurez senior', en: 'ğŸ’¡ Having a rollback plan shows senior maturity', pt: 'ğŸ’¡ Ter um plano de rollback demonstra maturidade senior' }
    ],
    relatedTopics: ['Migration', 'Data Lake', 'Delta Lake', 'AWS DMS', 'Spark', 'Enterprise'],
    estimatedXP: 1000
  },

  // ============ INTERVIEW 4: CDC PIPELINE ============
  {
    id: 'sd-cdc-pipeline',
    title: {
      es: 'Pipeline de Change Data Capture (CDC)',
      en: 'Change Data Capture (CDC) Pipeline',
      pt: 'Pipeline de Change Data Capture (CDC)'
    },
    company: 'SaaS / Startup Tech',
    difficulty: 'mid',
    duration: '45 min',
    tags: ['CDC', 'Debezium', 'Kafka', 'Real-time', 'PostgreSQL'],
    problem: {
      es: `Una startup SaaS tiene su aplicaciÃ³n principal en PostgreSQL con 50 tablas crÃ­ticas.
Necesitan sincronizar estos datos en near-real-time con:
1. Un Data Warehouse (Snowflake) para analytics
2. Un sistema de bÃºsqueda (Elasticsearch) para la app
3. Un cache (Redis) para datos de usuarios

Actualmente hacen un dump diario que tarda 4 horas y causa locks en producciÃ³n.

El CTO pregunta: "Â¿CÃ³mo diseÃ±arÃ­as un pipeline CDC para sincronizar en tiempo real sin afectar producciÃ³n?"`,
      en: `A SaaS startup has their main application on PostgreSQL with 50 critical tables.
They need to sync this data in near-real-time with:
1. A Data Warehouse (Snowflake) for analytics
2. A search system (Elasticsearch) for the app
3. A cache (Redis) for user data

Currently they do a daily dump that takes 4 hours and causes locks in production.

The CTO asks: "How would you design a CDC pipeline to sync in real-time without affecting production?"`,
      pt: `Uma startup SaaS tem sua aplicaÃ§Ã£o principal em PostgreSQL com 50 tabelas crÃ­ticas.
Eles precisam sincronizar esses dados em near-real-time com:
1. Um Data Warehouse (Snowflake) para analytics
2. Um sistema de busca (Elasticsearch) para a app
3. Um cache (Redis) para dados de usuÃ¡rios

Atualmente fazem um dump diÃ¡rio que leva 4 horas e causa locks em produÃ§Ã£o.

O CTO pergunta: "Como vocÃª projetaria um pipeline CDC para sincronizar em tempo real sem afetar produÃ§Ã£o?"`
    },
    clarifyingQuestions: [
      {
        question: { es: 'Â¿CuÃ¡l es el volumen de cambios por segundo?', en: 'What is the volume of changes per second?', pt: 'Qual Ã© o volume de mudanÃ§as por segundo?' },
        whyAsk: { es: 'Define el sizing de Kafka y si necesitamos particionamiento', en: 'Defines Kafka sizing and if we need partitioning', pt: 'Define o dimensionamento do Kafka e se precisamos de particionamento' },
        typicalAnswer: { es: 'Unos 1000 cambios/segundo en picos, 100/segundo promedio', en: 'About 1000 changes/second at peak, 100/second average', pt: 'Uns 1000 mudanÃ§as/segundo em picos, 100/segundo em mÃ©dia' }
      },
      {
        question: { es: 'Â¿Necesitan garantÃ­a de orden en los cambios?', en: 'Do you need ordering guarantees on changes?', pt: 'Precisam de garantia de ordem nas mudanÃ§as?' },
        whyAsk: { es: 'Si el orden importa, necesitamos particiÃ³n por key en Kafka', en: 'If order matters, we need partition by key in Kafka', pt: 'Se a ordem importa, precisamos de partiÃ§Ã£o por key no Kafka' },
        typicalAnswer: { es: 'SÃ­, para una misma entidad los cambios deben llegar en orden', en: 'Yes, for the same entity changes must arrive in order', pt: 'Sim, para uma mesma entidade as mudanÃ§as devem chegar em ordem' }
      },
      {
        question: { es: 'Â¿QuÃ© pasa si perdemos un evento? Â¿Es crÃ­tico?', en: 'What happens if we lose an event? Is it critical?', pt: 'O que acontece se perdermos um evento? Ã‰ crÃ­tico?' },
        whyAsk: { es: 'Define si necesitamos exactly-once o si at-least-once alcanza', en: 'Defines if we need exactly-once or if at-least-once is enough', pt: 'Define se precisamos de exactly-once ou se at-least-once Ã© suficiente' },
        typicalAnswer: { es: 'At-least-once estÃ¡ bien, podemos manejar duplicados', en: 'At-least-once is fine, we can handle duplicates', pt: 'At-least-once estÃ¡ ok, podemos lidar com duplicados' }
      }
    ],
    requirements: {
      functional: [
        { es: 'Capturar cambios de 50 tablas PostgreSQL en near-real-time', en: 'Capture changes from 50 PostgreSQL tables in near-real-time', pt: 'Capturar mudanÃ§as de 50 tabelas PostgreSQL em near-real-time' },
        { es: 'Enviar a Snowflake, Elasticsearch y Redis', en: 'Send to Snowflake, Elasticsearch and Redis', pt: 'Enviar para Snowflake, Elasticsearch e Redis' },
        { es: 'Mantener orden de eventos por entidad', en: 'Maintain event order per entity', pt: 'Manter ordem de eventos por entidade' },
        { es: 'No afectar performance de producciÃ³n', en: 'Not affect production performance', pt: 'NÃ£o afetar performance de produÃ§Ã£o' }
      ],
      nonFunctional: [
        { es: 'Latencia < 30 segundos end-to-end', en: 'Latency < 30 seconds end-to-end', pt: 'LatÃªncia < 30 segundos end-to-end' },
        { es: 'Disponibilidad 99.9%', en: 'Availability 99.9%', pt: 'Disponibilidade 99.9%' },
        { es: 'Escalable a 10x el volumen actual', en: 'Scalable to 10x current volume', pt: 'EscalÃ¡vel a 10x o volume atual' }
      ]
    },
    solution: [
      {
        step: 1,
        title: { es: 'CDC con Debezium', en: 'CDC with Debezium', pt: 'CDC com Debezium' },
        description: {
          es: `Debezium es el estÃ¡ndar open-source para CDC:

1. Lee el WAL (Write-Ahead Log) de PostgreSQL
2. NO hace queries a las tablas (cero impacto en prod)
3. Captura INSERTs, UPDATEs, DELETEs
4. EnvÃ­a eventos a Kafka

ConfiguraciÃ³n PostgreSQL:
- wal_level = logical
- max_replication_slots = 4
- max_wal_senders = 4

Cada cambio se convierte en un evento JSON con:
- before: estado anterior
- after: estado nuevo
- op: tipo de operaciÃ³n (c/u/d)
- ts_ms: timestamp`,
          en: `Debezium is the open-source standard for CDC:

1. Reads PostgreSQL's WAL (Write-Ahead Log)
2. Does NOT query tables (zero prod impact)
3. Captures INSERTs, UPDATEs, DELETEs
4. Sends events to Kafka

PostgreSQL configuration:
- wal_level = logical
- max_replication_slots = 4
- max_wal_senders = 4

Each change becomes a JSON event with:
- before: previous state
- after: new state
- op: operation type (c/u/d)
- ts_ms: timestamp`,
          pt: `Debezium Ã© o padrÃ£o open-source para CDC:

1. LÃª o WAL (Write-Ahead Log) do PostgreSQL
2. NÃƒO faz queries nas tabelas (zero impacto em prod)
3. Captura INSERTs, UPDATEs, DELETEs
4. Envia eventos para Kafka

ConfiguraÃ§Ã£o PostgreSQL:
- wal_level = logical
- max_replication_slots = 4
- max_wal_senders = 4

Cada mudanÃ§a vira um evento JSON com:
- before: estado anterior
- after: estado novo
- op: tipo de operaÃ§Ã£o (c/u/d)
- ts_ms: timestamp`
        },
        components: ['Debezium', 'PostgreSQL', 'Kafka Connect'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL  â”‚â”€â”€â”€â”€â–¶â”‚   Debezium   â”‚â”€â”€â”€â”€â–¶â”‚    Kafka     â”‚
â”‚     WAL      â”‚     â”‚  Connector   â”‚     â”‚   Topics     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                 â”‚
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚                    â”‚                    â”‚
                            â–¼                    â–¼                    â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚ Snowflake  â”‚       â”‚Elasticsearchâ”‚      â”‚   Redis    â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      },
      {
        step: 2,
        title: { es: 'Kafka como Hub Central', en: 'Kafka as Central Hub', pt: 'Kafka como Hub Central' },
        description: {
          es: `Kafka actÃºa como buffer y distribuidor:

Estructura de topics:
- dbserver.schema.table (1 topic por tabla)
- Particionado por primary key (garantiza orden)

RetenciÃ³n:
- 7 dÃ­as mÃ­nimo (permite replay)
- Compaction para tablas dimensionales

Consumer Groups:
- cg-snowflake: Lee todos los topics
- cg-elasticsearch: Solo tablas de bÃºsqueda
- cg-redis: Solo tablas de usuarios

Cada consumer puede ir a su ritmo sin afectar a otros.`,
          en: `Kafka acts as buffer and distributor:

Topic structure:
- dbserver.schema.table (1 topic per table)
- Partitioned by primary key (guarantees order)

Retention:
- 7 days minimum (allows replay)
- Compaction for dimensional tables

Consumer Groups:
- cg-snowflake: Reads all topics
- cg-elasticsearch: Only search tables
- cg-redis: Only user tables

Each consumer can go at its own pace without affecting others.`,
          pt: `Kafka atua como buffer e distribuidor:

Estrutura de topics:
- dbserver.schema.table (1 topic por tabela)
- Particionado por primary key (garante ordem)

RetenÃ§Ã£o:
- 7 dias mÃ­nimo (permite replay)
- Compaction para tabelas dimensionais

Consumer Groups:
- cg-snowflake: LÃª todos os topics
- cg-elasticsearch: SÃ³ tabelas de busca
- cg-redis: SÃ³ tabelas de usuÃ¡rios

Cada consumer pode ir no seu ritmo sem afetar os outros.`
        },
        components: ['Kafka', 'MSK', 'Consumer Groups'],
        diagram: `
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚           Kafka                  â”‚
                     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
                     â”‚  â”‚ users.public.customers      â”‚â”‚
                     â”‚  â”‚ [p0] [p1] [p2] [p3]        â”‚â”‚
                     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
                     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
                     â”‚  â”‚ users.public.orders         â”‚â”‚
                     â”‚  â”‚ [p0] [p1] [p2] [p3]        â”‚â”‚
                     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      },
      {
        step: 3,
        title: { es: 'Consumers EspecÃ­ficos', en: 'Specific Consumers', pt: 'Consumers EspecÃ­ficos' },
        description: {
          es: `Cada destino tiene su consumer optimizado:

Snowflake Consumer:
- Flink job que hace micro-batches (cada 30 seg)
- MERGE INTO para upserts eficientes
- Maneja schema evolution automÃ¡tico

Elasticsearch Consumer:
- Kafka Connect con Elasticsearch Sink
- Bulk indexing cada 5 segundos
- Dead letter queue para errores

Redis Consumer:
- AplicaciÃ³n Go/Rust para baja latencia
- Actualiza solo campos que cambiaron
- TTL automÃ¡tico para datos viejos

Importante: Cada consumer tiene su propia lÃ³gica de retry y DLQ.`,
          en: `Each destination has its optimized consumer:

Snowflake Consumer:
- Flink job doing micro-batches (every 30 sec)
- MERGE INTO for efficient upserts
- Handles schema evolution automatically

Elasticsearch Consumer:
- Kafka Connect with Elasticsearch Sink
- Bulk indexing every 5 seconds
- Dead letter queue for errors

Redis Consumer:
- Go/Rust application for low latency
- Updates only changed fields
- Automatic TTL for old data

Important: Each consumer has its own retry and DLQ logic.`,
          pt: `Cada destino tem seu consumer otimizado:

Snowflake Consumer:
- Flink job fazendo micro-batches (a cada 30 seg)
- MERGE INTO para upserts eficientes
- Lida com schema evolution automaticamente

Elasticsearch Consumer:
- Kafka Connect com Elasticsearch Sink
- Bulk indexing a cada 5 segundos
- Dead letter queue para erros

Redis Consumer:
- AplicaÃ§Ã£o Go/Rust para baixa latÃªncia
- Atualiza sÃ³ campos que mudaram
- TTL automÃ¡tico para dados velhos

Importante: Cada consumer tem sua prÃ³pria lÃ³gica de retry e DLQ.`
        },
        components: ['Flink', 'Kafka Connect', 'Go/Rust'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Snowflake   â”‚     â”‚Elasticsearch â”‚     â”‚    Redis     â”‚
â”‚   Consumer   â”‚     â”‚   Sink       â”‚     â”‚   Consumer   â”‚
â”‚  (Flink)     â”‚     â”‚(Kafka Connect)â”‚    â”‚   (Go)       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                    â”‚                    â”‚
       â”‚ MERGE INTO         â”‚ Bulk Index         â”‚ SET/HSET
       â–¼                    â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Snowflake   â”‚     â”‚Elasticsearch â”‚     â”‚    Redis     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      },
      {
        step: 4,
        title: { es: 'Monitoreo y Recovery', en: 'Monitoring and Recovery', pt: 'Monitoramento e Recovery' },
        description: {
          es: `Monitoreo crÃ­tico para CDC:

MÃ©tricas clave:
- Lag de replicaciÃ³n (Debezium â†’ Kafka)
- Lag de consumers (Kafka â†’ destinos)
- Eventos en DLQ por destino
- Latencia end-to-end (p50, p99)

Alertas:
- Lag > 5 minutos
- DLQ > 100 mensajes
- Consumer detenido > 1 minuto

Recovery:
- Si Debezium falla: Replay desde LSN guardado
- Si consumer falla: Resume desde offset de Kafka
- Si destino falla: DLQ + retry automÃ¡tico`,
          en: `Critical monitoring for CDC:

Key metrics:
- Replication lag (Debezium â†’ Kafka)
- Consumer lag (Kafka â†’ destinations)
- Events in DLQ per destination
- End-to-end latency (p50, p99)

Alerts:
- Lag > 5 minutes
- DLQ > 100 messages
- Consumer stopped > 1 minute

Recovery:
- If Debezium fails: Replay from saved LSN
- If consumer fails: Resume from Kafka offset
- If destination fails: DLQ + automatic retry`,
          pt: `Monitoramento crÃ­tico para CDC:

MÃ©tricas chave:
- Lag de replicaÃ§Ã£o (Debezium â†’ Kafka)
- Lag de consumers (Kafka â†’ destinos)
- Eventos em DLQ por destino
- LatÃªncia end-to-end (p50, p99)

Alertas:
- Lag > 5 minutos
- DLQ > 100 mensagens
- Consumer parado > 1 minuto

Recovery:
- Se Debezium falha: Replay do LSN salvo
- Se consumer falha: Resume do offset do Kafka
- Se destino falha: DLQ + retry automÃ¡tico`
        },
        components: ['Prometheus', 'Grafana', 'PagerDuty'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Monitoring Dashboard                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Debezium    â”‚  â”‚  Consumer   â”‚  â”‚    DLQ      â”‚     â”‚
â”‚  â”‚ Lag: 2s     â”‚  â”‚  Lag: 15s   â”‚  â”‚ Count: 3    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ End-to-End Latency: p50=5s, p99=25s            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      }
    ],
    tradeoffs: [
      {
        decision: { es: 'Debezium vs AWS DMS', en: 'Debezium vs AWS DMS', pt: 'Debezium vs AWS DMS' },
        option1: { es: 'Debezium: Open source, mÃ¡s control, necesita infra', en: 'Debezium: Open source, more control, needs infra', pt: 'Debezium: Open source, mais controle, precisa de infra' },
        option2: { es: 'AWS DMS: Managed, menos control, mÃ¡s caro', en: 'AWS DMS: Managed, less control, more expensive', pt: 'AWS DMS: Managed, menos controle, mais caro' },
        recommendation: { es: 'Debezium si tenÃ©s el equipo para mantenerlo. DMS si querÃ©s simplificar ops.', en: 'Debezium if you have the team to maintain it. DMS if you want to simplify ops.', pt: 'Debezium se tem o time para manter. DMS se quer simplificar ops.' }
      },
      {
        decision: { es: 'Kafka vs Kinesis para eventos', en: 'Kafka vs Kinesis for events', pt: 'Kafka vs Kinesis para eventos' },
        option1: { es: 'Kafka: RetenciÃ³n ilimitada, replay, mÃ¡s complejo', en: 'Kafka: Unlimited retention, replay, more complex', pt: 'Kafka: RetenÃ§Ã£o ilimitada, replay, mais complexo' },
        option2: { es: 'Kinesis: MÃ¡s simple, retenciÃ³n 7 dÃ­as max, menos features', en: 'Kinesis: Simpler, 7 day max retention, fewer features', pt: 'Kinesis: Mais simples, retenÃ§Ã£o 7 dias max, menos features' },
        recommendation: { es: 'Kafka para CDC - necesitÃ¡s replay largo y particionamiento por key.', en: 'Kafka for CDC - you need long replay and partitioning by key.', pt: 'Kafka para CDC - vocÃª precisa de replay longo e particionamento por key.' }
      }
    ],
    commonMistakes: [
      { es: 'âŒ Hacer queries a las tablas en lugar de leer el WAL', en: 'âŒ Querying tables instead of reading the WAL', pt: 'âŒ Fazer queries nas tabelas em vez de ler o WAL' },
      { es: 'âŒ No particionar por key - pierde garantÃ­a de orden', en: 'âŒ Not partitioning by key - loses ordering guarantee', pt: 'âŒ NÃ£o particionar por key - perde garantia de ordem' },
      { es: 'âŒ Un solo consumer para todos los destinos', en: 'âŒ One consumer for all destinations', pt: 'âŒ Um sÃ³ consumer para todos os destinos' },
      { es: 'âŒ No tener DLQ - eventos perdidos sin forma de recuperar', en: 'âŒ No DLQ - lost events with no way to recover', pt: 'âŒ NÃ£o ter DLQ - eventos perdidos sem forma de recuperar' }
    ],
    interviewerTips: [
      { es: 'ğŸ’¡ MencionÃ¡ que CDC lee el WAL, no hace queries', en: 'ğŸ’¡ Mention that CDC reads the WAL, doesn\'t query', pt: 'ğŸ’¡ Mencione que CDC lÃª o WAL, nÃ£o faz queries' },
      { es: 'ğŸ’¡ ExplicÃ¡ por quÃ© cada destino necesita su consumer', en: 'ğŸ’¡ Explain why each destination needs its own consumer', pt: 'ğŸ’¡ Explique por que cada destino precisa de seu prÃ³prio consumer' },
      { es: 'ğŸ’¡ HablÃ¡ de idempotencia para manejar duplicados', en: 'ğŸ’¡ Talk about idempotency to handle duplicates', pt: 'ğŸ’¡ Fale de idempotÃªncia para lidar com duplicados' }
    ],
    relatedTopics: ['CDC', 'Debezium', 'Kafka', 'PostgreSQL', 'Event Sourcing'],
    estimatedXP: 650
  },

  // ============ INTERVIEW 5: STREAMING ANALYTICS ============
  {
    id: 'sd-streaming-analytics',
    title: {
      es: 'Plataforma de Analytics en Tiempo Real',
      en: 'Real-Time Analytics Platform',
      pt: 'Plataforma de Analytics em Tempo Real'
    },
    company: 'AdTech / Gaming',
    difficulty: 'mid',
    duration: '45 min',
    tags: ['Streaming', 'Flink', 'Kafka', 'Analytics', 'Real-time'],
    problem: {
      es: `Una empresa de gaming mobile tiene 10 millones de usuarios activos diarios.
Necesitan analytics en tiempo real para:
1. Dashboard de mÃ©tricas live (DAU, sesiones, revenue)
2. DetecciÃ³n de anomalÃ­as (drops en engagement)
3. A/B testing con resultados en minutos, no dÃ­as

Actualmente procesan con Spark batch cada hora - demasiado lento para reaccionar.

El CTO pregunta: "Â¿CÃ³mo diseÃ±arÃ­as una plataforma de analytics en tiempo real?"`,
      en: `A mobile gaming company has 10 million daily active users.
They need real-time analytics for:
1. Live metrics dashboard (DAU, sessions, revenue)
2. Anomaly detection (drops in engagement)
3. A/B testing with results in minutes, not days

Currently they process with Spark batch every hour - too slow to react.

The CTO asks: "How would you design a real-time analytics platform?"`,
      pt: `Uma empresa de gaming mobile tem 10 milhÃµes de usuÃ¡rios ativos diÃ¡rios.
Eles precisam de analytics em tempo real para:
1. Dashboard de mÃ©tricas live (DAU, sessÃµes, revenue)
2. DetecÃ§Ã£o de anomalias (quedas em engagement)
3. A/B testing com resultados em minutos, nÃ£o dias

Atualmente processam com Spark batch a cada hora - muito lento para reagir.

O CTO pergunta: "Como vocÃª projetaria uma plataforma de analytics em tempo real?"`
    },
    clarifyingQuestions: [
      {
        question: { es: 'Â¿CuÃ¡ntos eventos por segundo generan?', en: 'How many events per second do you generate?', pt: 'Quantos eventos por segundo vocÃªs geram?' },
        whyAsk: { es: 'Define el sizing de Kafka y Flink', en: 'Defines Kafka and Flink sizing', pt: 'Define o dimensionamento do Kafka e Flink' },
        typicalAnswer: { es: '100K eventos/segundo en pico', en: '100K events/second at peak', pt: '100K eventos/segundo em pico' }
      },
      {
        question: { es: 'Â¿QuÃ© granularidad necesitan? Â¿Por minuto, por 5 min?', en: 'What granularity do you need? Per minute, per 5 min?', pt: 'Que granularidade precisam? Por minuto, por 5 min?' },
        whyAsk: { es: 'Define el window size en el streaming', en: 'Defines the window size in streaming', pt: 'Define o tamanho da janela no streaming' },
        typicalAnswer: { es: 'MÃ©tricas por minuto para el dashboard, por 5 min para alertas', en: 'Per minute metrics for dashboard, per 5 min for alerts', pt: 'MÃ©tricas por minuto para o dashboard, por 5 min para alertas' }
      },
      {
        question: { es: 'Â¿Necesitan datos histÃ³ricos tambiÃ©n o solo real-time?', en: 'Do you need historical data too or just real-time?', pt: 'Precisam de dados histÃ³ricos tambÃ©m ou sÃ³ real-time?' },
        whyAsk: { es: 'Si necesitan histÃ³rico, vamos a necesitar una Lambda architecture', en: 'If they need historical, we\'ll need a Lambda architecture', pt: 'Se precisam de histÃ³rico, vamos precisar de uma Lambda architecture' },
        typicalAnswer: { es: 'Ambos - real-time para el dÃ­a, histÃ³rico para comparar con ayer/semana pasada', en: 'Both - real-time for today, historical to compare with yesterday/last week', pt: 'Ambos - real-time para o dia, histÃ³rico para comparar com ontem/semana passada' }
      }
    ],
    requirements: {
      functional: [
        { es: 'Procesar 100K eventos/segundo', en: 'Process 100K events/second', pt: 'Processar 100K eventos/segundo' },
        { es: 'Dashboard con latencia < 1 minuto', en: 'Dashboard with latency < 1 minute', pt: 'Dashboard com latÃªncia < 1 minuto' },
        { es: 'Alertas de anomalÃ­as en < 5 minutos', en: 'Anomaly alerts in < 5 minutes', pt: 'Alertas de anomalias em < 5 minutos' },
        { es: 'A/B testing con significancia estadÃ­stica en tiempo real', en: 'A/B testing with statistical significance in real-time', pt: 'A/B testing com significÃ¢ncia estatÃ­stica em tempo real' }
      ],
      nonFunctional: [
        { es: 'Escalable a 1M eventos/segundo', en: 'Scalable to 1M events/second', pt: 'EscalÃ¡vel a 1M eventos/segundo' },
        { es: 'Disponibilidad 99.9%', en: 'Availability 99.9%', pt: 'Disponibilidade 99.9%' },
        { es: 'Costo optimizado (no sobre-provisionear)', en: 'Cost optimized (don\'t over-provision)', pt: 'Custo otimizado (nÃ£o super-provisionar)' }
      ]
    },
    solution: [
      {
        step: 1,
        title: { es: 'Ingesta con Kafka', en: 'Ingestion with Kafka', pt: 'IngestÃ£o com Kafka' },
        description: {
          es: `Kafka como buffer de entrada:

Topics:
- game-events: Todos los eventos del juego
- purchases: Eventos de compra (separado para prioridad)

Particionamiento:
- Por user_id para mantener orden por usuario
- 100 particiones (permite 100 consumers paralelos)

Producers:
- SDK del juego envÃ­a a Kafka via API Gateway
- Compression: lz4 (mejor balance velocidad/tamaÃ±o)
- Batch: 100ms o 1000 eventos`,
          en: `Kafka as input buffer:

Topics:
- game-events: All game events
- purchases: Purchase events (separate for priority)

Partitioning:
- By user_id to maintain order per user
- 100 partitions (allows 100 parallel consumers)

Producers:
- Game SDK sends to Kafka via API Gateway
- Compression: lz4 (best speed/size balance)
- Batch: 100ms or 1000 events`,
          pt: `Kafka como buffer de entrada:

Topics:
- game-events: Todos os eventos do jogo
- purchases: Eventos de compra (separado para prioridade)

Particionamento:
- Por user_id para manter ordem por usuÃ¡rio
- 100 partiÃ§Ãµes (permite 100 consumers paralelos)

Producers:
- SDK do jogo envia para Kafka via API Gateway
- CompressÃ£o: lz4 (melhor balanÃ§o velocidade/tamanho)
- Batch: 100ms ou 1000 eventos`
        },
        components: ['Kafka', 'API Gateway', 'Game SDK'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Mobile     â”‚â”€â”€â”€â”€â–¶â”‚ API Gateway  â”‚â”€â”€â”€â”€â–¶â”‚    Kafka     â”‚
â”‚    Game      â”‚     â”‚  (throttle)  â”‚     â”‚   Topics     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                 â”‚
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚                                         â”‚
                            â–¼                                         â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚game-events â”‚                           â”‚ purchases  â”‚
                     â”‚ (100 part) â”‚                           â”‚ (10 part)  â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      },
      {
        step: 2,
        title: { es: 'Procesamiento con Flink', en: 'Processing with Flink', pt: 'Processamento com Flink' },
        description: {
          es: `Apache Flink para procesamiento streaming:

Jobs paralelos:
1. Metrics Aggregator
   - Window: 1 minuto tumbling
   - MÃ©tricas: DAU, sessions, events por tipo
   - Output: metrics topic

2. Anomaly Detector
   - Window: 5 minutos sliding
   - Compara con baseline (histÃ³rico)
   - Output: alerts topic

3. A/B Analyzer
   - Agrupa por experimento y variante
   - Calcula conversion rate con intervalo de confianza
   - Output: experiments topic

Checkpointing cada 30 segundos para recovery.`,
          en: `Apache Flink for streaming processing:

Parallel jobs:
1. Metrics Aggregator
   - Window: 1 minute tumbling
   - Metrics: DAU, sessions, events by type
   - Output: metrics topic

2. Anomaly Detector
   - Window: 5 minutes sliding
   - Compares with baseline (historical)
   - Output: alerts topic

3. A/B Analyzer
   - Groups by experiment and variant
   - Calculates conversion rate with confidence interval
   - Output: experiments topic

Checkpointing every 30 seconds for recovery.`,
          pt: `Apache Flink para processamento streaming:

Jobs paralelos:
1. Metrics Aggregator
   - Janela: 1 minuto tumbling
   - MÃ©tricas: DAU, sessÃµes, eventos por tipo
   - Output: metrics topic

2. Anomaly Detector
   - Janela: 5 minutos sliding
   - Compara com baseline (histÃ³rico)
   - Output: alerts topic

3. A/B Analyzer
   - Agrupa por experimento e variante
   - Calcula taxa de conversÃ£o com intervalo de confianÃ§a
   - Output: experiments topic

Checkpointing a cada 30 segundos para recovery.`
        },
        components: ['Apache Flink', 'Flink SQL', 'Checkpointing'],
        diagram: `
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚         Apache Flink            â”‚
                     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
                     â”‚  â”‚   Metrics Aggregator        â”‚â”‚
                     â”‚  â”‚   Window: 1 min             â”‚â”‚
                     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
                     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
                     â”‚  â”‚   Anomaly Detector          â”‚â”‚
                     â”‚  â”‚   Window: 5 min sliding     â”‚â”‚
                     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
                     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
                     â”‚  â”‚   A/B Analyzer              â”‚â”‚
                     â”‚  â”‚   Window: continuous        â”‚â”‚
                     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      },
      {
        step: 3,
        title: { es: 'Serving Layer', en: 'Serving Layer', pt: 'Serving Layer' },
        description: {
          es: `Dos capas de serving para diferentes casos de uso:

Real-time (hot):
- Redis TimeSeries para mÃ©tricas recientes
- RetenciÃ³n: Ãºltimas 24 horas
- Granularidad: 1 minuto
- Queries: O(1) para Ãºltimo valor, O(n) para rango

HistÃ³rico (warm):
- ClickHouse para analytics
- RetenciÃ³n: 2 aÃ±os
- Granularidad: 1 minuto
- Queries: Sub-segundo para agregaciones

El dashboard consulta ambos:
- Ãšltimas 24h â†’ Redis
- ComparaciÃ³n histÃ³rica â†’ ClickHouse`,
          en: `Two serving layers for different use cases:

Real-time (hot):
- Redis TimeSeries for recent metrics
- Retention: last 24 hours
- Granularity: 1 minute
- Queries: O(1) for latest value, O(n) for range

Historical (warm):
- ClickHouse for analytics
- Retention: 2 years
- Granularity: 1 minute
- Queries: Sub-second for aggregations

Dashboard queries both:
- Last 24h â†’ Redis
- Historical comparison â†’ ClickHouse`,
          pt: `Duas camadas de serving para diferentes casos de uso:

Real-time (hot):
- Redis TimeSeries para mÃ©tricas recentes
- RetenÃ§Ã£o: Ãºltimas 24 horas
- Granularidade: 1 minuto
- Queries: O(1) para Ãºltimo valor, O(n) para range

HistÃ³rico (warm):
- ClickHouse para analytics
- RetenÃ§Ã£o: 2 anos
- Granularidade: 1 minuto
- Queries: Sub-segundo para agregaÃ§Ãµes

O dashboard consulta ambos:
- Ãšltimas 24h â†’ Redis
- ComparaÃ§Ã£o histÃ³rica â†’ ClickHouse`
        },
        components: ['Redis TimeSeries', 'ClickHouse', 'Grafana'],
        diagram: `
                            Flink Output
                                 â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚                  â”‚                  â”‚
              â–¼                  â–¼                  â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚   Redis    â”‚     â”‚ ClickHouse â”‚     â”‚   Alerts   â”‚
       â”‚ TimeSeries â”‚     â”‚  (OLAP)    â”‚     â”‚  (Slack)   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  Dashboard â”‚
                â”‚  (Grafana) â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      }
    ],
    tradeoffs: [
      {
        decision: { es: 'Flink vs Spark Structured Streaming', en: 'Flink vs Spark Structured Streaming', pt: 'Flink vs Spark Structured Streaming' },
        option1: { es: 'Flink: True streaming, mejor latencia, event-time processing nativo', en: 'Flink: True streaming, better latency, native event-time processing', pt: 'Flink: True streaming, melhor latÃªncia, event-time processing nativo' },
        option2: { es: 'Spark: Micro-batch, mÃ¡s fÃ¡cil si ya usÃ¡s Spark, mejor para ML', en: 'Spark: Micro-batch, easier if you already use Spark, better for ML', pt: 'Spark: Micro-batch, mais fÃ¡cil se jÃ¡ usa Spark, melhor para ML' },
        recommendation: { es: 'Flink para este caso - latencia < 1 minuto es crÃ­tica.', en: 'Flink for this case - latency < 1 minute is critical.', pt: 'Flink para este caso - latÃªncia < 1 minuto Ã© crÃ­tica.' }
      },
      {
        decision: { es: 'ClickHouse vs Druid vs Pinot', en: 'ClickHouse vs Druid vs Pinot', pt: 'ClickHouse vs Druid vs Pinot' },
        option1: { es: 'ClickHouse: MÃ¡s simple, excelente SQL, mejor para analytics ad-hoc', en: 'ClickHouse: Simpler, excellent SQL, better for ad-hoc analytics', pt: 'ClickHouse: Mais simples, excelente SQL, melhor para analytics ad-hoc' },
        option2: { es: 'Druid/Pinot: Mejor para dashboards pre-definidos, mÃ¡s complejo', en: 'Druid/Pinot: Better for pre-defined dashboards, more complex', pt: 'Druid/Pinot: Melhor para dashboards prÃ©-definidos, mais complexo' },
        recommendation: { es: 'ClickHouse para empezar - mÃ¡s fÃ¡cil de operar y excelente performance.', en: 'ClickHouse to start - easier to operate and excellent performance.', pt: 'ClickHouse para comeÃ§ar - mais fÃ¡cil de operar e excelente performance.' }
      }
    ],
    commonMistakes: [
      { es: 'âŒ Usar solo Redis sin histÃ³rico - no pueden comparar con ayer', en: 'âŒ Using only Redis without historical - can\'t compare with yesterday', pt: 'âŒ Usar sÃ³ Redis sem histÃ³rico - nÃ£o podem comparar com ontem' },
      { es: 'âŒ Windows muy chicos (segundos) - demasiado ruido en las mÃ©tricas', en: 'âŒ Windows too small (seconds) - too much noise in metrics', pt: 'âŒ Janelas muito pequenas (segundos) - muito ruÃ­do nas mÃ©tricas' },
      { es: 'âŒ No usar event-time - mÃ©tricas incorrectas si hay late arrivals', en: 'âŒ Not using event-time - incorrect metrics if there are late arrivals', pt: 'âŒ NÃ£o usar event-time - mÃ©tricas incorretas se hÃ¡ late arrivals' }
    ],
    interviewerTips: [
      { es: 'ğŸ’¡ MencionÃ¡ event-time vs processing-time', en: 'ğŸ’¡ Mention event-time vs processing-time', pt: 'ğŸ’¡ Mencione event-time vs processing-time' },
      { es: 'ğŸ’¡ ExplicÃ¡ por quÃ© dos serving layers (hot/warm)', en: 'ğŸ’¡ Explain why two serving layers (hot/warm)', pt: 'ğŸ’¡ Explique por que duas serving layers (hot/warm)' },
      { es: 'ğŸ’¡ HablÃ¡ de watermarks para late data', en: 'ğŸ’¡ Talk about watermarks for late data', pt: 'ğŸ’¡ Fale de watermarks para late data' }
    ],
    relatedTopics: ['Streaming', 'Flink', 'ClickHouse', 'Real-time Analytics', 'Event Processing'],
    estimatedXP: 700
  },

  // ============ INTERVIEW 6: DATA MESH ============
  {
    id: 'sd-data-mesh',
    title: {
      es: 'ImplementaciÃ³n de Data Mesh',
      en: 'Data Mesh Implementation',
      pt: 'ImplementaÃ§Ã£o de Data Mesh'
    },
    company: 'Enterprise / CorporaciÃ³n grande',
    difficulty: 'senior',
    duration: '60 min',
    tags: ['Data Mesh', 'Architecture', 'Governance', 'Self-service', 'Federation'],
    problem: {
      es: `Una corporaciÃ³n con 50 equipos de producto tiene un equipo centralizado de datos de 15 personas.
Problemas actuales:
- El equipo de datos es cuello de botella (6 meses de backlog)
- Cada equipo de producto espera 3+ meses para tener sus datos en el warehouse
- Nadie confÃ­a en los datos porque no saben de dÃ³nde vienen
- Los dominios de negocio no tienen ownership de sus datos

El CDO pregunta: "Â¿CÃ³mo diseÃ±arÃ­as la transiciÃ³n a Data Mesh para descentralizar la responsabilidad de datos?"`,
      en: `A corporation with 50 product teams has a centralized data team of 15 people.
Current problems:
- Data team is a bottleneck (6 months backlog)
- Each product team waits 3+ months to get their data in the warehouse
- Nobody trusts the data because they don't know where it comes from
- Business domains don't have ownership of their data

The CDO asks: "How would you design the transition to Data Mesh to decentralize data responsibility?"`,
      pt: `Uma corporaÃ§Ã£o com 50 times de produto tem um time centralizado de dados de 15 pessoas.
Problemas atuais:
- O time de dados Ã© gargalo (6 meses de backlog)
- Cada time de produto espera 3+ meses para ter seus dados no warehouse
- NinguÃ©m confia nos dados porque nÃ£o sabem de onde vÃªm
- Os domÃ­nios de negÃ³cio nÃ£o tÃªm ownership dos seus dados

O CDO pergunta: "Como vocÃª projetaria a transiÃ§Ã£o para Data Mesh para descentralizar a responsabilidade de dados?"`
    },
    clarifyingQuestions: [
      {
        question: { es: 'Â¿Los equipos de producto tienen skills de datos o necesitan capacitaciÃ³n?', en: 'Do product teams have data skills or need training?', pt: 'Os times de produto tÃªm skills de dados ou precisam de capacitaÃ§Ã£o?' },
        whyAsk: { es: 'Data Mesh requiere que los dominios manejen sus datos - necesitÃ¡s saber el gap de skills', en: 'Data Mesh requires domains to handle their data - you need to know the skills gap', pt: 'Data Mesh requer que os domÃ­nios gerenciem seus dados - vocÃª precisa saber o gap de skills' },
        typicalAnswer: { es: 'Algunos tienen 1-2 personas con SQL, pero ninguno tiene DEs dedicados', en: 'Some have 1-2 people with SQL, but none have dedicated DEs', pt: 'Alguns tÃªm 1-2 pessoas com SQL, mas nenhum tem DEs dedicados' }
      },
      {
        question: { es: 'Â¿Hay estÃ¡ndares de datos o cada equipo hace lo que quiere?', en: 'Are there data standards or does each team do what they want?', pt: 'HÃ¡ padrÃµes de dados ou cada time faz o que quer?' },
        whyAsk: { es: 'Data Mesh sin gobernanza es caos. NecesitÃ¡s saber el punto de partida', en: 'Data Mesh without governance is chaos. You need to know the starting point', pt: 'Data Mesh sem governanÃ§a Ã© caos. VocÃª precisa saber o ponto de partida' },
        typicalAnswer: { es: 'Muy pocos estÃ¡ndares. Cada equipo nombra las columnas diferente.', en: 'Very few standards. Each team names columns differently.', pt: 'Poucos padrÃµes. Cada time nomeia as colunas de forma diferente.' }
      },
      {
        question: { es: 'Â¿CuÃ¡l es el timeline esperado para la transiciÃ³n?', en: 'What is the expected timeline for the transition?', pt: 'Qual Ã© o timeline esperado para a transiÃ§Ã£o?' },
        whyAsk: { es: 'Data Mesh es una transformaciÃ³n de aÃ±os, no meses', en: 'Data Mesh is a years-long transformation, not months', pt: 'Data Mesh Ã© uma transformaÃ§Ã£o de anos, nÃ£o meses' },
        typicalAnswer: { es: '2-3 aÃ±os para la transiciÃ³n completa, pero necesitamos quick wins en 6 meses', en: '2-3 years for full transition, but we need quick wins in 6 months', pt: '2-3 anos para a transiÃ§Ã£o completa, mas precisamos de quick wins em 6 meses' }
      }
    ],
    requirements: {
      functional: [
        { es: 'Cada dominio publica sus datos como "productos de datos"', en: 'Each domain publishes their data as "data products"', pt: 'Cada domÃ­nio publica seus dados como "produtos de dados"' },
        { es: 'CatÃ¡logo centralizado para descubrir data products', en: 'Centralized catalog to discover data products', pt: 'CatÃ¡logo centralizado para descobrir data products' },
        { es: 'Self-service para que dominios creen pipelines sin el equipo central', en: 'Self-service for domains to create pipelines without central team', pt: 'Self-service para que domÃ­nios criem pipelines sem o time central' },
        { es: 'Gobernanza federada (estÃ¡ndares globales, implementaciÃ³n local)', en: 'Federated governance (global standards, local implementation)', pt: 'GovernanÃ§a federada (padrÃµes globais, implementaÃ§Ã£o local)' }
      ],
      nonFunctional: [
        { es: 'Quick wins en 6 meses con 2-3 dominios piloto', en: 'Quick wins in 6 months with 2-3 pilot domains', pt: 'Quick wins em 6 meses com 2-3 domÃ­nios piloto' },
        { es: 'TransiciÃ³n gradual sin disruption del negocio', en: 'Gradual transition without business disruption', pt: 'TransiÃ§Ã£o gradual sem disrupÃ§Ã£o do negÃ³cio' },
        { es: 'Interoperabilidad entre data products de diferentes dominios', en: 'Interoperability between data products from different domains', pt: 'Interoperabilidade entre data products de diferentes domÃ­nios' }
      ]
    },
    solution: [
      {
        step: 1,
        title: { es: 'Definir Dominios y Data Products', en: 'Define Domains and Data Products', pt: 'Definir DomÃ­nios e Data Products' },
        description: {
          es: `Primero: identificar los dominios de negocio y sus data products.

Dominios tÃ­picos:
- Customers (datos de clientes)
- Orders (transacciones)
- Products (catÃ¡logo)
- Finance (revenue, costs)
- Marketing (campaigns, attribution)

Cada dominio define sus Data Products:
- Nombre Ãºnico (customers.profiles)
- Owner (equipo responsable)
- Schema (estructura de datos)
- SLA (freshness, availability)
- DocumentaciÃ³n

El equipo central se convierte en "enabler", no "owner".`,
          en: `First: identify business domains and their data products.

Typical domains:
- Customers (customer data)
- Orders (transactions)
- Products (catalog)
- Finance (revenue, costs)
- Marketing (campaigns, attribution)

Each domain defines their Data Products:
- Unique name (customers.profiles)
- Owner (responsible team)
- Schema (data structure)
- SLA (freshness, availability)
- Documentation

Central team becomes "enabler", not "owner".`,
          pt: `Primeiro: identificar os domÃ­nios de negÃ³cio e seus data products.

DomÃ­nios tÃ­picos:
- Customers (dados de clientes)
- Orders (transaÃ§Ãµes)
- Products (catÃ¡logo)
- Finance (receita, custos)
- Marketing (campanhas, atribuiÃ§Ã£o)

Cada domÃ­nio define seus Data Products:
- Nome Ãºnico (customers.profiles)
- Owner (time responsÃ¡vel)
- Schema (estrutura de dados)
- SLA (freshness, disponibilidade)
- DocumentaÃ§Ã£o

O time central se torna "enabler", nÃ£o "owner".`
        },
        components: ['Domain-Driven Design', 'Data Products', 'Ownership'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Business Domains                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ Customers â”‚  â”‚  Orders   â”‚  â”‚  Finance  â”‚           â”‚
â”‚  â”‚           â”‚  â”‚           â”‚  â”‚           â”‚           â”‚
â”‚  â”‚ Products: â”‚  â”‚ Products: â”‚  â”‚ Products: â”‚           â”‚
â”‚  â”‚ - profilesâ”‚  â”‚ - orders  â”‚  â”‚ - revenue â”‚           â”‚
â”‚  â”‚ - segmentsâ”‚  â”‚ - returns â”‚  â”‚ - costs   â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      },
      {
        step: 2,
        title: { es: 'Self-Service Data Platform', en: 'Self-Service Data Platform', pt: 'Self-Service Data Platform' },
        description: {
          es: `El equipo central construye la plataforma, no los pipelines:

Componentes de la plataforma:
1. Data Lake compartido (S3 con particiones por dominio)
2. Templates de pipelines (Airflow DAGs pre-configurados)
3. Infraestructura como cÃ³digo (Terraform modules)
4. CatÃ¡logo de datos (DataHub/Amundsen)
5. Lineage automÃ¡tico

Cada dominio usa la plataforma para:
- Crear sus propios pipelines (sin tickets)
- Publicar data products (auto-registro)
- Monitorear calidad (tests automÃ¡ticos)

El equipo central mantiene la plataforma y define estÃ¡ndares.`,
          en: `Central team builds the platform, not the pipelines:

Platform components:
1. Shared Data Lake (S3 with domain partitions)
2. Pipeline templates (pre-configured Airflow DAGs)
3. Infrastructure as code (Terraform modules)
4. Data catalog (DataHub/Amundsen)
5. Automatic lineage

Each domain uses the platform to:
- Create their own pipelines (no tickets)
- Publish data products (auto-registration)
- Monitor quality (automatic tests)

Central team maintains the platform and defines standards.`,
          pt: `Time central constrÃ³i a plataforma, nÃ£o os pipelines:

Componentes da plataforma:
1. Data Lake compartilhado (S3 com partiÃ§Ãµes por domÃ­nio)
2. Templates de pipelines (Airflow DAGs prÃ©-configurados)
3. Infraestrutura como cÃ³digo (Terraform modules)
4. CatÃ¡logo de dados (DataHub/Amundsen)
5. Lineage automÃ¡tico

Cada domÃ­nio usa a plataforma para:
- Criar seus prÃ³prios pipelines (sem tickets)
- Publicar data products (auto-registro)
- Monitorar qualidade (testes automÃ¡ticos)

Time central mantÃ©m a plataforma e define padrÃµes.`
        },
        components: ['DataHub', 'Airflow', 'Terraform', 'S3'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Self-Service Platform                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚              Data Catalog (DataHub)                 â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Pipeline   â”‚  â”‚   Infra     â”‚  â”‚   Quality   â”‚     â”‚
â”‚  â”‚  Templates  â”‚  â”‚  Terraform  â”‚  â”‚   Tests     â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚           Shared Data Lake (S3)                     â”‚â”‚
â”‚  â”‚  /customers/  /orders/  /finance/  /marketing/      â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      },
      {
        step: 3,
        title: { es: 'Gobernanza Federada', en: 'Federated Governance', pt: 'GovernanÃ§a Federada' },
        description: {
          es: `Gobernanza = EstÃ¡ndares globales + AutonomÃ­a local

EstÃ¡ndares globales (enforcement automÃ¡tico):
- Naming conventions (snake_case, prefijos de dominio)
- Schema registry obligatorio
- DocumentaciÃ³n mÃ­nima requerida
- Tests de calidad bÃ¡sicos (nulls, freshness)
- PII marcado y encriptado

AutonomÃ­a local (decisiÃ³n del dominio):
- TecnologÃ­a de procesamiento
- Frecuencia de actualizaciÃ³n
- LÃ³gica de negocio
- SLAs especÃ­ficos

Guild de Data:
- Representantes de cada dominio
- Se reÃºne mensualmente
- Decide nuevos estÃ¡ndares
- Comparte mejores prÃ¡cticas`,
          en: `Governance = Global standards + Local autonomy

Global standards (automatic enforcement):
- Naming conventions (snake_case, domain prefixes)
- Mandatory schema registry
- Minimum required documentation
- Basic quality tests (nulls, freshness)
- PII marked and encrypted

Local autonomy (domain decision):
- Processing technology
- Update frequency
- Business logic
- Specific SLAs

Data Guild:
- Representatives from each domain
- Meets monthly
- Decides new standards
- Shares best practices`,
          pt: `GovernanÃ§a = PadrÃµes globais + Autonomia local

PadrÃµes globais (enforcement automÃ¡tico):
- Naming conventions (snake_case, prefixos de domÃ­nio)
- Schema registry obrigatÃ³rio
- DocumentaÃ§Ã£o mÃ­nima requerida
- Testes de qualidade bÃ¡sicos (nulls, freshness)
- PII marcado e criptografado

Autonomia local (decisÃ£o do domÃ­nio):
- Tecnologia de processamento
- FrequÃªncia de atualizaÃ§Ã£o
- LÃ³gica de negÃ³cio
- SLAs especÃ­ficos

Guild de Data:
- Representantes de cada domÃ­nio
- Se reÃºne mensalmente
- Decide novos padrÃµes
- Compartilha melhores prÃ¡ticas`
        },
        components: ['Schema Registry', 'Data Quality', 'Data Guild'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Federated Governance                       â”‚
â”‚                                                          â”‚
â”‚  GLOBAL STANDARDS          LOCAL AUTONOMY               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚ Naming      â”‚           â”‚ Technology  â”‚             â”‚
â”‚  â”‚ Schema      â”‚     +     â”‚ Frequency   â”‚             â”‚
â”‚  â”‚ PII         â”‚           â”‚ SLAs        â”‚             â”‚
â”‚  â”‚ Quality     â”‚           â”‚ Logic       â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                          â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚        â”‚         Data Guild              â”‚              â”‚
â”‚        â”‚  [Customers] [Orders] [Finance] â”‚              â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      },
      {
        step: 4,
        title: { es: 'Rollout Gradual', en: 'Gradual Rollout', pt: 'Rollout Gradual' },
        description: {
          es: `TransiciÃ³n en fases (no big bang):

Fase 1 (Meses 1-6): Piloto
- 2-3 dominios con equipos motivados
- Construir plataforma MVP
- Aprender y ajustar

Fase 2 (Meses 6-12): ExpansiÃ³n
- 5-10 dominios mÃ¡s
- Madurar la plataforma
- Documentar patrones

Fase 3 (Meses 12-24): Escala
- Resto de dominios
- Migrar pipelines legacy
- Deprecar warehouse centralizado

MÃ©tricas de Ã©xito:
- Time to data (de meses a dÃ­as)
- % de data products con owner
- NPS de consumidores de datos`,
          en: `Transition in phases (not big bang):

Phase 1 (Months 1-6): Pilot
- 2-3 domains with motivated teams
- Build MVP platform
- Learn and adjust

Phase 2 (Months 6-12): Expansion
- 5-10 more domains
- Mature the platform
- Document patterns

Phase 3 (Months 12-24): Scale
- Rest of domains
- Migrate legacy pipelines
- Deprecate centralized warehouse

Success metrics:
- Time to data (from months to days)
- % of data products with owner
- Data consumer NPS`,
          pt: `TransiÃ§Ã£o em fases (nÃ£o big bang):

Fase 1 (Meses 1-6): Piloto
- 2-3 domÃ­nios com times motivados
- Construir plataforma MVP
- Aprender e ajustar

Fase 2 (Meses 6-12): ExpansÃ£o
- 5-10 domÃ­nios mais
- Amadurecer a plataforma
- Documentar padrÃµes

Fase 3 (Meses 12-24): Escala
- Resto dos domÃ­nios
- Migrar pipelines legacy
- Depreciar warehouse centralizado

MÃ©tricas de sucesso:
- Time to data (de meses para dias)
- % de data products com owner
- NPS de consumidores de dados`
        },
        components: ['Change Management', 'Metrics', 'Migration'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Rollout Timeline                      â”‚
â”‚                                                          â”‚
â”‚  Phase 1        Phase 2        Phase 3                  â”‚
â”‚  (Pilot)        (Expand)       (Scale)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚ 2-3  â”‚â”€â”€â”€â”€â”€â”€â”€â”‚ 5-10 â”‚â”€â”€â”€â”€â”€â”€â”€â”‚ All  â”‚                â”‚
â”‚  â”‚domainsâ”‚      â”‚domainsâ”‚      â”‚domainsâ”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚  Month 0-6      Month 6-12     Month 12-24             â”‚
â”‚                                                          â”‚
â”‚  âš¡ Quick wins  ğŸ“ˆ Scale       ğŸ¯ Full adoption        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      }
    ],
    tradeoffs: [
      {
        decision: { es: 'Data Mesh vs Data Fabric', en: 'Data Mesh vs Data Fabric', pt: 'Data Mesh vs Data Fabric' },
        option1: { es: 'Data Mesh: Descentralizado, ownership por dominio, cambio organizacional grande', en: 'Data Mesh: Decentralized, domain ownership, large organizational change', pt: 'Data Mesh: Descentralizado, ownership por domÃ­nio, mudanÃ§a organizacional grande' },
        option2: { es: 'Data Fabric: MÃ¡s tecnolÃ³gico, menos cambio org, el equipo central sigue siendo owner', en: 'Data Fabric: More technological, less org change, central team remains owner', pt: 'Data Fabric: Mais tecnolÃ³gico, menos mudanÃ§a org, time central continua sendo owner' },
        recommendation: { es: 'Data Mesh si el problema es organizacional (bottleneck). Data Fabric si es solo tecnolÃ³gico.', en: 'Data Mesh if problem is organizational (bottleneck). Data Fabric if just technological.', pt: 'Data Mesh se o problema Ã© organizacional (gargalo). Data Fabric se Ã© sÃ³ tecnolÃ³gico.' }
      }
    ],
    commonMistakes: [
      { es: 'âŒ Implementar solo la tecnologÃ­a sin el cambio organizacional', en: 'âŒ Implementing only technology without organizational change', pt: 'âŒ Implementar sÃ³ a tecnologia sem a mudanÃ§a organizacional' },
      { es: 'âŒ No definir estÃ¡ndares globales - termina en caos', en: 'âŒ Not defining global standards - ends in chaos', pt: 'âŒ NÃ£o definir padrÃµes globais - termina em caos' },
      { es: 'âŒ Big bang en lugar de rollout gradual', en: 'âŒ Big bang instead of gradual rollout', pt: 'âŒ Big bang em vez de rollout gradual' },
      { es: 'âŒ No invertir en la plataforma self-service', en: 'âŒ Not investing in self-service platform', pt: 'âŒ NÃ£o investir na plataforma self-service' }
    ],
    interviewerTips: [
      { es: 'ğŸ’¡ Data Mesh es tanto organizacional como tecnolÃ³gico - mencionÃ¡ ambos', en: 'ğŸ’¡ Data Mesh is both organizational and technological - mention both', pt: 'ğŸ’¡ Data Mesh Ã© tanto organizacional quanto tecnolÃ³gico - mencione ambos' },
      { es: 'ğŸ’¡ HablÃ¡ de gobernanza federada vs centralizada', en: 'ğŸ’¡ Talk about federated vs centralized governance', pt: 'ğŸ’¡ Fale de governanÃ§a federada vs centralizada' },
      { es: 'ğŸ’¡ MencionÃ¡ el rol del equipo central como "platform team"', en: 'ğŸ’¡ Mention central team role as "platform team"', pt: 'ğŸ’¡ Mencione o papel do time central como "platform team"' }
    ],
    relatedTopics: ['Data Mesh', 'Data Products', 'Governance', 'Self-service', 'Domain-Driven Design'],
    estimatedXP: 900
  },

  // ============ INTERVIEW 7: ML FEATURE STORE ============
  {
    id: 'sd-feature-store',
    title: {
      es: 'Feature Store para ML en ProducciÃ³n',
      en: 'Feature Store for ML in Production',
      pt: 'Feature Store para ML em ProduÃ§Ã£o'
    },
    company: 'ML Platform / Fintech',
    difficulty: 'senior',
    duration: '60 min',
    tags: ['ML', 'Feature Store', 'Real-time', 'Feast', 'MLOps'],
    problem: {
      es: `Una fintech tiene 20 modelos de ML en producciÃ³n (fraude, scoring, recomendaciones).
Problemas actuales:
1. Training-serving skew: Features calculadas diferente en training vs inference
2. Cada modelo recalcula las mismas features (user_avg_transaction)
3. Latencia de inference muy alta (200ms) porque calculan features en runtime
4. Data scientists no pueden experimentar con features de otros equipos

El Head of ML pregunta: "Â¿CÃ³mo diseÃ±arÃ­as un Feature Store que resuelva estos problemas?"`,
      en: `A fintech has 20 ML models in production (fraud, scoring, recommendations).
Current problems:
1. Training-serving skew: Features calculated differently in training vs inference
2. Each model recalculates the same features (user_avg_transaction)
3. Very high inference latency (200ms) because they calculate features at runtime
4. Data scientists can't experiment with features from other teams

The Head of ML asks: "How would you design a Feature Store that solves these problems?"`,
      pt: `Uma fintech tem 20 modelos de ML em produÃ§Ã£o (fraude, scoring, recomendaÃ§Ãµes).
Problemas atuais:
1. Training-serving skew: Features calculadas de forma diferente em training vs inference
2. Cada modelo recalcula as mesmas features (user_avg_transaction)
3. LatÃªncia de inferÃªncia muito alta (200ms) porque calculam features em runtime
4. Data scientists nÃ£o podem experimentar com features de outros times

O Head of ML pergunta: "Como vocÃª projetaria um Feature Store que resolva estes problemas?"`
    },
    clarifyingQuestions: [
      {
        question: { es: 'Â¿CuÃ¡ntas features tienen en total y cuÃ¡ntas necesitan en real-time?', en: 'How many features do you have total and how many need real-time?', pt: 'Quantas features vocÃªs tÃªm no total e quantas precisam em real-time?' },
        whyAsk: { es: 'Define si necesitas online store, offline store, o ambos', en: 'Defines if you need online store, offline store, or both', pt: 'Define se precisa de online store, offline store, ou ambos' },
        typicalAnswer: { es: '500 features, 50 necesitan real-time con latencia < 10ms', en: '500 features, 50 need real-time with latency < 10ms', pt: '500 features, 50 precisam de real-time com latÃªncia < 10ms' }
      },
      {
        question: { es: 'Â¿QuÃ© latencia de inference es aceptable?', en: 'What inference latency is acceptable?', pt: 'Qual latÃªncia de inferÃªncia Ã© aceitÃ¡vel?' },
        whyAsk: { es: 'Define el storage para online features (Redis, DynamoDB)', en: 'Defines storage for online features (Redis, DynamoDB)', pt: 'Define o storage para online features (Redis, DynamoDB)' },
        typicalAnswer: { es: 'Para fraude necesitamos < 50ms total, de los cuales 10ms pueden ser feature retrieval', en: 'For fraud we need < 50ms total, of which 10ms can be feature retrieval', pt: 'Para fraude precisamos < 50ms total, dos quais 10ms podem ser feature retrieval' }
      },
      {
        question: { es: 'Â¿Los data scientists usan Python/Spark o SQL?', en: 'Do data scientists use Python/Spark or SQL?', pt: 'Os data scientists usam Python/Spark ou SQL?' },
        whyAsk: { es: 'Define el SDK y la interfaz del feature store', en: 'Defines the SDK and feature store interface', pt: 'Define o SDK e a interface do feature store' },
        typicalAnswer: { es: 'Principalmente Python y PySpark, algunos usan SQL', en: 'Mainly Python and PySpark, some use SQL', pt: 'Principalmente Python e PySpark, alguns usam SQL' }
      }
    ],
    requirements: {
      functional: [
        { es: 'Definir features una vez, usar en training y serving', en: 'Define features once, use in training and serving', pt: 'Definir features uma vez, usar em training e serving' },
        { es: 'Reutilizar features entre modelos', en: 'Reuse features across models', pt: 'Reutilizar features entre modelos' },
        { es: 'Servir features en < 10ms para inference', en: 'Serve features in < 10ms for inference', pt: 'Servir features em < 10ms para inferÃªncia' },
        { es: 'Point-in-time correctness para training', en: 'Point-in-time correctness for training', pt: 'Point-in-time correctness para training' }
      ],
      nonFunctional: [
        { es: 'Latencia p99 < 10ms para online serving', en: 'p99 latency < 10ms for online serving', pt: 'LatÃªncia p99 < 10ms para online serving' },
        { es: 'Soportar 500+ features', en: 'Support 500+ features', pt: 'Suportar 500+ features' },
        { es: 'Self-service para data scientists', en: 'Self-service for data scientists', pt: 'Self-service para data scientists' }
      ]
    },
    solution: [
      {
        step: 1,
        title: { es: 'Arquitectura Dual: Online + Offline', en: 'Dual Architecture: Online + Offline', pt: 'Arquitetura Dual: Online + Offline' },
        description: {
          es: `Feature Store tiene dos componentes:

Offline Store (para training):
- Storage: S3/Delta Lake
- Features histÃ³ricas con timestamp
- Point-in-time queries para evitar data leakage
- Batch processing con Spark

Online Store (para inference):
- Storage: Redis/DynamoDB
- Solo Ãºltimo valor de cada feature
- Latencia < 10ms
- Actualizaciones en streaming

Ambos stores comparten las mismas definiciones de features.`,
          en: `Feature Store has two components:

Offline Store (for training):
- Storage: S3/Delta Lake
- Historical features with timestamp
- Point-in-time queries to avoid data leakage
- Batch processing with Spark

Online Store (for inference):
- Storage: Redis/DynamoDB
- Only latest value of each feature
- Latency < 10ms
- Streaming updates

Both stores share the same feature definitions.`,
          pt: `Feature Store tem dois componentes:

Offline Store (para training):
- Storage: S3/Delta Lake
- Features histÃ³ricas com timestamp
- Point-in-time queries para evitar data leakage
- Batch processing com Spark

Online Store (para inferÃªncia):
- Storage: Redis/DynamoDB
- SÃ³ Ãºltimo valor de cada feature
- LatÃªncia < 10ms
- AtualizaÃ§Ãµes em streaming

Ambos stores compartilham as mesmas definiÃ§Ãµes de features.`
        },
        components: ['Feast', 'Delta Lake', 'Redis', 'Spark'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Feature Store                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   Offline Store     â”‚   â”‚    Online Store     â”‚     â”‚
â”‚  â”‚   (Training)        â”‚   â”‚   (Inference)       â”‚     â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚     â”‚
â”‚  â”‚   â”‚  Delta  â”‚       â”‚   â”‚   â”‚  Redis  â”‚       â”‚     â”‚
â”‚  â”‚   â”‚  Lake   â”‚       â”‚   â”‚   â”‚         â”‚       â”‚     â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚     â”‚
â”‚  â”‚   Point-in-time âœ“   â”‚   â”‚   Latency < 10ms   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚            Feature Registry (definitions)            â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      },
      {
        step: 2,
        title: { es: 'Feature Definitions', en: 'Feature Definitions', pt: 'Feature Definitions' },
        description: {
          es: `Las features se definen UNA vez en cÃ³digo:

Feature definition incluye:
- Nombre y descripciÃ³n
- Entidad (user, transaction, merchant)
- Tipo de dato
- TransformaciÃ³n (SQL o Python)
- TTL para online store

Ejemplo (Feast):
user_features = FeatureView(
    name="user_transaction_stats",
    entities=[user],
    features=[
        Feature("avg_transaction_30d", Float64),
        Feature("count_transactions_30d", Int64),
    ],
    batch_source=BigQuerySource(
        query="SELECT user_id, AVG(amount) as avg..."
    )
)

El mismo cÃ³digo genera training data y online features.`,
          en: `Features are defined ONCE in code:

Feature definition includes:
- Name and description
- Entity (user, transaction, merchant)
- Data type
- Transformation (SQL or Python)
- TTL for online store

Example (Feast):
user_features = FeatureView(
    name="user_transaction_stats",
    entities=[user],
    features=[
        Feature("avg_transaction_30d", Float64),
        Feature("count_transactions_30d", Int64),
    ],
    batch_source=BigQuerySource(
        query="SELECT user_id, AVG(amount) as avg..."
    )
)

Same code generates training data and online features.`,
          pt: `As features sÃ£o definidas UMA vez em cÃ³digo:

Feature definition inclui:
- Nome e descriÃ§Ã£o
- Entidade (user, transaction, merchant)
- Tipo de dado
- TransformaÃ§Ã£o (SQL ou Python)
- TTL para online store

Exemplo (Feast):
user_features = FeatureView(
    name="user_transaction_stats",
    entities=[user],
    features=[
        Feature("avg_transaction_30d", Float64),
        Feature("count_transactions_30d", Int64),
    ],
    batch_source=BigQuerySource(
        query="SELECT user_id, AVG(amount) as avg..."
    )
)

O mesmo cÃ³digo gera training data e online features.`
        },
        components: ['Feast', 'Feature Registry', 'Python SDK'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Feature Definition                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ user_features = FeatureView(                        â”‚â”‚
â”‚  â”‚     name="user_transaction_stats",                  â”‚â”‚
â”‚  â”‚     entities=[user],                                â”‚â”‚
â”‚  â”‚     features=[                                      â”‚â”‚
â”‚  â”‚         Feature("avg_transaction_30d", Float64),    â”‚â”‚
â”‚  â”‚         Feature("count_transactions_30d", Int64),   â”‚â”‚
â”‚  â”‚     ],                                              â”‚â”‚
â”‚  â”‚     batch_source=BigQuerySource(query="...")        â”‚â”‚
â”‚  â”‚ )                                                   â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                          â”‚                               â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚              â–¼                       â–¼                  â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚     â”‚  Training   â”‚         â”‚  Serving    â”‚            â”‚
â”‚     â”‚   Data      â”‚         â”‚   Data      â”‚            â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      },
      {
        step: 3,
        title: { es: 'MaterializaciÃ³n y Serving', en: 'Materialization and Serving', pt: 'MaterializaÃ§Ã£o e Serving' },
        description: {
          es: `Dos flujos de materializaciÃ³n:

Batch (diario/horario):
1. Spark job lee feature definitions
2. Ejecuta transformaciones
3. Escribe a offline store (Delta Lake)
4. Copia Ãºltimos valores a online store (Redis)

Streaming (real-time):
1. Features que necesitan frescura < 1 hora
2. Flink consume eventos de Kafka
3. Calcula features incrementales
4. Actualiza Redis directamente

Serving API:
- get_online_features(entity_keys, feature_refs)
- Retorna features en < 10ms
- SDK para Python/Java/Go`,
          en: `Two materialization flows:

Batch (daily/hourly):
1. Spark job reads feature definitions
2. Executes transformations
3. Writes to offline store (Delta Lake)
4. Copies latest values to online store (Redis)

Streaming (real-time):
1. Features that need freshness < 1 hour
2. Flink consumes events from Kafka
3. Calculates incremental features
4. Updates Redis directly

Serving API:
- get_online_features(entity_keys, feature_refs)
- Returns features in < 10ms
- SDK for Python/Java/Go`,
          pt: `Dois fluxos de materializaÃ§Ã£o:

Batch (diÃ¡rio/horÃ¡rio):
1. Spark job lÃª feature definitions
2. Executa transformaÃ§Ãµes
3. Escreve no offline store (Delta Lake)
4. Copia Ãºltimos valores para online store (Redis)

Streaming (real-time):
1. Features que precisam de freshness < 1 hora
2. Flink consome eventos do Kafka
3. Calcula features incrementais
4. Atualiza Redis diretamente

Serving API:
- get_online_features(entity_keys, feature_refs)
- Retorna features em < 10ms
- SDK para Python/Java/Go`
        },
        components: ['Spark', 'Flink', 'Redis', 'Serving API'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Materialization Flows                    â”‚
â”‚                                                          â”‚
â”‚  BATCH (Daily)              STREAMING (Real-time)       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚  Spark  â”‚                â”‚  Flink  â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                 â”‚
â”‚       â”‚                          â”‚                      â”‚
â”‚       â–¼                          â”‚                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚                      â”‚
â”‚  â”‚ Delta   â”‚                     â”‚                      â”‚
â”‚  â”‚ Lake    â”‚                     â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                     â”‚                      â”‚
â”‚       â”‚ copy                     â”‚ direct               â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                  â–¼    â–¼                                 â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚              â”‚    Redis    â”‚                            â”‚
â”‚              â”‚ (< 10ms)    â”‚                            â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      }
    ],
    tradeoffs: [
      {
        decision: { es: 'Feast vs Tecton vs Custom', en: 'Feast vs Tecton vs Custom', pt: 'Feast vs Tecton vs Custom' },
        option1: { es: 'Feast: Open source, gratis, necesita ops', en: 'Feast: Open source, free, needs ops', pt: 'Feast: Open source, grÃ¡tis, precisa de ops' },
        option2: { es: 'Tecton: Managed, muy caro ($$$), menos ops', en: 'Tecton: Managed, very expensive ($$$), less ops', pt: 'Tecton: Managed, muito caro ($$$), menos ops' },
        recommendation: { es: 'Feast para empezar. Tecton si tenÃ©s mucho budget y poco tiempo.', en: 'Feast to start. Tecton if you have big budget and little time.', pt: 'Feast para comeÃ§ar. Tecton se tem muito budget e pouco tempo.' }
      },
      {
        decision: { es: 'Redis vs DynamoDB para online store', en: 'Redis vs DynamoDB for online store', pt: 'Redis vs DynamoDB para online store' },
        option1: { es: 'Redis: MÃ¡s rÃ¡pido (< 5ms), necesita cluster management', en: 'Redis: Faster (< 5ms), needs cluster management', pt: 'Redis: Mais rÃ¡pido (< 5ms), precisa de cluster management' },
        option2: { es: 'DynamoDB: Serverless, un poco mÃ¡s lento (5-10ms), less ops', en: 'DynamoDB: Serverless, slightly slower (5-10ms), less ops', pt: 'DynamoDB: Serverless, um pouco mais lento (5-10ms), less ops' },
        recommendation: { es: 'Redis si < 5ms es crÃ­tico. DynamoDB para simplificar ops.', en: 'Redis if < 5ms is critical. DynamoDB to simplify ops.', pt: 'Redis se < 5ms Ã© crÃ­tico. DynamoDB para simplificar ops.' }
      }
    ],
    commonMistakes: [
      { es: 'âŒ No considerar point-in-time correctness - causa data leakage', en: 'âŒ Not considering point-in-time correctness - causes data leakage', pt: 'âŒ NÃ£o considerar point-in-time correctness - causa data leakage' },
      { es: 'âŒ Calcular features en runtime en lugar de pre-computar', en: 'âŒ Calculating features at runtime instead of pre-computing', pt: 'âŒ Calcular features em runtime em vez de prÃ©-computar' },
      { es: 'âŒ Diferentes definiciones para training y serving', en: 'âŒ Different definitions for training and serving', pt: 'âŒ DefiniÃ§Ãµes diferentes para training e serving' }
    ],
    interviewerTips: [
      { es: 'ğŸ’¡ ExplicÃ¡ el problema de training-serving skew', en: 'ğŸ’¡ Explain the training-serving skew problem', pt: 'ğŸ’¡ Explique o problema de training-serving skew' },
      { es: 'ğŸ’¡ MencionÃ¡ point-in-time correctness para evitar data leakage', en: 'ğŸ’¡ Mention point-in-time correctness to avoid data leakage', pt: 'ğŸ’¡ Mencione point-in-time correctness para evitar data leakage' },
      { es: 'ğŸ’¡ HablÃ¡ de la dualidad offline/online store', en: 'ğŸ’¡ Talk about the offline/online store duality', pt: 'ğŸ’¡ Fale da dualidade offline/online store' }
    ],
    relatedTopics: ['Feature Store', 'ML', 'Feast', 'MLOps', 'Real-time Inference'],
    estimatedXP: 850
  },

  // ============ INTERVIEW 8: DATA WAREHOUSE MODELING (JUNIOR) ============
  {
    id: 'sd-dwh-modeling',
    title: {
      es: 'Modelado de Data Warehouse (Star Schema)',
      en: 'Data Warehouse Modeling (Star Schema)',
      pt: 'Modelagem de Data Warehouse (Star Schema)'
    },
    company: 'Retail / E-commerce',
    difficulty: 'junior',
    duration: '30 min',
    tags: ['Data Modeling', 'Star Schema', 'Dimensional', 'SQL', 'Entry-level'],
    problem: {
      es: `Una tienda de retail tiene datos de ventas en una base de datos transaccional (PostgreSQL).
El equipo de BI necesita hacer anÃ¡lisis de ventas por:
- Producto, categorÃ­a
- Tienda, regiÃ³n
- Fecha (dÃ­a, semana, mes, aÃ±o)
- Cliente (segmento, antigÃ¼edad)

Actualmente hacen queries directamente a producciÃ³n y tardan 10+ minutos.

El manager pregunta: "Â¿CÃ³mo modelarÃ­as un Data Warehouse para que las queries sean rÃ¡pidas?"`,
      en: `A retail store has sales data in a transactional database (PostgreSQL).
The BI team needs to analyze sales by:
- Product, category
- Store, region
- Date (day, week, month, year)
- Customer (segment, tenure)

Currently they query production directly and it takes 10+ minutes.

The manager asks: "How would you model a Data Warehouse so queries are fast?"`,
      pt: `Uma loja de varejo tem dados de vendas em um banco de dados transacional (PostgreSQL).
A equipe de BI precisa analisar vendas por:
- Produto, categoria
- Loja, regiÃ£o
- Data (dia, semana, mÃªs, ano)
- Cliente (segmento, antiguidade)

Atualmente fazem queries diretamente em produÃ§Ã£o e demoram 10+ minutos.

O gerente pergunta: "Como vocÃª modelaria um Data Warehouse para que as queries sejam rÃ¡pidas?"`
    },
    clarifyingQuestions: [
      {
        question: { es: 'Â¿CuÃ¡ntos registros de ventas tienen por dÃ­a?', en: 'How many sales records do you have per day?', pt: 'Quantos registros de vendas vocÃªs tÃªm por dia?' },
        whyAsk: { es: 'Define el tamaÃ±o de la fact table y si necesitamos particionamiento', en: 'Defines fact table size and if we need partitioning', pt: 'Define o tamanho da tabela fato e se precisamos de particionamento' },
        typicalAnswer: { es: 'Unas 50,000 ventas por dÃ­a, 18 millones al aÃ±o', en: 'About 50,000 sales per day, 18 million per year', pt: 'Umas 50.000 vendas por dia, 18 milhÃµes por ano' }
      },
      {
        question: { es: 'Â¿CuÃ¡ntos productos y tiendas tienen?', en: 'How many products and stores do you have?', pt: 'Quantos produtos e lojas vocÃªs tÃªm?' },
        whyAsk: { es: 'Define el tamaÃ±o de las dimension tables', en: 'Defines dimension table sizes', pt: 'Define o tamanho das tabelas dimensÃ£o' },
        typicalAnswer: { es: '10,000 productos, 200 tiendas, 500,000 clientes', en: '10,000 products, 200 stores, 500,000 customers', pt: '10.000 produtos, 200 lojas, 500.000 clientes' }
      },
      {
        question: { es: 'Â¿Necesitan datos histÃ³ricos o solo actuales?', en: 'Do you need historical data or just current?', pt: 'Precisam de dados histÃ³ricos ou sÃ³ atuais?' },
        whyAsk: { es: 'Define si necesitamos SCD (Slowly Changing Dimensions)', en: 'Defines if we need SCD (Slowly Changing Dimensions)', pt: 'Define se precisamos de SCD (Slowly Changing Dimensions)' },
        typicalAnswer: { es: 'Necesitamos ver cÃ³mo cambian los precios y categorÃ­as de productos', en: 'We need to see how product prices and categories change', pt: 'Precisamos ver como mudam os preÃ§os e categorias de produtos' }
      }
    ],
    requirements: {
      functional: [
        { es: 'Queries de agregaciÃ³n en < 5 segundos', en: 'Aggregation queries in < 5 seconds', pt: 'Queries de agregaÃ§Ã£o em < 5 segundos' },
        { es: 'AnÃ¡lisis por mÃºltiples dimensiones', en: 'Analysis by multiple dimensions', pt: 'AnÃ¡lise por mÃºltiplas dimensÃµes' },
        { es: 'Historial de cambios en productos', en: 'History of product changes', pt: 'HistÃ³rico de mudanÃ§as em produtos' },
        { es: 'ActualizaciÃ³n diaria de datos', en: 'Daily data refresh', pt: 'AtualizaÃ§Ã£o diÃ¡ria de dados' }
      ],
      nonFunctional: [
        { es: 'FÃ¡cil de entender para analistas de BI', en: 'Easy to understand for BI analysts', pt: 'FÃ¡cil de entender para analistas de BI' },
        { es: 'Escalable a 5 aÃ±os de datos', en: 'Scalable to 5 years of data', pt: 'EscalÃ¡vel a 5 anos de dados' }
      ]
    },
    solution: [
      {
        step: 1,
        title: { es: 'Identificar Fact Table (Hechos)', en: 'Identify Fact Table', pt: 'Identificar Tabela Fato' },
        description: {
          es: `La Fact Table contiene las mÃ©tricas numÃ©ricas que queremos analizar:

fact_sales:
- sale_id (PK)
- date_key (FK a dim_date)
- product_key (FK a dim_product)
- store_key (FK a dim_store)
- customer_key (FK a dim_customer)
- quantity (medida)
- unit_price (medida)
- total_amount (medida)
- discount_amount (medida)

Las medidas son los nÃºmeros que vamos a sumar, promediar, etc.
Las keys son referencias a las dimensiones.`,
          en: `The Fact Table contains the numeric metrics we want to analyze:

fact_sales:
- sale_id (PK)
- date_key (FK to dim_date)
- product_key (FK to dim_product)
- store_key (FK to dim_store)
- customer_key (FK to dim_customer)
- quantity (measure)
- unit_price (measure)
- total_amount (measure)
- discount_amount (measure)

Measures are the numbers we'll sum, average, etc.
Keys are references to dimensions.`,
          pt: `A Tabela Fato contÃ©m as mÃ©tricas numÃ©ricas que queremos analisar:

fact_sales:
- sale_id (PK)
- date_key (FK para dim_date)
- product_key (FK para dim_product)
- store_key (FK para dim_store)
- customer_key (FK para dim_customer)
- quantity (medida)
- unit_price (medida)
- total_amount (medida)
- discount_amount (medida)

As medidas sÃ£o os nÃºmeros que vamos somar, calcular mÃ©dia, etc.
As keys sÃ£o referÃªncias Ã s dimensÃµes.`
        },
        components: ['Fact Table', 'Measures', 'Foreign Keys'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             fact_sales                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ sale_id         (PK)                    â”‚
â”‚ date_key        (FK) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ dim_date
â”‚ product_key     (FK) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ dim_product
â”‚ store_key       (FK) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ dim_store
â”‚ customer_key    (FK) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ dim_customer
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ quantity        (measure)               â”‚
â”‚ unit_price      (measure)               â”‚
â”‚ total_amount    (measure)               â”‚
â”‚ discount_amount (measure)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      },
      {
        step: 2,
        title: { es: 'DiseÃ±ar Dimension Tables', en: 'Design Dimension Tables', pt: 'Projetar Tabelas DimensÃ£o' },
        description: {
          es: `Las Dimensions son las tablas que describen el "quiÃ©n, quÃ©, dÃ³nde, cuÃ¡ndo":

dim_date:
- date_key (PK, formato YYYYMMDD)
- full_date, day, month, year
- day_of_week, week_of_year
- is_weekend, is_holiday
- quarter, fiscal_year

dim_product:
- product_key (PK, surrogate key)
- product_id (natural key)
- product_name, category, subcategory
- brand, supplier
- current_price

dim_store:
- store_key (PK)
- store_name, city, region, country

dim_customer:
- customer_key (PK)
- customer_name, segment
- registration_date, tenure_months`,
          en: `Dimensions are tables that describe "who, what, where, when":

dim_date:
- date_key (PK, format YYYYMMDD)
- full_date, day, month, year
- day_of_week, week_of_year
- is_weekend, is_holiday
- quarter, fiscal_year

dim_product:
- product_key (PK, surrogate key)
- product_id (natural key)
- product_name, category, subcategory
- brand, supplier
- current_price

dim_store:
- store_key (PK)
- store_name, city, region, country

dim_customer:
- customer_key (PK)
- customer_name, segment
- registration_date, tenure_months`,
          pt: `As DimensÃµes sÃ£o tabelas que descrevem "quem, o quÃª, onde, quando":

dim_date:
- date_key (PK, formato YYYYMMDD)
- full_date, day, month, year
- day_of_week, week_of_year
- is_weekend, is_holiday
- quarter, fiscal_year

dim_product:
- product_key (PK, surrogate key)
- product_id (natural key)
- product_name, category, subcategory
- brand, supplier
- current_price

dim_store:
- store_key (PK)
- store_name, city, region, country

dim_customer:
- customer_key (PK)
- customer_name, segment
- registration_date, tenure_months`
        },
        components: ['Dimension Tables', 'Surrogate Keys', 'Attributes'],
        diagram: `
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  dim_date   â”‚
                    â”‚ date_key    â”‚
                    â”‚ day, month  â”‚
                    â”‚ quarter...  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ dim_product â”‚     â”‚ fact_sales  â”‚     â”‚  dim_store  â”‚
â”‚ product_key â”œâ”€â”€â”€â”€â–¶â”‚             â”‚â—€â”€â”€â”€â”€â”¤ store_key   â”‚
â”‚ name, cat.  â”‚     â”‚  measures   â”‚     â”‚ city, regionâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
                    â”‚dim_customer â”‚
                    â”‚customer_key â”‚
                    â”‚ segment...  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      },
      {
        step: 3,
        title: { es: 'Star Schema Completo', en: 'Complete Star Schema', pt: 'Star Schema Completo' },
        description: {
          es: `El Star Schema se llama asÃ­ porque las dimensiones rodean la fact table como una estrella.

Ventajas:
âœ… Queries simples con JOINs directos
âœ… FÃ¡cil de entender para analistas
âœ… Performance optimizada para agregaciones
âœ… Herramientas BI lo soportan nativamente

Query tÃ­pica:
SELECT 
  d.month,
  p.category,
  s.region,
  SUM(f.total_amount) as revenue
FROM fact_sales f
JOIN dim_date d ON f.date_key = d.date_key
JOIN dim_product p ON f.product_key = p.product_key
JOIN dim_store s ON f.store_key = s.store_key
GROUP BY d.month, p.category, s.region

Esta query es rÃ¡pida porque:
- Solo JOINs simples (no cascada)
- Dimensiones son pequeÃ±as
- Fact table estÃ¡ particionada por fecha`,
          en: `The Star Schema is named because dimensions surround the fact table like a star.

Advantages:
âœ… Simple queries with direct JOINs
âœ… Easy to understand for analysts
âœ… Optimized performance for aggregations
âœ… BI tools support it natively

Typical query:
SELECT 
  d.month,
  p.category,
  s.region,
  SUM(f.total_amount) as revenue
FROM fact_sales f
JOIN dim_date d ON f.date_key = d.date_key
JOIN dim_product p ON f.product_key = p.product_key
JOIN dim_store s ON f.store_key = s.store_key
GROUP BY d.month, p.category, s.region

This query is fast because:
- Only simple JOINs (no cascade)
- Dimensions are small
- Fact table is partitioned by date`,
          pt: `O Star Schema se chama assim porque as dimensÃµes cercam a tabela fato como uma estrela.

Vantagens:
âœ… Queries simples com JOINs diretos
âœ… FÃ¡cil de entender para analistas
âœ… Performance otimizada para agregaÃ§Ãµes
âœ… Ferramentas BI suportam nativamente

Query tÃ­pica:
SELECT 
  d.month,
  p.category,
  s.region,
  SUM(f.total_amount) as revenue
FROM fact_sales f
JOIN dim_date d ON f.date_key = d.date_key
JOIN dim_product p ON f.product_key = p.product_key
JOIN dim_store s ON f.store_key = s.store_key
GROUP BY d.month, p.category, s.region

Esta query Ã© rÃ¡pida porque:
- SÃ³ JOINs simples (sem cascata)
- DimensÃµes sÃ£o pequenas
- Tabela fato estÃ¡ particionada por data`
        },
        components: ['Star Schema', 'Query Optimization', 'Partitioning'],
        diagram: `
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚ dim_date  â”‚
                          â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚dim_productâ”‚â”€â”€â”€â”€â”€â”‚fact_sales â”‚â”€â”€â”€â”€â”€â”‚ dim_store â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                          â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
                          â”‚dim_customerâ”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          
                     â­ STAR SCHEMA â­
        `
      },
      {
        step: 4,
        title: { es: 'SCD Tipo 2 para Historial', en: 'SCD Type 2 for History', pt: 'SCD Tipo 2 para HistÃ³rico' },
        description: {
          es: `Para trackear cambios histÃ³ricos usamos Slowly Changing Dimensions (SCD) Tipo 2:

dim_product (con SCD Tipo 2):
- product_key (surrogate key, Ãºnico)
- product_id (natural key, se repite)
- product_name, category, price
- valid_from (fecha inicio)
- valid_to (fecha fin, NULL = actual)
- is_current (boolean)

Ejemplo:
| product_key | product_id | price | valid_from | valid_to   | is_current |
|-------------|------------|-------|------------|------------|------------|
| 1           | PROD-001   | 100   | 2023-01-01 | 2023-06-30 | false      |
| 2           | PROD-001   | 120   | 2023-07-01 | NULL       | true       |

AsÃ­ podemos ver ventas con el precio que tenÃ­a el producto EN ESE MOMENTO.`,
          en: `To track historical changes we use Slowly Changing Dimensions (SCD) Type 2:

dim_product (with SCD Type 2):
- product_key (surrogate key, unique)
- product_id (natural key, repeats)
- product_name, category, price
- valid_from (start date)
- valid_to (end date, NULL = current)
- is_current (boolean)

Example:
| product_key | product_id | price | valid_from | valid_to   | is_current |
|-------------|------------|-------|------------|------------|------------|
| 1           | PROD-001   | 100   | 2023-01-01 | 2023-06-30 | false      |
| 2           | PROD-001   | 120   | 2023-07-01 | NULL       | true       |

This way we can see sales with the price the product had AT THAT TIME.`,
          pt: `Para rastrear mudanÃ§as histÃ³ricas usamos Slowly Changing Dimensions (SCD) Tipo 2:

dim_product (com SCD Tipo 2):
- product_key (surrogate key, Ãºnico)
- product_id (natural key, se repete)
- product_name, category, price
- valid_from (data inÃ­cio)
- valid_to (data fim, NULL = atual)
- is_current (boolean)

Exemplo:
| product_key | product_id | price | valid_from | valid_to   | is_current |
|-------------|------------|-------|------------|------------|------------|
| 1           | PROD-001   | 100   | 2023-01-01 | 2023-06-30 | false      |
| 2           | PROD-001   | 120   | 2023-07-01 | NULL       | true       |

Assim podemos ver vendas com o preÃ§o que o produto tinha NAQUELE MOMENTO.`
        },
        components: ['SCD Type 2', 'Surrogate Keys', 'Historical Tracking'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           dim_product (SCD Type 2)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚product_keyâ”‚product_id â”‚ price â”‚ valid_from â”‚ valid_to  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     1     â”‚ PROD-001  â”‚  100  â”‚ 2023-01-01 â”‚2023-06-30 â”‚
â”‚     2     â”‚ PROD-001  â”‚  120  â”‚ 2023-07-01 â”‚   NULL    â”‚ â† current
â”‚     3     â”‚ PROD-002  â”‚   50  â”‚ 2023-01-01 â”‚   NULL    â”‚ â† current
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      }
    ],
    tradeoffs: [
      {
        decision: { es: 'Star Schema vs Snowflake Schema', en: 'Star Schema vs Snowflake Schema', pt: 'Star Schema vs Snowflake Schema' },
        option1: { es: 'Star: Dimensiones denormalizadas, mÃ¡s simple, queries mÃ¡s rÃ¡pidas', en: 'Star: Denormalized dimensions, simpler, faster queries', pt: 'Star: DimensÃµes desnormalizadas, mais simples, queries mais rÃ¡pidas' },
        option2: { es: 'Snowflake: Dimensiones normalizadas, menos espacio, mÃ¡s JOINs', en: 'Snowflake: Normalized dimensions, less space, more JOINs', pt: 'Snowflake: DimensÃµes normalizadas, menos espaÃ§o, mais JOINs' },
        recommendation: { es: 'Star Schema para la mayorÃ­a de casos - simplicidad > ahorro de espacio', en: 'Star Schema for most cases - simplicity > space savings', pt: 'Star Schema para a maioria dos casos - simplicidade > economia de espaÃ§o' }
      },
      {
        decision: { es: 'SCD Tipo 1 vs Tipo 2', en: 'SCD Type 1 vs Type 2', pt: 'SCD Tipo 1 vs Tipo 2' },
        option1: { es: 'Tipo 1: Sobrescribir (no hay historial), mÃ¡s simple', en: 'Type 1: Overwrite (no history), simpler', pt: 'Tipo 1: Sobrescrever (sem histÃ³rico), mais simples' },
        option2: { es: 'Tipo 2: Nueva fila por cambio (historial completo), mÃ¡s complejo', en: 'Type 2: New row per change (full history), more complex', pt: 'Tipo 2: Nova linha por mudanÃ§a (histÃ³rico completo), mais complexo' },
        recommendation: { es: 'Tipo 2 para precios y atributos importantes. Tipo 1 para datos que no cambian.', en: 'Type 2 for prices and important attributes. Type 1 for data that doesn\'t change.', pt: 'Tipo 2 para preÃ§os e atributos importantes. Tipo 1 para dados que nÃ£o mudam.' }
      }
    ],
    commonMistakes: [
      { es: 'âŒ No usar surrogate keys - problemas cuando cambian IDs naturales', en: 'âŒ Not using surrogate keys - problems when natural IDs change', pt: 'âŒ NÃ£o usar surrogate keys - problemas quando IDs naturais mudam' },
      { es: 'âŒ Poner demasiadas columnas en la fact table (debe ser solo medidas y FKs)', en: 'âŒ Putting too many columns in fact table (should only be measures and FKs)', pt: 'âŒ Colocar muitas colunas na tabela fato (deve ser sÃ³ medidas e FKs)' },
      { es: 'âŒ No crear dim_date - es SIEMPRE necesaria', en: 'âŒ Not creating dim_date - it\'s ALWAYS necessary', pt: 'âŒ NÃ£o criar dim_date - Ã© SEMPRE necessÃ¡ria' },
      { es: 'âŒ Olvidar particionar fact table por fecha', en: 'âŒ Forgetting to partition fact table by date', pt: 'âŒ Esquecer de particionar tabela fato por data' }
    ],
    interviewerTips: [
      { es: 'ğŸ’¡ Siempre empezÃ¡ identificando quÃ© quieren MEDIR (eso es la fact table)', en: 'ğŸ’¡ Always start by identifying what they want to MEASURE (that\'s the fact table)', pt: 'ğŸ’¡ Sempre comece identificando o que querem MEDIR (isso Ã© a tabela fato)' },
      { es: 'ğŸ’¡ PreguntÃ¡ por anÃ¡lisis histÃ³ricos para determinar si necesitan SCD', en: 'ğŸ’¡ Ask about historical analysis to determine if they need SCD', pt: 'ğŸ’¡ Pergunte sobre anÃ¡lises histÃ³ricas para determinar se precisam de SCD' },
      { es: 'ğŸ’¡ DibujÃ¡ el star schema - es muy visual y los entrevistadores lo valoran', en: 'ğŸ’¡ Draw the star schema - it\'s very visual and interviewers appreciate it', pt: 'ğŸ’¡ Desenhe o star schema - Ã© muito visual e os entrevistadores valorizam' }
    ],
    relatedTopics: ['Star Schema', 'Dimensional Modeling', 'SCD', 'Data Warehouse', 'Kimball'],
    estimatedXP: 450
  },

  // ============ INTERVIEW 9: DATA QUALITY PIPELINE (JUNIOR) ============
  {
    id: 'sd-data-quality',
    title: {
      es: 'Pipeline de Calidad de Datos',
      en: 'Data Quality Pipeline',
      pt: 'Pipeline de Qualidade de Dados'
    },
    company: 'Fintech / Startup',
    difficulty: 'junior',
    duration: '30 min',
    tags: ['Data Quality', 'Testing', 'Great Expectations', 'dbt', 'Entry-level'],
    problem: {
      es: `Una fintech tiene problemas con la calidad de sus datos:
- El mes pasado enviaron reportes con nÃºmeros incorrectos al regulador
- Hay clientes con fechas de nacimiento en el futuro
- Algunas transacciones tienen montos negativos que no deberÃ­an
- Los dashboards a veces muestran NULL donde no deberÃ­a

El Data Lead pregunta: "Â¿CÃ³mo diseÃ±arÃ­as un sistema para detectar y alertar sobre problemas de calidad de datos?"`,
      en: `A fintech has data quality problems:
- Last month they sent reports with incorrect numbers to the regulator
- There are customers with birth dates in the future
- Some transactions have negative amounts that shouldn't exist
- Dashboards sometimes show NULL where they shouldn't

The Data Lead asks: "How would you design a system to detect and alert on data quality issues?"`,
      pt: `Uma fintech tem problemas de qualidade de dados:
- No mÃªs passado enviaram relatÃ³rios com nÃºmeros incorretos ao regulador
- HÃ¡ clientes com datas de nascimento no futuro
- Algumas transaÃ§Ãµes tÃªm valores negativos que nÃ£o deveriam existir
- Os dashboards Ã s vezes mostram NULL onde nÃ£o deveriam

O Data Lead pergunta: "Como vocÃª projetaria um sistema para detectar e alertar sobre problemas de qualidade de dados?"`
    },
    clarifyingQuestions: [
      {
        question: { es: 'Â¿CuÃ¡ndo necesitan detectar los problemas? Â¿En tiempo real o estÃ¡ bien diario?', en: 'When do you need to detect issues? Real-time or daily is OK?', pt: 'Quando precisam detectar os problemas? Em tempo real ou diÃ¡rio estÃ¡ ok?' },
        whyAsk: { es: 'Define si necesitamos validaciÃ³n en streaming o batch', en: 'Defines if we need streaming or batch validation', pt: 'Define se precisamos de validaÃ§Ã£o em streaming ou batch' },
        typicalAnswer: { es: 'Con detectar problemas antes del reporte diario estÃ¡ bien', en: 'Detecting issues before the daily report is fine', pt: 'Detectar problemas antes do relatÃ³rio diÃ¡rio estÃ¡ ok' }
      },
      {
        question: { es: 'Â¿QuÃ© pasa cuando detectan un problema? Â¿Bloquean el pipeline o solo alertan?', en: 'What happens when you detect an issue? Block the pipeline or just alert?', pt: 'O que acontece quando detectam um problema? Bloqueiam o pipeline ou sÃ³ alertam?' },
        whyAsk: { es: 'Define si los tests son bloqueantes o solo informativos', en: 'Defines if tests are blocking or just informational', pt: 'Define se os testes sÃ£o bloqueantes ou sÃ³ informativos' },
        typicalAnswer: { es: 'Para datos regulatorios debe bloquear, para dashboards solo alertar', en: 'For regulatory data it must block, for dashboards just alert', pt: 'Para dados regulatÃ³rios deve bloquear, para dashboards sÃ³ alertar' }
      }
    ],
    requirements: {
      functional: [
        { es: 'Validar datos antes de cada carga al warehouse', en: 'Validate data before each warehouse load', pt: 'Validar dados antes de cada carga ao warehouse' },
        { es: 'Alertar cuando hay anomalÃ­as', en: 'Alert when there are anomalies', pt: 'Alertar quando hÃ¡ anomalias' },
        { es: 'Dashboard de estado de calidad de datos', en: 'Data quality status dashboard', pt: 'Dashboard de status de qualidade de dados' },
        { es: 'Historial de problemas detectados', en: 'History of detected issues', pt: 'HistÃ³rico de problemas detectados' }
      ],
      nonFunctional: [
        { es: 'Tests deben correr en < 10 minutos', en: 'Tests must run in < 10 minutes', pt: 'Testes devem rodar em < 10 minutos' },
        { es: 'FÃ¡cil de agregar nuevas reglas', en: 'Easy to add new rules', pt: 'FÃ¡cil de adicionar novas regras' }
      ]
    },
    solution: [
      {
        step: 1,
        title: { es: 'Tipos de Validaciones', en: 'Types of Validations', pt: 'Tipos de ValidaÃ§Ãµes' },
        description: {
          es: `Hay diferentes tipos de checks de calidad:

1. Schema Validation (estructura):
   - Â¿Las columnas existen?
   - Â¿Los tipos de datos son correctos?

2. Completeness (completitud):
   - Â¿Hay NULLs donde no deberÃ­a?
   - Â¿Faltan registros esperados?

3. Uniqueness (unicidad):
   - Â¿Hay duplicados en primary keys?

4. Validity (validez):
   - Â¿Los valores estÃ¡n en rangos vÃ¡lidos?
   - Â¿Los emails tienen formato correcto?

5. Consistency (consistencia):
   - Â¿Los totales cuadran?
   - Â¿Las relaciones FK existen?

6. Freshness (frescura):
   - Â¿Los datos son recientes?`,
          en: `There are different types of quality checks:

1. Schema Validation (structure):
   - Do columns exist?
   - Are data types correct?

2. Completeness:
   - Are there NULLs where they shouldn't be?
   - Are expected records missing?

3. Uniqueness:
   - Are there duplicates in primary keys?

4. Validity:
   - Are values in valid ranges?
   - Do emails have correct format?

5. Consistency:
   - Do totals add up?
   - Do FK relationships exist?

6. Freshness:
   - Is data recent?`,
          pt: `HÃ¡ diferentes tipos de checks de qualidade:

1. Schema Validation (estrutura):
   - As colunas existem?
   - Os tipos de dados estÃ£o corretos?

2. Completeness (completude):
   - HÃ¡ NULLs onde nÃ£o deveria?
   - Faltam registros esperados?

3. Uniqueness (unicidade):
   - HÃ¡ duplicados em primary keys?

4. Validity (validade):
   - Os valores estÃ£o em ranges vÃ¡lidos?
   - Os emails tÃªm formato correto?

5. Consistency (consistÃªncia):
   - Os totais batem?
   - As relaÃ§Ãµes FK existem?

6. Freshness (frescura):
   - Os dados sÃ£o recentes?`
        },
        components: ['Schema', 'Completeness', 'Uniqueness', 'Validity'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Data Quality Dimensions                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Schema    â”‚Completeness â”‚ Uniqueness  â”‚   Validity   â”‚
â”‚  (columns)  â”‚  (NULLs)    â”‚(duplicates) â”‚  (ranges)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Consistency â”‚         Freshness         â”‚   Accuracy   â”‚
â”‚  (totals)   â”‚        (recency)          â”‚  (correct?)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      },
      {
        step: 2,
        title: { es: 'ImplementaciÃ³n con dbt tests', en: 'Implementation with dbt tests', pt: 'ImplementaÃ§Ã£o com dbt tests' },
        description: {
          es: `dbt tiene tests de calidad integrados:

schema.yml:
models:
  - name: customers
    columns:
      - name: customer_id
        tests:
          - unique        # No duplicados
          - not_null      # No NULLs
      - name: email
        tests:
          - unique
          - not_null
      - name: birth_date
        tests:
          - not_null
          - dbt_utils.expression_is_true:
              expression: "birth_date <= current_date"
      - name: balance
        tests:
          - dbt_utils.expression_is_true:
              expression: "balance >= 0"

Tests custom en SQL:
-- tests/assert_total_balance_matches.sql
SELECT 1
WHERE (SELECT SUM(balance) FROM customers)
   != (SELECT total_balance FROM daily_totals)`,
          en: `dbt has built-in quality tests:

schema.yml:
models:
  - name: customers
    columns:
      - name: customer_id
        tests:
          - unique        # No duplicates
          - not_null      # No NULLs
      - name: email
        tests:
          - unique
          - not_null
      - name: birth_date
        tests:
          - not_null
          - dbt_utils.expression_is_true:
              expression: "birth_date <= current_date"
      - name: balance
        tests:
          - dbt_utils.expression_is_true:
              expression: "balance >= 0"

Custom SQL tests:
-- tests/assert_total_balance_matches.sql
SELECT 1
WHERE (SELECT SUM(balance) FROM customers)
   != (SELECT total_balance FROM daily_totals)`,
          pt: `dbt tem testes de qualidade integrados:

schema.yml:
models:
  - name: customers
    columns:
      - name: customer_id
        tests:
          - unique        # Sem duplicados
          - not_null      # Sem NULLs
      - name: email
        tests:
          - unique
          - not_null
      - name: birth_date
        tests:
          - not_null
          - dbt_utils.expression_is_true:
              expression: "birth_date <= current_date"
      - name: balance
        tests:
          - dbt_utils.expression_is_true:
              expression: "balance >= 0"

Testes custom em SQL:
-- tests/assert_total_balance_matches.sql
SELECT 1
WHERE (SELECT SUM(balance) FROM customers)
   != (SELECT total_balance FROM daily_totals)`
        },
        components: ['dbt', 'dbt tests', 'schema.yml'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    dbt Pipeline                          â”‚
â”‚                                                          â”‚
â”‚  Source Data  â†’  dbt run  â†’  dbt test  â†’  Production    â”‚
â”‚                     â”‚            â”‚                       â”‚
â”‚                     â”‚            â–¼                       â”‚
â”‚                     â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚                     â”‚       â”‚ Tests:  â”‚                 â”‚
â”‚                     â”‚       â”‚- unique â”‚                 â”‚
â”‚                     â”‚       â”‚- not_nullâ”‚                â”‚
â”‚                     â”‚       â”‚- custom â”‚                 â”‚
â”‚                     â”‚       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                 â”‚
â”‚                     â”‚            â”‚                       â”‚
â”‚                     â”‚      Pass? â”‚ Fail?                â”‚
â”‚                     â”‚        âœ“   â”‚   âœ—                  â”‚
â”‚                     â”‚            â”‚   â†“                  â”‚
â”‚                     â”‚            â”‚ ALERT!               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      },
      {
        step: 3,
        title: { es: 'Pipeline Completo', en: 'Complete Pipeline', pt: 'Pipeline Completo' },
        description: {
          es: `El pipeline de calidad se integra en el proceso ETL:

1. Ingest: Datos llegan a staging
2. Test staging: Validaciones bÃ¡sicas
3. Transform: dbt transforma datos
4. Test transform: Validaciones de negocio
5. Load: Si todo pasa â†’ producciÃ³n
6. Monitor: Alertas continuas

Severidad de tests:
- ERROR: Bloquea pipeline (datos regulatorios)
- WARN: Solo alerta, pipeline continÃºa
- INFO: Log para anÃ¡lisis

Alertas van a:
- Slack: Para el equipo de datos
- PagerDuty: Para errores crÃ­ticos
- Dashboard: Para tracking histÃ³rico`,
          en: `The quality pipeline integrates into the ETL process:

1. Ingest: Data arrives at staging
2. Test staging: Basic validations
3. Transform: dbt transforms data
4. Test transform: Business validations
5. Load: If all pass â†’ production
6. Monitor: Continuous alerts

Test severity:
- ERROR: Blocks pipeline (regulatory data)
- WARN: Just alert, pipeline continues
- INFO: Log for analysis

Alerts go to:
- Slack: For the data team
- PagerDuty: For critical errors
- Dashboard: For historical tracking`,
          pt: `O pipeline de qualidade se integra no processo ETL:

1. Ingest: Dados chegam no staging
2. Test staging: ValidaÃ§Ãµes bÃ¡sicas
3. Transform: dbt transforma dados
4. Test transform: ValidaÃ§Ãµes de negÃ³cio
5. Load: Se tudo passa â†’ produÃ§Ã£o
6. Monitor: Alertas contÃ­nuas

Severidade dos testes:
- ERROR: Bloqueia pipeline (dados regulatÃ³rios)
- WARN: SÃ³ alerta, pipeline continua
- INFO: Log para anÃ¡lise

Alertas vÃ£o para:
- Slack: Para o time de dados
- PagerDuty: Para erros crÃ­ticos
- Dashboard: Para tracking histÃ³rico`
        },
        components: ['ETL', 'dbt', 'Slack', 'Monitoring'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Source  â”‚â”€â”€â–¶â”‚ Staging â”‚â”€â”€â–¶â”‚Transformâ”‚â”€â”€â–¶â”‚  Prod   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚             â”‚
                   â–¼             â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Tests 1 â”‚   â”‚ Tests 2 â”‚
              â”‚ (basic) â”‚   â”‚(businessâ”‚
              â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                   â”‚             â”‚
                   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚   Alerts    â”‚
                   â”‚ Slack/Pager â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      }
    ],
    tradeoffs: [
      {
        decision: { es: 'dbt tests vs Great Expectations', en: 'dbt tests vs Great Expectations', pt: 'dbt tests vs Great Expectations' },
        option1: { es: 'dbt tests: Integrado, simple, menos features', en: 'dbt tests: Integrated, simple, fewer features', pt: 'dbt tests: Integrado, simples, menos features' },
        option2: { es: 'Great Expectations: MÃ¡s potente, documentaciÃ³n auto, mÃ¡s setup', en: 'Great Expectations: More powerful, auto docs, more setup', pt: 'Great Expectations: Mais potente, docs auto, mais setup' },
        recommendation: { es: 'EmpezÃ¡ con dbt tests, agregÃ¡ GX cuando necesites mÃ¡s poder.', en: 'Start with dbt tests, add GX when you need more power.', pt: 'Comece com dbt tests, adicione GX quando precisar de mais poder.' }
      }
    ],
    commonMistakes: [
      { es: 'âŒ Solo testear en producciÃ³n - los errores ya llegaron', en: 'âŒ Only testing in production - errors already arrived', pt: 'âŒ SÃ³ testar em produÃ§Ã£o - os erros jÃ¡ chegaram' },
      { es: 'âŒ Demasiadas alertas - fatiga de alertas, se ignoran', en: 'âŒ Too many alerts - alert fatigue, they get ignored', pt: 'âŒ Muitos alertas - fadiga de alertas, sÃ£o ignorados' },
      { es: 'âŒ No documentar quÃ© significa cada test', en: 'âŒ Not documenting what each test means', pt: 'âŒ NÃ£o documentar o que cada teste significa' }
    ],
    interviewerTips: [
      { es: 'ğŸ’¡ MencionÃ¡ las 6 dimensiones de calidad de datos', en: 'ğŸ’¡ Mention the 6 dimensions of data quality', pt: 'ğŸ’¡ Mencione as 6 dimensÃµes de qualidade de dados' },
      { es: 'ğŸ’¡ HablÃ¡ de severidades (ERROR vs WARN)', en: 'ğŸ’¡ Talk about severities (ERROR vs WARN)', pt: 'ğŸ’¡ Fale de severidades (ERROR vs WARN)' },
      { es: 'ğŸ’¡ MencionÃ¡ que los tests deben estar en el pipeline, no despuÃ©s', en: 'ğŸ’¡ Mention that tests should be in the pipeline, not after', pt: 'ğŸ’¡ Mencione que os testes devem estar no pipeline, nÃ£o depois' }
    ],
    relatedTopics: ['Data Quality', 'dbt', 'Great Expectations', 'Testing', 'ETL'],
    estimatedXP: 400
  },

  // ============ INTERVIEW 10: LOG ANALYTICS (JUNIOR) ============
  {
    id: 'sd-log-analytics',
    title: {
      es: 'Sistema de Analytics de Logs',
      en: 'Log Analytics System',
      pt: 'Sistema de Analytics de Logs'
    },
    company: 'Tech Company / SaaS',
    difficulty: 'junior',
    duration: '30 min',
    tags: ['Logs', 'ELK', 'Analytics', 'Monitoring', 'Entry-level'],
    problem: {
      es: `Una empresa SaaS tiene 50 microservicios que generan logs.
Problemas actuales:
- Los logs estÃ¡n en cada servidor, hay que hacer SSH para verlos
- Cuando hay un error en producciÃ³n, tardan 30+ min en encontrar la causa
- No saben cuÃ¡ntos errores tienen por dÃ­a
- No pueden buscar por usuario o transacciÃ³n

El DevOps Lead pregunta: "Â¿CÃ³mo centralizarÃ­as los logs para poder analizarlos?"`,
      en: `A SaaS company has 50 microservices generating logs.
Current problems:
- Logs are on each server, need SSH to see them
- When there's a production error, it takes 30+ min to find the cause
- They don't know how many errors they have per day
- They can't search by user or transaction

The DevOps Lead asks: "How would you centralize logs to be able to analyze them?"`,
      pt: `Uma empresa SaaS tem 50 microserviÃ§os que geram logs.
Problemas atuais:
- Os logs estÃ£o em cada servidor, precisa fazer SSH para ver
- Quando hÃ¡ um erro em produÃ§Ã£o, demoram 30+ min para encontrar a causa
- NÃ£o sabem quantos erros tÃªm por dia
- NÃ£o conseguem buscar por usuÃ¡rio ou transaÃ§Ã£o

O DevOps Lead pergunta: "Como vocÃª centralizaria os logs para poder analisÃ¡-los?"`
    },
    clarifyingQuestions: [
      {
        question: { es: 'Â¿CuÃ¡ntos GB de logs generan por dÃ­a?', en: 'How many GB of logs do you generate per day?', pt: 'Quantos GB de logs vocÃªs geram por dia?' },
        whyAsk: { es: 'Define el sizing del cluster y costos', en: 'Defines cluster sizing and costs', pt: 'Define o dimensionamento do cluster e custos' },
        typicalAnswer: { es: 'Unos 50 GB por dÃ­a, 1.5 TB al mes', en: 'About 50 GB per day, 1.5 TB per month', pt: 'Uns 50 GB por dia, 1.5 TB por mÃªs' }
      },
      {
        question: { es: 'Â¿CuÃ¡nto tiempo necesitan retener los logs?', en: 'How long do you need to retain logs?', pt: 'Quanto tempo precisam reter os logs?' },
        whyAsk: { es: 'Define el storage necesario y polÃ­ticas de retenciÃ³n', en: 'Defines storage needed and retention policies', pt: 'Define o storage necessÃ¡rio e polÃ­ticas de retenÃ§Ã£o' },
        typicalAnswer: { es: '30 dÃ­as para bÃºsqueda rÃ¡pida, 1 aÃ±o en archivo', en: '30 days for quick search, 1 year in archive', pt: '30 dias para busca rÃ¡pida, 1 ano em arquivo' }
      },
      {
        question: { es: 'Â¿Los logs tienen un formato estÃ¡ndar o cada servicio logea diferente?', en: 'Do logs have a standard format or does each service log differently?', pt: 'Os logs tÃªm um formato padrÃ£o ou cada serviÃ§o loga diferente?' },
        whyAsk: { es: 'Define si necesitamos parseo complejo', en: 'Defines if we need complex parsing', pt: 'Define se precisamos de parsing complexo' },
        typicalAnswer: { es: 'Cada equipo usa su formato, es un caos', en: 'Each team uses their format, it\'s chaos', pt: 'Cada time usa seu formato, Ã© um caos' }
      }
    ],
    requirements: {
      functional: [
        { es: 'Centralizar logs de todos los servicios', en: 'Centralize logs from all services', pt: 'Centralizar logs de todos os serviÃ§os' },
        { es: 'BÃºsqueda full-text en < 5 segundos', en: 'Full-text search in < 5 seconds', pt: 'Busca full-text em < 5 segundos' },
        { es: 'Dashboard de mÃ©tricas de errores', en: 'Error metrics dashboard', pt: 'Dashboard de mÃ©tricas de erros' },
        { es: 'Alertas cuando hay muchos errores', en: 'Alerts when there are many errors', pt: 'Alertas quando hÃ¡ muitos erros' }
      ],
      nonFunctional: [
        { es: 'Latencia de ingesta < 30 segundos', en: 'Ingestion latency < 30 seconds', pt: 'LatÃªncia de ingestÃ£o < 30 segundos' },
        { es: 'RetenciÃ³n 30 dÃ­as hot, 1 aÃ±o cold', en: 'Retention 30 days hot, 1 year cold', pt: 'RetenÃ§Ã£o 30 dias hot, 1 ano cold' }
      ]
    },
    solution: [
      {
        step: 1,
        title: { es: 'Arquitectura ELK/OpenSearch', en: 'ELK/OpenSearch Architecture', pt: 'Arquitetura ELK/OpenSearch' },
        description: {
          es: `El stack ELK (Elasticsearch, Logstash, Kibana) o su versiÃ³n open source OpenSearch:

Componentes:
- Agents (Filebeat/Fluentd): Recolectan logs de cada servidor
- Kafka (opcional): Buffer para no perder logs
- Logstash: Parsea y transforma logs
- Elasticsearch/OpenSearch: Almacena e indexa
- Kibana: VisualizaciÃ³n y bÃºsqueda

Flujo:
App â†’ Filebeat â†’ Kafka â†’ Logstash â†’ Elasticsearch â†’ Kibana`,
          en: `The ELK stack (Elasticsearch, Logstash, Kibana) or its open source version OpenSearch:

Components:
- Agents (Filebeat/Fluentd): Collect logs from each server
- Kafka (optional): Buffer to not lose logs
- Logstash: Parse and transform logs
- Elasticsearch/OpenSearch: Store and index
- Kibana: Visualization and search

Flow:
App â†’ Filebeat â†’ Kafka â†’ Logstash â†’ Elasticsearch â†’ Kibana`,
          pt: `O stack ELK (Elasticsearch, Logstash, Kibana) ou sua versÃ£o open source OpenSearch:

Componentes:
- Agents (Filebeat/Fluentd): Coletam logs de cada servidor
- Kafka (opcional): Buffer para nÃ£o perder logs
- Logstash: Parseia e transforma logs
- Elasticsearch/OpenSearch: Armazena e indexa
- Kibana: VisualizaÃ§Ã£o e busca

Fluxo:
App â†’ Filebeat â†’ Kafka â†’ Logstash â†’ Elasticsearch â†’ Kibana`
        },
        components: ['Filebeat', 'Kafka', 'Logstash', 'Elasticsearch', 'Kibana'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Service 1â”‚ â”‚Service 2â”‚ â”‚Service Nâ”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚           â”‚           â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ Filebeat
               â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Kafka   â”‚ (buffer)
         â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Logstash  â”‚ (parse)
         â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚Elasticsearchâ”‚
         â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Kibana   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      },
      {
        step: 2,
        title: { es: 'Formato de Logs Estructurado', en: 'Structured Log Format', pt: 'Formato de Logs Estruturado' },
        description: {
          es: `Definir un formato estÃ¡ndar para TODOS los servicios:

JSON estructurado:
{
  "timestamp": "2024-01-15T10:30:00Z",
  "level": "ERROR",
  "service": "payment-api",
  "trace_id": "abc123",
  "user_id": "user_456",
  "message": "Payment failed",
  "error": {
    "type": "CardDeclined",
    "code": "INSUFFICIENT_FUNDS"
  },
  "context": {
    "amount": 100.00,
    "currency": "USD"
  }
}

Campos obligatorios:
- timestamp (ISO 8601)
- level (DEBUG, INFO, WARN, ERROR)
- service (nombre del microservicio)
- trace_id (para tracking distribuido)
- message

Esto permite:
- Filtrar por nivel: level:ERROR
- Buscar por usuario: user_id:user_456
- Seguir una transacciÃ³n: trace_id:abc123`,
          en: `Define a standard format for ALL services:

Structured JSON:
{
  "timestamp": "2024-01-15T10:30:00Z",
  "level": "ERROR",
  "service": "payment-api",
  "trace_id": "abc123",
  "user_id": "user_456",
  "message": "Payment failed",
  "error": {
    "type": "CardDeclined",
    "code": "INSUFFICIENT_FUNDS"
  },
  "context": {
    "amount": 100.00,
    "currency": "USD"
  }
}

Required fields:
- timestamp (ISO 8601)
- level (DEBUG, INFO, WARN, ERROR)
- service (microservice name)
- trace_id (for distributed tracing)
- message

This allows:
- Filter by level: level:ERROR
- Search by user: user_id:user_456
- Follow a transaction: trace_id:abc123`,
          pt: `Definir um formato padrÃ£o para TODOS os serviÃ§os:

JSON estruturado:
{
  "timestamp": "2024-01-15T10:30:00Z",
  "level": "ERROR",
  "service": "payment-api",
  "trace_id": "abc123",
  "user_id": "user_456",
  "message": "Payment failed",
  "error": {
    "type": "CardDeclined",
    "code": "INSUFFICIENT_FUNDS"
  },
  "context": {
    "amount": 100.00,
    "currency": "USD"
  }
}

Campos obrigatÃ³rios:
- timestamp (ISO 8601)
- level (DEBUG, INFO, WARN, ERROR)
- service (nome do microserviÃ§o)
- trace_id (para tracking distribuÃ­do)
- message

Isso permite:
- Filtrar por nÃ­vel: level:ERROR
- Buscar por usuÃ¡rio: user_id:user_456
- Seguir uma transaÃ§Ã£o: trace_id:abc123`
        },
        components: ['JSON', 'Structured Logging', 'Trace ID'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Structured Log Event                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ timestamp â”‚ level â”‚ service    â”‚ trace_id â”‚ message    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2024-01-15â”‚ ERROR â”‚ payment-apiâ”‚ abc123   â”‚ Payment... â”‚
â”‚ 2024-01-15â”‚ INFO  â”‚ user-api   â”‚ abc123   â”‚ User found â”‚
â”‚ 2024-01-15â”‚ ERROR â”‚ payment-apiâ”‚ def456   â”‚ Timeout    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ Same trace_id = same transaction!
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  trace_id:abc123 shows full request flow across servicesâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      },
      {
        step: 3,
        title: { es: 'Dashboards y Alertas', en: 'Dashboards and Alerts', pt: 'Dashboards e Alertas' },
        description: {
          es: `Kibana para visualizaciÃ³n:

Dashboard principal:
- Errores por servicio (last 24h)
- Errores por hora (time series)
- Top 10 tipos de error
- Latencia por servicio

Alertas configuradas:
- MÃ¡s de 100 errores en 5 minutos â†’ Slack
- MÃ¡s de 1000 errores en 1 hora â†’ PagerDuty
- Nuevo tipo de error detectado â†’ Email

Saved searches para debugging:
- "Todos los errores del servicio X"
- "Logs de una transacciÃ³n especÃ­fica"
- "Errores de autenticaciÃ³n"`,
          en: `Kibana for visualization:

Main dashboard:
- Errors by service (last 24h)
- Errors by hour (time series)
- Top 10 error types
- Latency by service

Configured alerts:
- More than 100 errors in 5 minutes â†’ Slack
- More than 1000 errors in 1 hour â†’ PagerDuty
- New error type detected â†’ Email

Saved searches for debugging:
- "All errors from service X"
- "Logs from a specific transaction"
- "Authentication errors"`,
          pt: `Kibana para visualizaÃ§Ã£o:

Dashboard principal:
- Erros por serviÃ§o (last 24h)
- Erros por hora (time series)
- Top 10 tipos de erro
- LatÃªncia por serviÃ§o

Alertas configuradas:
- Mais de 100 erros em 5 minutos â†’ Slack
- Mais de 1000 erros em 1 hora â†’ PagerDuty
- Novo tipo de erro detectado â†’ Email

Buscas salvas para debugging:
- "Todos os erros do serviÃ§o X"
- "Logs de uma transaÃ§Ã£o especÃ­fica"
- "Erros de autenticaÃ§Ã£o"`
        },
        components: ['Kibana', 'Dashboards', 'Alerts'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Kibana Dashboard                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Errors: 234  â”‚  â”‚ Services: 50 â”‚  â”‚ Alerts: 3    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [Graph: Errors over time]                              â”‚
â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–“â–“â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Top Errors:                                             â”‚
â”‚  1. NullPointerException (45)                           â”‚
â”‚  2. ConnectionTimeout (32)                              â”‚
â”‚  3. AuthFailed (28)                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        `
      }
    ],
    tradeoffs: [
      {
        decision: { es: 'ELK self-hosted vs CloudWatch/Datadog', en: 'ELK self-hosted vs CloudWatch/Datadog', pt: 'ELK self-hosted vs CloudWatch/Datadog' },
        option1: { es: 'ELK: MÃ¡s control, mÃ¡s barato a escala, mÃ¡s ops', en: 'ELK: More control, cheaper at scale, more ops', pt: 'ELK: Mais controle, mais barato em escala, mais ops' },
        option2: { es: 'CloudWatch/Datadog: Managed, mÃ¡s caro, menos ops', en: 'CloudWatch/Datadog: Managed, more expensive, less ops', pt: 'CloudWatch/Datadog: Managed, mais caro, menos ops' },
        recommendation: { es: 'Datadog si tenÃ©s budget y querÃ©s simplicidad. ELK si querÃ©s control y ahorro.', en: 'Datadog if you have budget and want simplicity. ELK if you want control and savings.', pt: 'Datadog se tem budget e quer simplicidade. ELK se quer controle e economia.' }
      }
    ],
    commonMistakes: [
      { es: 'âŒ No definir formato estÃ¡ndar - imposible buscar despuÃ©s', en: 'âŒ Not defining standard format - impossible to search later', pt: 'âŒ NÃ£o definir formato padrÃ£o - impossÃ­vel buscar depois' },
      { es: 'âŒ Logear informaciÃ³n sensible (passwords, tokens)', en: 'âŒ Logging sensitive info (passwords, tokens)', pt: 'âŒ Logear informaÃ§Ã£o sensÃ­vel (passwords, tokens)' },
      { es: 'âŒ Logear todo en DEBUG - costos de storage explosivos', en: 'âŒ Logging everything in DEBUG - explosive storage costs', pt: 'âŒ Logear tudo em DEBUG - custos de storage explosivos' }
    ],
    interviewerTips: [
      { es: 'ğŸ’¡ MencionÃ¡ la importancia del trace_id para debugging distribuido', en: 'ğŸ’¡ Mention the importance of trace_id for distributed debugging', pt: 'ğŸ’¡ Mencione a importÃ¢ncia do trace_id para debugging distribuÃ­do' },
      { es: 'ğŸ’¡ HablÃ¡ de retenciÃ³n en tiers (hot/warm/cold)', en: 'ğŸ’¡ Talk about retention in tiers (hot/warm/cold)', pt: 'ğŸ’¡ Fale de retenÃ§Ã£o em tiers (hot/warm/cold)' },
      { es: 'ğŸ’¡ No te olvides de mencionar seguridad - PII en logs', en: 'ğŸ’¡ Don\'t forget to mention security - PII in logs', pt: 'ğŸ’¡ NÃ£o esqueÃ§a de mencionar seguranÃ§a - PII em logs' }
    ],
    relatedTopics: ['ELK', 'Logging', 'Monitoring', 'Observability', 'Microservices'],
    estimatedXP: 400
  },

  // ============ INTERVIEW 11: SOCIAL MEDIA ANALYTICS ============
  {
    id: 'sd-social-analytics',
    title: {
      es: 'Analytics de Redes Sociales',
      en: 'Social Media Analytics Platform',
      pt: 'Analytics de Redes Sociais'
    },
    company: 'Social Media (estilo Twitter/LinkedIn)',
    difficulty: 'mid',
    duration: '45 min',
    tags: ['Streaming', 'Analytics', 'Real-time', 'Aggregations'],
    problem: {
      es: `Sos Data Engineer en una red social con 50M de usuarios activos. 
El equipo de Growth necesita:
1. MÃ©tricas en tiempo real: posts, likes, shares por minuto
2. Tendencias: hashtags trending en los Ãºltimos 15 minutos
3. Analytics por usuario: engagement rate, mejores horarios para postear
4. Dashboard para el equipo de moderaciÃ³n

Â¿CÃ³mo diseÃ±arÃ­as este sistema?`,
      en: `You're a Data Engineer at a social network with 50M active users.
The Growth team needs:
1. Real-time metrics: posts, likes, shares per minute
2. Trends: trending hashtags in the last 15 minutes
3. Per-user analytics: engagement rate, best times to post
4. Dashboard for the moderation team

How would you design this system?`,
      pt: `VocÃª Ã© Data Engineer em uma rede social com 50M de usuÃ¡rios ativos.
O time de Growth precisa de:
1. MÃ©tricas em tempo real: posts, likes, shares por minuto
2. TendÃªncias: hashtags em alta nos Ãºltimos 15 minutos
3. Analytics por usuÃ¡rio: taxa de engajamento, melhores horÃ¡rios para postar
4. Dashboard para o time de moderaÃ§Ã£o

Como vocÃª projetaria este sistema?`
    },
    clarifyingQuestions: [
      {
        question: { es: 'Â¿CuÃ¡ntos eventos por segundo manejamos?', en: 'How many events per second do we handle?', pt: 'Quantos eventos por segundo temos?' },
        whyAsk: { es: 'Define si necesitamos streaming pesado', en: 'Defines if we need heavy streaming', pt: 'Define se precisamos de streaming pesado' },
        typicalAnswer: { es: 'Picos de 100k eventos/segundo', en: 'Peaks of 100k events/second', pt: 'Picos de 100k eventos/segundo' }
      },
      {
        question: { es: 'Â¿QuÃ© latencia es aceptable para trending?', en: 'What latency is acceptable for trending?', pt: 'Que latÃªncia Ã© aceitÃ¡vel para trending?' },
        whyAsk: { es: 'Define la ventana de procesamiento', en: 'Defines the processing window', pt: 'Define a janela de processamento' },
        typicalAnswer: { es: 'MÃ¡ximo 1 minuto de delay', en: 'Maximum 1 minute delay', pt: 'MÃ¡ximo 1 minuto de delay' }
      }
    ],
    requirements: {
      functional: [
        { es: 'Contar eventos en tiempo real', en: 'Count events in real-time', pt: 'Contar eventos em tempo real' },
        { es: 'Calcular trending hashtags cada minuto', en: 'Calculate trending hashtags every minute', pt: 'Calcular trending hashtags a cada minuto' },
        { es: 'Agregar mÃ©tricas por usuario', en: 'Aggregate metrics per user', pt: 'Agregar mÃ©tricas por usuÃ¡rio' }
      ],
      nonFunctional: [
        { es: 'Latencia < 1 minuto para trending', en: 'Latency < 1 minute for trending', pt: 'LatÃªncia < 1 minuto para trending' },
        { es: 'Manejar 100k eventos/segundo', en: 'Handle 100k events/second', pt: 'Lidar com 100k eventos/segundo' },
        { es: '99.9% uptime', en: '99.9% uptime', pt: '99.9% uptime' }
      ]
    },
    solution: [
      {
        step: 1,
        title: { es: 'Ingesta con Kafka', en: 'Ingestion with Kafka', pt: 'IngestÃ£o com Kafka' },
        description: { es: 'Todos los eventos (posts, likes, shares) van a topics de Kafka particionados por user_id', en: 'All events (posts, likes, shares) go to Kafka topics partitioned by user_id', pt: 'Todos os eventos (posts, likes, shares) vÃ£o para topics do Kafka particionados por user_id' },
        components: ['Kafka', 'Schema Registry']
      },
      {
        step: 2,
        title: { es: 'Procesamiento con Flink', en: 'Processing with Flink', pt: 'Processamento com Flink' },
        description: { es: 'Flink para agregaciones en ventanas: trending cada 1 min, mÃ©tricas por usuario cada 5 min', en: 'Flink for windowed aggregations: trending every 1 min, user metrics every 5 min', pt: 'Flink para agregaÃ§Ãµes em janelas: trending a cada 1 min, mÃ©tricas por usuÃ¡rio a cada 5 min' },
        components: ['Apache Flink', 'Windowing', 'State Management'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Events    â”‚â”€â”€â”€â”€â–¶â”‚    Kafka    â”‚â”€â”€â”€â”€â–¶â”‚    Flink    â”‚
â”‚  (50M/day)  â”‚     â”‚  (3 topics) â”‚     â”‚  (windows)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                               â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                          â–¼                          â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚   Redis     â”‚           â”‚  TimescaleDB â”‚           â”‚ ClickHouse  â”‚
             â”‚ (trending)  â”‚           â”‚(user metrics)â”‚           â”‚ (analytics) â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
      },
      {
        step: 3,
        title: { es: 'Storage por caso de uso', en: 'Storage by use case', pt: 'Storage por caso de uso' },
        description: { es: 'Redis para trending (TTL 1h), TimescaleDB para time-series por usuario, ClickHouse para analytics ad-hoc', en: 'Redis for trending (TTL 1h), TimescaleDB for per-user time-series, ClickHouse for ad-hoc analytics', pt: 'Redis para trending (TTL 1h), TimescaleDB para time-series por usuÃ¡rio, ClickHouse para analytics ad-hoc' },
        components: ['Redis', 'TimescaleDB', 'ClickHouse']
      }
    ],
    tradeoffs: [
      {
        decision: { es: 'Flink vs Spark Streaming', en: 'Flink vs Spark Streaming', pt: 'Flink vs Spark Streaming' },
        option1: { es: 'Flink: true streaming, mejor latencia', en: 'Flink: true streaming, better latency', pt: 'Flink: true streaming, melhor latÃªncia' },
        option2: { es: 'Spark: micro-batches, ecosistema mÃ¡s grande', en: 'Spark: micro-batches, bigger ecosystem', pt: 'Spark: micro-batches, ecossistema maior' },
        recommendation: { es: 'Flink para latencia < 1 min. Spark si ya lo usan para batch.', en: 'Flink for latency < 1 min. Spark if already used for batch.', pt: 'Flink para latÃªncia < 1 min. Spark se jÃ¡ usam para batch.' }
      }
    ],
    commonMistakes: [
      { es: 'âŒ No considerar late arrivals (eventos que llegan tarde)', en: 'âŒ Not considering late arrivals', pt: 'âŒ NÃ£o considerar late arrivals (eventos que chegam tarde)' },
      { es: 'âŒ Guardar todo en una sola DB - Redis no escala para histÃ³rico', en: 'âŒ Storing everything in one DB - Redis doesnt scale for historical', pt: 'âŒ Guardar tudo em um sÃ³ DB - Redis nÃ£o escala para histÃ³rico' }
    ],
    interviewerTips: [
      { es: 'ğŸ’¡ MencionÃ¡ watermarks para late arrivals', en: 'ğŸ’¡ Mention watermarks for late arrivals', pt: 'ğŸ’¡ Mencione watermarks para late arrivals' },
      { es: 'ğŸ’¡ HablÃ¡ de backpressure en Flink', en: 'ğŸ’¡ Talk about backpressure in Flink', pt: 'ğŸ’¡ Fale de backpressure no Flink' }
    ],
    relatedTopics: ['Streaming', 'Flink', 'Kafka', 'Redis', 'ClickHouse'],
    estimatedXP: 350
  },

  // ============ INTERVIEW 12: NOTIFICATION SYSTEM ============
  {
    id: 'sd-notification-system',
    title: {
      es: 'Sistema de Notificaciones',
      en: 'Notification System',
      pt: 'Sistema de NotificaÃ§Ãµes'
    },
    company: 'Fintech (estilo app bancaria)',
    difficulty: 'mid',
    duration: '45 min',
    tags: ['Real-time', 'Queues', 'Push Notifications', 'Multi-channel'],
    problem: {
      es: `DiseÃ±Ã¡ un sistema de notificaciones para una app bancaria con 5M de usuarios.
Tipos de notificaciones:
1. Transaccionales: "Recibiste $500" (inmediato)
2. Alertas de fraude: "Detectamos actividad sospechosa" (< 30 seg)
3. Marketing: "Nuevo prÃ©stamo disponible" (batch, mejor horario)

Canales: Push, Email, SMS, In-app
Requisito clave: Las alertas de fraude NUNCA pueden perderse.`,
      en: `Design a notification system for a banking app with 5M users.
Notification types:
1. Transactional: "You received $500" (immediate)
2. Fraud alerts: "We detected suspicious activity" (< 30 sec)
3. Marketing: "New loan available" (batch, best time)

Channels: Push, Email, SMS, In-app
Key requirement: Fraud alerts can NEVER be lost.`,
      pt: `Projete um sistema de notificaÃ§Ãµes para um app bancÃ¡rio com 5M de usuÃ¡rios.
Tipos de notificaÃ§Ãµes:
1. Transacionais: "VocÃª recebeu R$500" (imediato)
2. Alertas de fraude: "Detectamos atividade suspeita" (< 30 seg)
3. Marketing: "Novo emprÃ©stimo disponÃ­vel" (batch, melhor horÃ¡rio)

Canais: Push, Email, SMS, In-app
Requisito chave: Alertas de fraude NUNCA podem ser perdidos.`
    },
    clarifyingQuestions: [
      {
        question: { es: 'Â¿CuÃ¡ntas notificaciones por dÃ­a?', en: 'How many notifications per day?', pt: 'Quantas notificaÃ§Ãµes por dia?' },
        whyAsk: { es: 'Dimensiona la infraestructura', en: 'Sizes the infrastructure', pt: 'Dimensiona a infraestrutura' },
        typicalAnswer: { es: '10M transaccionales, 500k marketing, 10k fraude', en: '10M transactional, 500k marketing, 10k fraud', pt: '10M transacionais, 500k marketing, 10k fraude' }
      }
    ],
    requirements: {
      functional: [
        { es: 'Enviar a mÃºltiples canales segÃºn preferencia', en: 'Send to multiple channels based on preference', pt: 'Enviar para mÃºltiplos canais conforme preferÃªncia' },
        { es: 'PriorizaciÃ³n (fraude > transaccional > marketing)', en: 'Prioritization (fraud > transactional > marketing)', pt: 'PriorizaÃ§Ã£o (fraude > transacional > marketing)' },
        { es: 'DeduplicaciÃ³n (no enviar 2 veces la misma)', en: 'Deduplication (dont send same notification twice)', pt: 'DeduplicaÃ§Ã£o (nÃ£o enviar 2 vezes a mesma)' }
      ],
      nonFunctional: [
        { es: 'Fraude: < 30 segundos, 0 pÃ©rdida', en: 'Fraud: < 30 seconds, 0 loss', pt: 'Fraude: < 30 segundos, 0 perda' },
        { es: '99.99% delivery rate', en: '99.99% delivery rate', pt: '99.99% taxa de entrega' }
      ]
    },
    solution: [
      {
        step: 1,
        title: { es: 'API Gateway con priorizaciÃ³n', en: 'API Gateway with prioritization', pt: 'API Gateway com priorizaÃ§Ã£o' },
        description: { es: 'API recibe notificaciones y las rutea a colas por prioridad', en: 'API receives notifications and routes to queues by priority', pt: 'API recebe notificaÃ§Ãµes e roteia para filas por prioridade' },
        components: ['API Gateway', 'Router'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Notification API                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                  â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Queue: FRAUD â”‚   â”‚Queue: TRANS  â”‚   â”‚Queue: MKTG   â”‚
â”‚  (priority)  â”‚   â”‚  (normal)    â”‚   â”‚  (low)       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                  â”‚                  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Channel Router    â”‚
              â”‚ (Push/Email/SMS)   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
      },
      {
        step: 2,
        title: { es: 'Colas separadas por prioridad', en: 'Separate queues by priority', pt: 'Filas separadas por prioridade' },
        description: { es: 'SQS con colas dedicadas: fraud (FIFO, DLQ), transactional (standard), marketing (scheduled)', en: 'SQS with dedicated queues: fraud (FIFO, DLQ), transactional (standard), marketing (scheduled)', pt: 'SQS com filas dedicadas: fraud (FIFO, DLQ), transactional (standard), marketing (scheduled)' },
        components: ['SQS FIFO', 'Dead Letter Queue', 'CloudWatch']
      },
      {
        step: 3,
        title: { es: 'Workers con retry y DLQ', en: 'Workers with retry and DLQ', pt: 'Workers com retry e DLQ' },
        description: { es: 'Workers procesan colas. Si falla 3 veces â†’ DLQ. Alerta inmediata para fraud DLQ.', en: 'Workers process queues. If fails 3 times â†’ DLQ. Immediate alert for fraud DLQ.', pt: 'Workers processam filas. Se falha 3 vezes â†’ DLQ. Alerta imediato para fraud DLQ.' },
        components: ['Lambda/ECS', 'SNS', 'Twilio', 'Firebase']
      }
    ],
    tradeoffs: [
      {
        decision: { es: 'SQS FIFO vs Kafka', en: 'SQS FIFO vs Kafka', pt: 'SQS FIFO vs Kafka' },
        option1: { es: 'SQS FIFO: garantiza orden y exactly-once, lÃ­mite 300 msg/s por grupo', en: 'SQS FIFO: guarantees order and exactly-once, limit 300 msg/s per group', pt: 'SQS FIFO: garante ordem e exactly-once, limite 300 msg/s por grupo' },
        option2: { es: 'Kafka: mayor throughput, mÃ¡s complejo de operar', en: 'Kafka: higher throughput, more complex to operate', pt: 'Kafka: maior throughput, mais complexo de operar' },
        recommendation: { es: 'SQS para notificaciones (volumen manejable). Kafka si ya lo tienen.', en: 'SQS for notifications (manageable volume). Kafka if you already have it.', pt: 'SQS para notificaÃ§Ãµes (volume gerenciÃ¡vel). Kafka se jÃ¡ tÃªm.' }
      }
    ],
    commonMistakes: [
      { es: 'âŒ Una sola cola para todo - fraude se bloquea por marketing', en: 'âŒ Single queue for everything - fraud gets blocked by marketing', pt: 'âŒ Uma Ãºnica fila para tudo - fraude bloqueia por marketing' },
      { es: 'âŒ No tener DLQ - mensajes se pierden silenciosamente', en: 'âŒ No DLQ - messages get lost silently', pt: 'âŒ NÃ£o ter DLQ - mensagens se perdem silenciosamente' }
    ],
    interviewerTips: [
      { es: 'ğŸ’¡ MencionÃ¡ idempotencia para evitar duplicados', en: 'ğŸ’¡ Mention idempotency to avoid duplicates', pt: 'ğŸ’¡ Mencione idempotÃªncia para evitar duplicados' },
      { es: 'ğŸ’¡ HablÃ¡ de user preferences (horario, canales)', en: 'ğŸ’¡ Talk about user preferences (time, channels)', pt: 'ğŸ’¡ Fale de user preferences (horÃ¡rio, canais)' }
    ],
    relatedTopics: ['Queues', 'SQS', 'Push Notifications', 'Exactly-once'],
    estimatedXP: 350
  },

  // ============ INTERVIEW 13: LEGACY MODERNIZATION ============
  {
    id: 'sd-legacy-modernization',
    title: {
      es: 'ModernizaciÃ³n de Sistemas Legacy',
      en: 'Legacy Systems Modernization',
      pt: 'ModernizaÃ§Ã£o de Sistemas Legacy'
    },
    company: 'Enterprise (banco/retail grande)',
    difficulty: 'senior',
    duration: '45 min',
    tags: ['Modernization', 'Legacy', 'Migration', 'Governance'],
    problem: {
      es: `Un banco tradicional tiene datos en:
- Oracle (core banking, 10TB)
- SQL Server (CRM, 2TB)
- Archivos CSV en file servers (reportes legacy, 500GB)
- Mainframe COBOL (transacciones histÃ³ricas, 5TB)

Quieren migrar a un Data Lake moderno en AWS.
Restricciones:
- No pueden apagar sistemas legacy durante migraciÃ³n
- Compliance: auditorÃ­a de todos los accesos
- Presupuesto: $500k para el primer aÃ±o

Â¿CÃ³mo lo harÃ­as?`,
      en: `A traditional bank has data in:
- Oracle (core banking, 10TB)
- SQL Server (CRM, 2TB)
- CSV files on file servers (legacy reports, 500GB)
- Mainframe COBOL (historical transactions, 5TB)

They want to migrate to a modern Data Lake on AWS.
Constraints:
- Cannot shut down legacy systems during migration
- Compliance: audit all access
- Budget: $500k for first year

How would you do it?`,
      pt: `Um banco tradicional tem dados em:
- Oracle (core banking, 10TB)
- SQL Server (CRM, 2TB)
- Arquivos CSV em file servers (relatÃ³rios legacy, 500GB)
- Mainframe COBOL (transaÃ§Ãµes histÃ³ricas, 5TB)

Eles querem migrar para um Data Lake moderno na AWS.
RestriÃ§Ãµes:
- NÃ£o podem desligar sistemas legacy durante migraÃ§Ã£o
- Compliance: auditoria de todos os acessos
- Budget: $500k para o primeiro ano

Como vocÃª faria?`
    },
    clarifyingQuestions: [
      {
        question: { es: 'Â¿CuÃ¡l es el timeline esperado?', en: 'What is the expected timeline?', pt: 'Qual Ã© o timeline esperado?' },
        whyAsk: { es: 'Define el approach (big bang vs incremental)', en: 'Defines the approach (big bang vs incremental)', pt: 'Define o approach (big bang vs incremental)' },
        typicalAnswer: { es: '18 meses para migraciÃ³n completa', en: '18 months for full migration', pt: '18 meses para migraÃ§Ã£o completa' }
      },
      {
        question: { es: 'Â¿QuÃ© sistemas son crÃ­ticos 24/7?', en: 'Which systems are critical 24/7?', pt: 'Quais sistemas sÃ£o crÃ­ticos 24/7?' },
        whyAsk: { es: 'Define ventanas de migraciÃ³n', en: 'Defines migration windows', pt: 'Define janelas de migraÃ§Ã£o' },
        typicalAnswer: { es: 'Core banking no puede tener downtime', en: 'Core banking cannot have downtime', pt: 'Core banking nÃ£o pode ter downtime' }
      }
    ],
    requirements: {
      functional: [
        { es: 'Migrar 17.5TB sin downtime', en: 'Migrate 17.5TB without downtime', pt: 'Migrar 17.5TB sem downtime' },
        { es: 'CDC para sincronizaciÃ³n continua', en: 'CDC for continuous sync', pt: 'CDC para sincronizaÃ§Ã£o contÃ­nua' },
        { es: 'CatÃ¡logo de datos centralizado', en: 'Centralized data catalog', pt: 'CatÃ¡logo de dados centralizado' }
      ],
      nonFunctional: [
        { es: 'AuditorÃ­a de todos los accesos', en: 'Audit all access', pt: 'Auditoria de todos os acessos' },
        { es: 'EncriptaciÃ³n at rest y in transit', en: 'Encryption at rest and in transit', pt: 'Criptografia at rest e in transit' },
        { es: 'Rollback posible en cualquier fase', en: 'Rollback possible at any phase', pt: 'Rollback possÃ­vel em qualquer fase' }
      ]
    },
    solution: [
      {
        step: 1,
        title: { es: 'Fase 1: Landing Zone', en: 'Phase 1: Landing Zone', pt: 'Fase 1: Landing Zone' },
        description: { es: 'Setup S3 con estructura Medallion, Lake Formation para governance, Glue Catalog', en: 'Setup S3 with Medallion structure, Lake Formation for governance, Glue Catalog', pt: 'Setup S3 com estrutura Medallion, Lake Formation para governance, Glue Catalog' },
        components: ['S3', 'Lake Formation', 'Glue Catalog'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AWS Data Lake                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                   Lake Formation                       â”‚  â”‚
â”‚  â”‚  (Permissions, Auditing, Data Catalog)               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  Bronze    â”‚  â”‚  Silver    â”‚  â”‚   Gold     â”‚            â”‚
â”‚  â”‚  (raw)     â”‚â”€â–¶â”‚ (cleaned)  â”‚â”€â–¶â”‚ (curated)  â”‚            â”‚
â”‚  â”‚  17.5TB    â”‚  â”‚            â”‚  â”‚            â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
      },
      {
        step: 2,
        title: { es: 'Fase 2: CDC con DMS', en: 'Phase 2: CDC with DMS', pt: 'Fase 2: CDC com DMS' },
        description: { es: 'AWS DMS para Oracle/SQL Server con CDC. Full load inicial + ongoing replication.', en: 'AWS DMS for Oracle/SQL Server with CDC. Initial full load + ongoing replication.', pt: 'AWS DMS para Oracle/SQL Server com CDC. Full load inicial + replicaÃ§Ã£o contÃ­nua.' },
        components: ['AWS DMS', 'CDC', 'Schema Conversion Tool']
      },
      {
        step: 3,
        title: { es: 'Fase 3: Mainframe con Connect:Direct', en: 'Phase 3: Mainframe with Connect:Direct', pt: 'Fase 3: Mainframe com Connect:Direct' },
        description: { es: 'Batch diario del mainframe via Connect:Direct o AWS Mainframe Modernization', en: 'Daily batch from mainframe via Connect:Direct or AWS Mainframe Modernization', pt: 'Batch diÃ¡rio do mainframe via Connect:Direct ou AWS Mainframe Modernization' },
        components: ['Connect:Direct', 'AWS Transfer Family']
      },
      {
        step: 4,
        title: { es: 'Fase 4: Cutover gradual', en: 'Phase 4: Gradual cutover', pt: 'Fase 4: Cutover gradual' },
        description: { es: 'Migrar reportes uno por uno. Validar datos. Apagar fuentes legacy cuando estÃ©n replicadas.', en: 'Migrate reports one by one. Validate data. Turn off legacy sources when replicated.', pt: 'Migrar relatÃ³rios um por um. Validar dados. Desligar fontes legacy quando replicadas.' },
        components: ['Data Validation', 'Parallel Running']
      }
    ],
    tradeoffs: [
      {
        decision: { es: 'Big Bang vs Incremental', en: 'Big Bang vs Incremental', pt: 'Big Bang vs Incremental' },
        option1: { es: 'Big Bang: mÃ¡s rÃ¡pido pero alto riesgo', en: 'Big Bang: faster but high risk', pt: 'Big Bang: mais rÃ¡pido mas alto risco' },
        option2: { es: 'Incremental: mÃ¡s seguro pero toma mÃ¡s tiempo', en: 'Incremental: safer but takes longer', pt: 'Incremental: mais seguro mas leva mais tempo' },
        recommendation: { es: 'Incremental SIEMPRE para bancos. El riesgo regulatorio no vale.', en: 'Incremental ALWAYS for banks. The regulatory risk is not worth it.', pt: 'Incremental SEMPRE para bancos. O risco regulatÃ³rio nÃ£o vale.' }
      }
    ],
    commonMistakes: [
      { es: 'âŒ No planear rollback - cuando algo falla, estÃ¡n atrapados', en: 'âŒ Not planning rollback - when something fails, theyre stuck', pt: 'âŒ NÃ£o planejar rollback - quando algo falha, estÃ£o presos' },
      { es: 'âŒ Olvidar data quality checks antes de apagar legacy', en: 'âŒ Forgetting data quality checks before turning off legacy', pt: 'âŒ Esquecer data quality checks antes de desligar legacy' },
      { es: 'âŒ No involucrar compliance desde el dÃ­a 1', en: 'âŒ Not involving compliance from day 1', pt: 'âŒ NÃ£o envolver compliance desde o dia 1' }
    ],
    interviewerTips: [
      { es: 'ğŸ’¡ MencionÃ¡ Lake Formation para governance', en: 'ğŸ’¡ Mention Lake Formation for governance', pt: 'ğŸ’¡ Mencione Lake Formation para governance' },
      { es: 'ğŸ’¡ HablÃ¡ de parallel running antes de cutover', en: 'ğŸ’¡ Talk about parallel running before cutover', pt: 'ğŸ’¡ Fale de parallel running antes de cutover' }
    ],
    relatedTopics: ['Migration', 'Data Lake', 'CDC', 'DMS', 'Governance'],
    estimatedXP: 500
  },

  // ============ INTERVIEW 14: ML FEATURE ENGINEERING ============
  {
    id: 'sd-feature-engineering',
    title: {
      es: 'Feature Engineering Pipeline',
      en: 'Feature Engineering Pipeline',
      pt: 'Pipeline de Feature Engineering'
    },
    company: 'Fintech/E-commerce con ML',
    difficulty: 'senior',
    duration: '45 min',
    tags: ['ML', 'Feature Engineering', 'Real-time', 'Batch'],
    problem: {
      es: `Tu empresa tiene 15 modelos de ML en producciÃ³n:
- DetecciÃ³n de fraude (real-time, < 100ms)
- Recomendaciones (batch, diario)
- Credit scoring (batch + real-time para aplicaciones)

Problemas actuales:
- Cada equipo calcula las mismas features diferente
- Training/serving skew (features distintas en training vs prod)
- No hay versionado de features

DiseÃ±Ã¡ un Feature Store.`,
      en: `Your company has 15 ML models in production:
- Fraud detection (real-time, < 100ms)
- Recommendations (batch, daily)
- Credit scoring (batch + real-time for applications)

Current problems:
- Each team calculates the same features differently
- Training/serving skew (different features in training vs prod)
- No feature versioning

Design a Feature Store.`,
      pt: `Sua empresa tem 15 modelos de ML em produÃ§Ã£o:
- DetecÃ§Ã£o de fraude (real-time, < 100ms)
- RecomendaÃ§Ãµes (batch, diÃ¡rio)
- Credit scoring (batch + real-time para aplicaÃ§Ãµes)

Problemas atuais:
- Cada time calcula as mesmas features diferente
- Training/serving skew (features diferentes em training vs prod)
- NÃ£o hÃ¡ versionamento de features

Projete um Feature Store.`
    },
    clarifyingQuestions: [
      {
        question: { es: 'Â¿CuÃ¡ntas features Ãºnicas tenemos?', en: 'How many unique features do we have?', pt: 'Quantas features Ãºnicas temos?' },
        whyAsk: { es: 'Dimensiona el catÃ¡logo', en: 'Sizes the catalog', pt: 'Dimensiona o catÃ¡logo' },
        typicalAnswer: { es: 'Alrededor de 500 features, 50 compartidas entre modelos', en: 'Around 500 features, 50 shared across models', pt: 'Cerca de 500 features, 50 compartilhadas entre modelos' }
      }
    ],
    requirements: {
      functional: [
        { es: 'CatÃ¡logo de features con metadata', en: 'Feature catalog with metadata', pt: 'CatÃ¡logo de features com metadata' },
        { es: 'Serving online (< 100ms) y offline (batch)', en: 'Online serving (< 100ms) and offline (batch)', pt: 'Serving online (< 100ms) e offline (batch)' },
        { es: 'Versionado y lineage de features', en: 'Feature versioning and lineage', pt: 'Versionamento e lineage de features' }
      ],
      nonFunctional: [
        { es: 'p99 < 50ms para online serving', en: 'p99 < 50ms for online serving', pt: 'p99 < 50ms para online serving' },
        { es: 'Consistencia entre training y serving', en: 'Consistency between training and serving', pt: 'ConsistÃªncia entre training e serving' }
      ]
    },
    solution: [
      {
        step: 1,
        title: { es: 'Arquitectura dual store', en: 'Dual store architecture', pt: 'Arquitetura dual store' },
        description: { es: 'Offline store (S3/Delta) para training, Online store (Redis/DynamoDB) para serving', en: 'Offline store (S3/Delta) for training, Online store (Redis/DynamoDB) for serving', pt: 'Offline store (S3/Delta) para training, Online store (Redis/DynamoDB) para serving' },
        components: ['S3', 'Delta Lake', 'Redis', 'DynamoDB'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Feature Store                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚  Feature       â”‚         â”‚  Feature       â”‚              â”‚
â”‚  â”‚  Computation   â”‚         â”‚  Serving API   â”‚              â”‚
â”‚  â”‚  (Spark/Flink) â”‚         â”‚  (< 50ms p99)  â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚          â”‚                          â”‚                        â”‚
â”‚          â–¼                          â–¼                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ Offline Store  â”‚ â”€â”€syncâ”€â–¶â”‚ Online Store   â”‚              â”‚
â”‚  â”‚ (S3 + Delta)   â”‚         â”‚ (Redis/Dynamo) â”‚              â”‚
â”‚  â”‚ For Training   â”‚         â”‚ For Inference  â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚            Feature Registry / Catalog                  â”‚  â”‚
â”‚  â”‚  (metadata, versions, lineage, ownership)             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
      },
      {
        step: 2,
        title: { es: 'SincronizaciÃ³n offline â†’ online', en: 'Offline â†’ online sync', pt: 'SincronizaÃ§Ã£o offline â†’ online' },
        description: { es: 'Batch job que materializa features del offline store al online store. Para real-time: stream processing.', en: 'Batch job that materializes features from offline to online store. For real-time: stream processing.', pt: 'Batch job que materializa features do offline para online store. Para real-time: stream processing.' },
        components: ['Airflow', 'Spark', 'Flink']
      }
    ],
    tradeoffs: [
      {
        decision: { es: 'Build vs Buy (Feast, Tecton, SageMaker)', en: 'Build vs Buy (Feast, Tecton, SageMaker)', pt: 'Build vs Buy (Feast, Tecton, SageMaker)' },
        option1: { es: 'Build: mÃ¡s control, mÃ¡s esfuerzo', en: 'Build: more control, more effort', pt: 'Build: mais controle, mais esforÃ§o' },
        option2: { es: 'Feast/Tecton: mÃ¡s rÃ¡pido, vendor lock-in', en: 'Feast/Tecton: faster, vendor lock-in', pt: 'Feast/Tecton: mais rÃ¡pido, vendor lock-in' },
        recommendation: { es: 'Feast open-source si tenÃ©s equipo. Tecton/SageMaker si no.', en: 'Feast open-source if you have a team. Tecton/SageMaker if not.', pt: 'Feast open-source se tem equipe. Tecton/SageMaker se nÃ£o.' }
      }
    ],
    commonMistakes: [
      { es: 'âŒ Guardar features sin versionado - imposible reproducir modelos', en: 'âŒ Storing features without versioning - impossible to reproduce models', pt: 'âŒ Guardar features sem versionamento - impossÃ­vel reproduzir modelos' },
      { es: 'âŒ No considerar feature freshness - datos stale en serving', en: 'âŒ Not considering feature freshness - stale data in serving', pt: 'âŒ NÃ£o considerar feature freshness - dados desatualizados em serving' }
    ],
    interviewerTips: [
      { es: 'ğŸ’¡ MencionÃ¡ point-in-time correctness para evitar data leakage', en: 'ğŸ’¡ Mention point-in-time correctness to avoid data leakage', pt: 'ğŸ’¡ Mencione point-in-time correctness para evitar data leakage' },
      { es: 'ğŸ’¡ HablÃ¡ de backfill de features', en: 'ğŸ’¡ Talk about feature backfill', pt: 'ğŸ’¡ Fale de backfill de features' }
    ],
    relatedTopics: ['ML', 'Feature Store', 'Feast', 'Redis', 'Delta Lake'],
    estimatedXP: 450
  },

  // ============ INTERVIEW 15: IOT DATA PLATFORM ============
  {
    id: 'sd-iot-platform',
    title: {
      es: 'Plataforma de Datos IoT',
      en: 'IoT Data Platform',
      pt: 'Plataforma de Dados IoT'
    },
    company: 'Manufactura/Logistics',
    difficulty: 'mid',
    duration: '45 min',
    tags: ['IoT', 'Time-series', 'Edge', 'Streaming'],
    problem: {
      es: `Una fÃ¡brica tiene 10,000 sensores que envÃ­an datos cada segundo:
- Temperatura, presiÃ³n, vibraciÃ³n
- Cada sensor: 1 mensaje/segundo = 10k msg/seg total
- Necesitan: alertas en tiempo real + analytics histÃ³rico

Casos de uso:
1. Alerta si temperatura > umbral (< 5 segundos)
2. PredicciÃ³n de mantenimiento (anÃ¡lisis de tendencias)
3. Dashboard operativo

Â¿CÃ³mo diseÃ±arÃ­as la plataforma?`,
      en: `A factory has 10,000 sensors sending data every second:
- Temperature, pressure, vibration
- Each sensor: 1 message/second = 10k msg/sec total
- They need: real-time alerts + historical analytics

Use cases:
1. Alert if temperature > threshold (< 5 seconds)
2. Predictive maintenance (trend analysis)
3. Operational dashboard

How would you design the platform?`,
      pt: `Uma fÃ¡brica tem 10.000 sensores enviando dados a cada segundo:
- Temperatura, pressÃ£o, vibraÃ§Ã£o
- Cada sensor: 1 mensagem/segundo = 10k msg/seg total
- Precisam de: alertas em tempo real + analytics histÃ³rico

Casos de uso:
1. Alerta se temperatura > limiar (< 5 segundos)
2. ManutenÃ§Ã£o preditiva (anÃ¡lise de tendÃªncias)
3. Dashboard operacional

Como vocÃª projetaria a plataforma?`
    },
    clarifyingQuestions: [
      {
        question: { es: 'Â¿Los sensores tienen conectividad estable?', en: 'Do sensors have stable connectivity?', pt: 'Os sensores tÃªm conectividade estÃ¡vel?' },
        whyAsk: { es: 'Define si necesitamos edge processing', en: 'Defines if we need edge processing', pt: 'Define se precisamos de edge processing' },
        typicalAnswer: { es: 'WiFi industrial, 99% uptime', en: 'Industrial WiFi, 99% uptime', pt: 'WiFi industrial, 99% uptime' }
      }
    ],
    requirements: {
      functional: [
        { es: 'Ingerir 10k mensajes/segundo', en: 'Ingest 10k messages/second', pt: 'Ingerir 10k mensagens/segundo' },
        { es: 'Alertas en < 5 segundos', en: 'Alerts in < 5 seconds', pt: 'Alertas em < 5 segundos' },
        { es: 'RetenciÃ³n de 2 aÃ±os para anÃ¡lisis', en: '2-year retention for analysis', pt: 'RetenÃ§Ã£o de 2 anos para anÃ¡lise' }
      ],
      nonFunctional: [
        { es: 'Alta disponibilidad (fÃ¡brica 24/7)', en: 'High availability (factory 24/7)', pt: 'Alta disponibilidade (fÃ¡brica 24/7)' },
        { es: 'Costo eficiente para storage histÃ³rico', en: 'Cost-efficient for historical storage', pt: 'Custo eficiente para storage histÃ³rico' }
      ]
    },
    solution: [
      {
        step: 1,
        title: { es: 'Ingesta con IoT Core + Kinesis', en: 'Ingestion with IoT Core + Kinesis', pt: 'IngestÃ£o com IoT Core + Kinesis' },
        description: { es: 'AWS IoT Core para MQTT, Kinesis Data Streams para buffering', en: 'AWS IoT Core for MQTT, Kinesis Data Streams for buffering', pt: 'AWS IoT Core para MQTT, Kinesis Data Streams para buffering' },
        components: ['AWS IoT Core', 'Kinesis Data Streams', 'MQTT'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Sensors â”‚â”€â”€â”€â”€â–¶â”‚ IoT Coreâ”‚â”€â”€â”€â”€â–¶â”‚ Kinesis â”‚â”€â”€â”€â”€â–¶â”‚ Consumers   â”‚
â”‚ (10k)   â”‚MQTT â”‚ (MQTT)  â”‚     â”‚ Streams â”‚     â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                â–¼                â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚   Lambda    â”‚  â”‚ Timestream  â”‚  â”‚     S3      â”‚
             â”‚  (alerts)   â”‚  â”‚(time-series)â”‚  â”‚  (archive)  â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
      },
      {
        step: 2,
        title: { es: 'Alertas con Lambda', en: 'Alerts with Lambda', pt: 'Alertas com Lambda' },
        description: { es: 'Lambda procesa cada batch de Kinesis, evalÃºa reglas, dispara SNS si hay alerta', en: 'Lambda processes each Kinesis batch, evaluates rules, triggers SNS if alert', pt: 'Lambda processa cada batch do Kinesis, avalia regras, dispara SNS se hÃ¡ alerta' },
        components: ['Lambda', 'SNS', 'Rules Engine']
      },
      {
        step: 3,
        title: { es: 'Storage dual: Timestream + S3', en: 'Dual storage: Timestream + S3', pt: 'Storage dual: Timestream + S3' },
        description: { es: 'Timestream para queries recientes (30 dÃ­as), S3 Parquet para histÃ³rico (2 aÃ±os)', en: 'Timestream for recent queries (30 days), S3 Parquet for historical (2 years)', pt: 'Timestream para queries recentes (30 dias), S3 Parquet para histÃ³rico (2 anos)' },
        components: ['Timestream', 'S3', 'Parquet']
      }
    ],
    tradeoffs: [
      {
        decision: { es: 'Timestream vs InfluxDB vs TimescaleDB', en: 'Timestream vs InfluxDB vs TimescaleDB', pt: 'Timestream vs InfluxDB vs TimescaleDB' },
        option1: { es: 'Timestream: serverless, mÃ¡s caro', en: 'Timestream: serverless, more expensive', pt: 'Timestream: serverless, mais caro' },
        option2: { es: 'InfluxDB/Timescale: mÃ¡s barato, hay que operar', en: 'InfluxDB/Timescale: cheaper, need to operate', pt: 'InfluxDB/Timescale: mais barato, precisa operar' },
        recommendation: { es: 'Timestream si no querÃ©s ops. Timescale si tenÃ©s equipo de infra.', en: 'Timestream if you dont want ops. Timescale if you have infra team.', pt: 'Timestream se nÃ£o quer ops. Timescale se tem equipe de infra.' }
      }
    ],
    commonMistakes: [
      { es: 'âŒ Guardar todo en hot storage - costos explotan', en: 'âŒ Storing everything in hot storage - costs explode', pt: 'âŒ Guardar tudo em hot storage - custos explodem' },
      { es: 'âŒ No comprimir datos - IoT genera mucho volumen', en: 'âŒ Not compressing data - IoT generates high volume', pt: 'âŒ NÃ£o comprimir dados - IoT gera muito volume' }
    ],
    interviewerTips: [
      { es: 'ğŸ’¡ MencionÃ¡ downsampling para datos histÃ³ricos', en: 'ğŸ’¡ Mention downsampling for historical data', pt: 'ğŸ’¡ Mencione downsampling para dados histÃ³ricos' },
      { es: 'ğŸ’¡ HablÃ¡ de edge computing si hay latencia de red', en: 'ğŸ’¡ Talk about edge computing if there is network latency', pt: 'ğŸ’¡ Fale de edge computing se hÃ¡ latÃªncia de rede' }
    ],
    relatedTopics: ['IoT', 'Time-series', 'Kinesis', 'Timestream', 'MQTT'],
    estimatedXP: 350
  },

  // ============ INTERVIEW 16: A/B TESTING PLATFORM ============
  {
    id: 'sd-ab-testing',
    title: {
      es: 'Plataforma de A/B Testing',
      en: 'A/B Testing Platform',
      pt: 'Plataforma de A/B Testing'
    },
    company: 'Tech company (producto digital)',
    difficulty: 'mid',
    duration: '45 min',
    tags: ['A/B Testing', 'Experimentation', 'Analytics', 'Statistics'],
    problem: {
      es: `Tu empresa quiere lanzar 50 experimentos por semana.
Necesitan una plataforma que permita:
1. Definir experimentos y variantes
2. Asignar usuarios a variantes consistentemente
3. Calcular mÃ©tricas y significancia estadÃ­stica
4. Dashboard para PMs

Usuarios: 10M activos mensuales
Eventos: 100M por dÃ­a`,
      en: `Your company wants to run 50 experiments per week.
They need a platform that allows:
1. Define experiments and variants
2. Assign users to variants consistently
3. Calculate metrics and statistical significance
4. Dashboard for PMs

Users: 10M monthly active
Events: 100M per day`,
      pt: `Sua empresa quer rodar 50 experimentos por semana.
Precisam de uma plataforma que permita:
1. Definir experimentos e variantes
2. Atribuir usuÃ¡rios a variantes consistentemente
3. Calcular mÃ©tricas e significÃ¢ncia estatÃ­stica
4. Dashboard para PMs

UsuÃ¡rios: 10M ativos mensais
Eventos: 100M por dia`
    },
    clarifyingQuestions: [
      {
        question: { es: 'Â¿QuÃ© mÃ©tricas son las mÃ¡s importantes?', en: 'What metrics are most important?', pt: 'Quais mÃ©tricas sÃ£o mais importantes?' },
        whyAsk: { es: 'Define quÃ© calcular en tiempo real vs batch', en: 'Defines what to calculate real-time vs batch', pt: 'Define o que calcular em tempo real vs batch' },
        typicalAnswer: { es: 'ConversiÃ³n (real-time), Revenue per user (batch)', en: 'Conversion (real-time), Revenue per user (batch)', pt: 'ConversÃ£o (real-time), Revenue per user (batch)' }
      }
    ],
    requirements: {
      functional: [
        { es: 'AsignaciÃ³n determinÃ­stica (mismo user = misma variante)', en: 'Deterministic assignment (same user = same variant)', pt: 'AtribuiÃ§Ã£o determinÃ­stica (mesmo user = mesma variante)' },
        { es: 'CÃ¡lculo de p-value automÃ¡tico', en: 'Automatic p-value calculation', pt: 'CÃ¡lculo de p-value automÃ¡tico' },
        { es: 'SegmentaciÃ³n (paÃ­s, device, etc.)', en: 'Segmentation (country, device, etc.)', pt: 'SegmentaÃ§Ã£o (paÃ­s, device, etc.)' }
      ],
      nonFunctional: [
        { es: 'Latencia < 50ms para assignment', en: 'Latency < 50ms for assignment', pt: 'LatÃªncia < 50ms para assignment' },
        { es: 'Resultados disponibles en < 24h', en: 'Results available in < 24h', pt: 'Resultados disponÃ­veis em < 24h' }
      ]
    },
    solution: [
      {
        step: 1,
        title: { es: 'Assignment Service', en: 'Assignment Service', pt: 'Assignment Service' },
        description: { es: 'Hash(user_id + experiment_id) % 100 para asignar variante. Cachear en Redis.', en: 'Hash(user_id + experiment_id) % 100 for variant assignment. Cache in Redis.', pt: 'Hash(user_id + experiment_id) % 100 para atribuir variante. Cachear no Redis.' },
        components: ['Assignment Service', 'Redis', 'Consistent Hashing'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   App    â”‚â”€â”€â”€â”€â–¶â”‚ Assignment API  â”‚â”€â”€â”€â”€â–¶â”‚  Redis  â”‚
â”‚          â”‚     â”‚ hash(uid+exp)   â”‚     â”‚ (cache) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚ Experiment      â”‚
                 â”‚ Config DB       â”‚
                 â”‚ (PostgreSQL)    â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
      },
      {
        step: 2,
        title: { es: 'Event Collection', en: 'Event Collection', pt: 'Coleta de Eventos' },
        description: { es: 'Eventos con experiment_id y variant van a Kafka â†’ ClickHouse', en: 'Events with experiment_id and variant go to Kafka â†’ ClickHouse', pt: 'Eventos com experiment_id e variant vÃ£o para Kafka â†’ ClickHouse' },
        components: ['Kafka', 'ClickHouse', 'Event Schema']
      },
      {
        step: 3,
        title: { es: 'Statistics Engine', en: 'Statistics Engine', pt: 'Engine de EstatÃ­sticas' },
        description: { es: 'Cron diario que calcula mÃ©tricas por experimento, variante. T-test para significancia.', en: 'Daily cron that calculates metrics per experiment, variant. T-test for significance.', pt: 'Cron diÃ¡rio que calcula mÃ©tricas por experimento, variante. T-test para significÃ¢ncia.' },
        components: ['Spark', 'Statistical Tests', 'Confidence Intervals']
      }
    ],
    tradeoffs: [
      {
        decision: { es: 'Build vs Buy (Optimizely, LaunchDarkly)', en: 'Build vs Buy (Optimizely, LaunchDarkly)', pt: 'Build vs Buy (Optimizely, LaunchDarkly)' },
        option1: { es: 'Build: mÃ¡s control, necesitÃ¡s estadÃ­sticos', en: 'Build: more control, need statisticians', pt: 'Build: mais controle, precisa de estatÃ­sticos' },
        option2: { es: 'Buy: mÃ¡s rÃ¡pido, vendor lock-in', en: 'Buy: faster, vendor lock-in', pt: 'Buy: mais rÃ¡pido, vendor lock-in' },
        recommendation: { es: 'Comprar al principio. Construir cuando tengas 100+ experimentos/mes.', en: 'Buy at first. Build when you have 100+ experiments/month.', pt: 'Comprar no inÃ­cio. Construir quando tiver 100+ experimentos/mÃªs.' }
      }
    ],
    commonMistakes: [
      { es: 'âŒ No usar hashing consistente - user ve variantes diferentes', en: 'âŒ Not using consistent hashing - user sees different variants', pt: 'âŒ NÃ£o usar hashing consistente - user vÃª variantes diferentes' },
      { es: 'âŒ Peeking (mirar resultados antes de sample size)', en: 'âŒ Peeking (looking at results before sample size)', pt: 'âŒ Peeking (olhar resultados antes do sample size)' }
    ],
    interviewerTips: [
      { es: 'ğŸ’¡ MencionÃ¡ multiple testing correction (Bonferroni)', en: 'ğŸ’¡ Mention multiple testing correction (Bonferroni)', pt: 'ğŸ’¡ Mencione multiple testing correction (Bonferroni)' },
      { es: 'ğŸ’¡ HablÃ¡ de guardrail metrics', en: 'ğŸ’¡ Talk about guardrail metrics', pt: 'ğŸ’¡ Fale de guardrail metrics' }
    ],
    relatedTopics: ['A/B Testing', 'Statistics', 'Hashing', 'ClickHouse'],
    estimatedXP: 350
  },

  // ============ INTERVIEW 17: SEARCH SYSTEM ============
  {
    id: 'sd-search-system',
    title: {
      es: 'Sistema de BÃºsqueda',
      en: 'Search System',
      pt: 'Sistema de Busca'
    },
    company: 'E-commerce/Content platform',
    difficulty: 'mid',
    duration: '45 min',
    tags: ['Search', 'Elasticsearch', 'Relevance', 'NLP'],
    problem: {
      es: `DiseÃ±Ã¡ el sistema de bÃºsqueda para una plataforma de e-commerce:
- 5 millones de productos
- 10k bÃºsquedas por segundo en picos
- Necesitan: autocomplete, typo tolerance, filtros, ranking personalizado

El equipo de producto se queja de que los resultados no son relevantes.`,
      en: `Design the search system for an e-commerce platform:
- 5 million products
- 10k searches per second at peak
- Need: autocomplete, typo tolerance, filters, personalized ranking

The product team complains that results are not relevant.`,
      pt: `Projete o sistema de busca para uma plataforma de e-commerce:
- 5 milhÃµes de produtos
- 10k buscas por segundo em picos
- Precisam de: autocomplete, tolerÃ¢ncia a erros, filtros, ranking personalizado

O time de produto reclama que os resultados nÃ£o sÃ£o relevantes.`
    },
    clarifyingQuestions: [
      {
        question: { es: 'Â¿QuÃ© latencia es aceptable?', en: 'What latency is acceptable?', pt: 'Que latÃªncia Ã© aceitÃ¡vel?' },
        whyAsk: { es: 'Define la arquitectura de caching', en: 'Defines caching architecture', pt: 'Define a arquitetura de caching' },
        typicalAnswer: { es: 'p95 < 200ms', en: 'p95 < 200ms', pt: 'p95 < 200ms' }
      }
    ],
    requirements: {
      functional: [
        { es: 'BÃºsqueda full-text con relevance scoring', en: 'Full-text search with relevance scoring', pt: 'Busca full-text com relevance scoring' },
        { es: 'Autocomplete en < 100ms', en: 'Autocomplete in < 100ms', pt: 'Autocomplete em < 100ms' },
        { es: 'Filtros (precio, categorÃ­a, rating)', en: 'Filters (price, category, rating)', pt: 'Filtros (preÃ§o, categoria, rating)' }
      ],
      nonFunctional: [
        { es: 'p95 < 200ms', en: 'p95 < 200ms', pt: 'p95 < 200ms' },
        { es: 'IndexaciÃ³n near real-time (< 1 min)', en: 'Near real-time indexing (< 1 min)', pt: 'IndexaÃ§Ã£o near real-time (< 1 min)' }
      ]
    },
    solution: [
      {
        step: 1,
        title: { es: 'Elasticsearch cluster', en: 'Elasticsearch cluster', pt: 'Elasticsearch cluster' },
        description: { es: 'Cluster de ES con 3 nodos mÃ­nimo. Ãndice por categorÃ­a para mejor performance.', en: 'ES cluster with minimum 3 nodes. Index per category for better performance.', pt: 'Cluster de ES com mÃ­nimo 3 nÃ³s. Ãndice por categoria para melhor performance.' },
        components: ['Elasticsearch', 'Kibana'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Search Architecture                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  User   â”‚â”€â”€â”€â”€â–¶â”‚ Search API  â”‚â”€â”€â”€â”€â–¶â”‚   Elasticsearch     â”‚ â”‚
â”‚  â”‚         â”‚     â”‚             â”‚     â”‚   (3-node cluster)  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                         â”‚                                     â”‚
â”‚                         â–¼                                     â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚                  â”‚    Redis    â”‚                              â”‚
â”‚                  â”‚(autocompleteâ”‚                              â”‚
â”‚                  â”‚   cache)    â”‚                              â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              Indexing Pipeline                           â”‚ â”‚
â”‚  â”‚  Products DB â”€â”€â–¶ Kafka â”€â”€â–¶ Index Worker â”€â”€â–¶ ES          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
      },
      {
        step: 2,
        title: { es: 'Relevance tuning', en: 'Relevance tuning', pt: 'Relevance tuning' },
        description: { es: 'BM25 base + boosts personalizados: ventas recientes, rating, match en tÃ­tulo > descripciÃ³n', en: 'BM25 base + custom boosts: recent sales, rating, title match > description', pt: 'BM25 base + boosts personalizados: vendas recentes, rating, match em tÃ­tulo > descriÃ§Ã£o' },
        components: ['BM25', 'Custom Scoring', 'Learning to Rank']
      },
      {
        step: 3,
        title: { es: 'Autocomplete con prefix index', en: 'Autocomplete with prefix index', pt: 'Autocomplete com prefix index' },
        description: { es: 'Edge n-gram tokenizer + Redis cache de las 10k queries mÃ¡s comunes', en: 'Edge n-gram tokenizer + Redis cache of top 10k queries', pt: 'Edge n-gram tokenizer + Redis cache das 10k queries mais comuns' },
        components: ['Edge N-gram', 'Redis', 'Completion Suggester']
      }
    ],
    tradeoffs: [
      {
        decision: { es: 'Elasticsearch vs Algolia vs Typesense', en: 'Elasticsearch vs Algolia vs Typesense', pt: 'Elasticsearch vs Algolia vs Typesense' },
        option1: { es: 'ES: mÃ¡s control, mÃ¡s ops', en: 'ES: more control, more ops', pt: 'ES: mais controle, mais ops' },
        option2: { es: 'Algolia: instant setup, caro a escala', en: 'Algolia: instant setup, expensive at scale', pt: 'Algolia: setup instantÃ¢neo, caro em escala' },
        recommendation: { es: 'Algolia para MVP. ES para 1M+ productos.', en: 'Algolia for MVP. ES for 1M+ products.', pt: 'Algolia para MVP. ES para 1M+ produtos.' }
      }
    ],
    commonMistakes: [
      { es: 'âŒ No usar analyzer correcto para el idioma', en: 'âŒ Not using correct analyzer for language', pt: 'âŒ NÃ£o usar analyzer correto para o idioma' },
      { es: 'âŒ Indexar todo en un solo Ã­ndice gigante', en: 'âŒ Indexing everything in one giant index', pt: 'âŒ Indexar tudo em um Ãºnico Ã­ndice gigante' }
    ],
    interviewerTips: [
      { es: 'ğŸ’¡ MencionÃ¡ synonyms y stemming', en: 'ğŸ’¡ Mention synonyms and stemming', pt: 'ğŸ’¡ Mencione synonyms e stemming' },
      { es: 'ğŸ’¡ HablÃ¡ de Learning to Rank para personalizaciÃ³n', en: 'ğŸ’¡ Talk about Learning to Rank for personalization', pt: 'ğŸ’¡ Fale de Learning to Rank para personalizaÃ§Ã£o' }
    ],
    relatedTopics: ['Search', 'Elasticsearch', 'NLP', 'Relevance'],
    estimatedXP: 350
  },

  // ============ INTERVIEW 18: COST OPTIMIZATION ============
  {
    id: 'sd-cost-optimization',
    title: {
      es: 'Dashboard de Costos Cloud',
      en: 'Cloud Cost Optimization Dashboard',
      pt: 'Dashboard de Custos Cloud'
    },
    company: 'Cualquier empresa con cloud spend significativo',
    difficulty: 'mid',
    duration: '45 min',
    tags: ['FinOps', 'Cost Management', 'AWS', 'Analytics'],
    problem: {
      es: `Tu empresa gasta $500k/mes en AWS y nadie sabe exactamente en quÃ©.
Necesitan:
1. Dashboard que muestre costo por equipo/proyecto/servicio
2. Alertas cuando un servicio excede su presupuesto
3. Recomendaciones de ahorro (instancias idle, reserved vs on-demand)
4. Forecasting de costos

Â¿CÃ³mo lo diseÃ±arÃ­as?`,
      en: `Your company spends $500k/month on AWS and nobody knows exactly on what.
They need:
1. Dashboard showing cost by team/project/service
2. Alerts when a service exceeds budget
3. Savings recommendations (idle instances, reserved vs on-demand)
4. Cost forecasting

How would you design it?`,
      pt: `Sua empresa gasta $500k/mÃªs na AWS e ninguÃ©m sabe exatamente em quÃª.
Precisam de:
1. Dashboard mostrando custo por time/projeto/serviÃ§o
2. Alertas quando um serviÃ§o excede o orÃ§amento
3. RecomendaÃ§Ãµes de economia (instÃ¢ncias ociosas, reserved vs on-demand)
4. Forecasting de custos

Como vocÃª projetaria?`
    },
    clarifyingQuestions: [
      {
        question: { es: 'Â¿CÃ³mo estÃ¡n taggeados los recursos actualmente?', en: 'How are resources currently tagged?', pt: 'Como os recursos estÃ£o taggeados atualmente?' },
        whyAsk: { es: 'Sin tags, no hay forma de atribuir costos', en: 'Without tags, theres no way to attribute costs', pt: 'Sem tags, nÃ£o hÃ¡ como atribuir custos' },
        typicalAnswer: { es: 'Parcialmente - algunos tienen team tag, muchos no', en: 'Partially - some have team tag, many dont', pt: 'Parcialmente - alguns tÃªm team tag, muitos nÃ£o' }
      }
    ],
    requirements: {
      functional: [
        { es: 'Ingerir Cost and Usage Report de AWS', en: 'Ingest AWS Cost and Usage Report', pt: 'Ingerir Cost and Usage Report da AWS' },
        { es: 'Atribuir costos a equipos via tags', en: 'Attribute costs to teams via tags', pt: 'Atribuir custos a times via tags' },
        { es: 'Alertas de budget threshold', en: 'Budget threshold alerts', pt: 'Alertas de limite de orÃ§amento' }
      ],
      nonFunctional: [
        { es: 'Datos actualizados diariamente', en: 'Data updated daily', pt: 'Dados atualizados diariamente' },
        { es: 'HistÃ³rico de 12 meses', en: '12 month history', pt: 'HistÃ³rico de 12 meses' }
      ]
    },
    solution: [
      {
        step: 1,
        title: { es: 'Ingesta de CUR', en: 'CUR Ingestion', pt: 'IngestÃ£o de CUR' },
        description: { es: 'AWS Cost and Usage Report a S3, Glue Crawler, Athena para queries', en: 'AWS Cost and Usage Report to S3, Glue Crawler, Athena for queries', pt: 'AWS Cost and Usage Report para S3, Glue Crawler, Athena para queries' },
        components: ['CUR', 'S3', 'Glue', 'Athena'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Cost Optimization Platform                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  AWS CUR â”€â”€â–¶ S3 â”€â”€â–¶ Glue Crawler â”€â”€â–¶ Athena                â”‚
â”‚    (CSV)     â”‚                         â”‚                    â”‚
â”‚              â”‚                         â–¼                    â”‚
â”‚              â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚              â”‚                  â”‚  QuickSight â”‚            â”‚
â”‚              â”‚                  â”‚ (dashboard) â”‚            â”‚
â”‚              â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚              â”‚                                              â”‚
â”‚              â–¼                                              â”‚
â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚       â”‚ Lambda      â”‚â”€â”€â”€â”€â–¶â”‚    SNS      â”‚                  â”‚
â”‚       â”‚ (alerts)    â”‚     â”‚  (notify)   â”‚                  â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
      },
      {
        step: 2,
        title: { es: 'Tagging enforcement', en: 'Tagging enforcement', pt: 'Tagging enforcement' },
        description: { es: 'AWS Config rules para detectar recursos sin tags. SCPs para prevenir creaciÃ³n sin tags.', en: 'AWS Config rules to detect untagged resources. SCPs to prevent creation without tags.', pt: 'AWS Config rules para detectar recursos sem tags. SCPs para prevenir criaÃ§Ã£o sem tags.' },
        components: ['AWS Config', 'SCPs', 'Tag Editor']
      },
      {
        step: 3,
        title: { es: 'Recommendations engine', en: 'Recommendations engine', pt: 'Engine de recomendaÃ§Ãµes' },
        description: { es: 'AWS Cost Explorer API + Trusted Advisor para sugerencias. Calcular savings si migran a Reserved.', en: 'AWS Cost Explorer API + Trusted Advisor for suggestions. Calculate savings if migrating to Reserved.', pt: 'AWS Cost Explorer API + Trusted Advisor para sugestÃµes. Calcular savings se migrarem para Reserved.' },
        components: ['Cost Explorer', 'Trusted Advisor', 'Compute Optimizer']
      }
    ],
    tradeoffs: [
      {
        decision: { es: 'Build vs Buy (CloudHealth, Spot.io)', en: 'Build vs Buy (CloudHealth, Spot.io)', pt: 'Build vs Buy (CloudHealth, Spot.io)' },
        option1: { es: 'Build: mÃ¡s barato, mÃ¡s trabajo', en: 'Build: cheaper, more work', pt: 'Build: mais barato, mais trabalho' },
        option2: { es: 'Buy: mÃ¡s rÃ¡pido, costo mensual', en: 'Buy: faster, monthly cost', pt: 'Buy: mais rÃ¡pido, custo mensal' },
        recommendation: { es: 'Athena + QuickSight para empezar. CloudHealth si > $1M/mes.', en: 'Athena + QuickSight to start. CloudHealth if > $1M/month.', pt: 'Athena + QuickSight para comeÃ§ar. CloudHealth se > $1M/mÃªs.' }
      }
    ],
    commonMistakes: [
      { es: 'âŒ No enforzar tagging desde el principio', en: 'âŒ Not enforcing tagging from the beginning', pt: 'âŒ NÃ£o enforÃ§ar tagging desde o inÃ­cio' },
      { es: 'âŒ Ignorar datos de dÃ­as anteriores al calcular trends', en: 'âŒ Ignoring previous days data when calculating trends', pt: 'âŒ Ignorar dados de dias anteriores ao calcular trends' }
    ],
    interviewerTips: [
      { es: 'ğŸ’¡ MencionÃ¡ Savings Plans vs Reserved Instances', en: 'ğŸ’¡ Mention Savings Plans vs Reserved Instances', pt: 'ğŸ’¡ Mencione Savings Plans vs Reserved Instances' },
      { es: 'ğŸ’¡ HablÃ¡ de rightsizing recommendations', en: 'ğŸ’¡ Talk about rightsizing recommendations', pt: 'ğŸ’¡ Fale de rightsizing recommendations' }
    ],
    relatedTopics: ['FinOps', 'AWS', 'Cost Management', 'Athena'],
    estimatedXP: 300
  },

  // ============ INTERVIEW 19: DATA CATALOG ============
  {
    id: 'sd-data-catalog',
    title: {
      es: 'Data Catalog y Governance',
      en: 'Data Catalog & Governance',
      pt: 'Data Catalog e Governance'
    },
    company: 'Enterprise (cualquier empresa grande)',
    difficulty: 'senior',
    duration: '45 min',
    tags: ['Data Catalog', 'Governance', 'Metadata', 'Compliance'],
    problem: {
      es: `Tu empresa tiene 500+ datasets en diferentes sistemas (Snowflake, S3, PostgreSQL).
Problemas:
- Nadie sabe quÃ© datos existen o quÃ© significan
- No hay forma de saber quiÃ©n tiene acceso a quÃ©
- Compliance pregunta por PII y no saben dÃ³nde estÃ¡
- Data scientists pierden horas buscando el dataset correcto

DiseÃ±Ã¡ un Data Catalog.`,
      en: `Your company has 500+ datasets in different systems (Snowflake, S3, PostgreSQL).
Problems:
- Nobody knows what data exists or what it means
- No way to know who has access to what
- Compliance asks about PII and they dont know where it is
- Data scientists waste hours looking for the right dataset

Design a Data Catalog.`,
      pt: `Sua empresa tem 500+ datasets em diferentes sistemas (Snowflake, S3, PostgreSQL).
Problemas:
- NinguÃ©m sabe que dados existem ou o que significam
- NÃ£o hÃ¡ como saber quem tem acesso ao quÃª
- Compliance pergunta sobre PII e nÃ£o sabem onde estÃ¡
- Data scientists perdem horas procurando o dataset certo

Projete um Data Catalog.`
    },
    clarifyingQuestions: [
      {
        question: { es: 'Â¿Hay algÃºn catÃ¡logo parcial existente?', en: 'Is there any existing partial catalog?', pt: 'HÃ¡ algum catÃ¡logo parcial existente?' },
        whyAsk: { es: 'Define si empezamos de cero', en: 'Defines if we start from scratch', pt: 'Define se comeÃ§amos do zero' },
        typicalAnswer: { es: 'Hay un Excel con algunos datasets, desactualizado', en: 'Theres an Excel with some datasets, outdated', pt: 'HÃ¡ um Excel com alguns datasets, desatualizado' }
      }
    ],
    requirements: {
      functional: [
        { es: 'Inventario automÃ¡tico de todos los datasets', en: 'Automatic inventory of all datasets', pt: 'InventÃ¡rio automÃ¡tico de todos os datasets' },
        { es: 'Search por nombre, descripciÃ³n, tags', en: 'Search by name, description, tags', pt: 'Search por nome, descriÃ§Ã£o, tags' },
        { es: 'Lineage: de dÃ³nde viene cada dato', en: 'Lineage: where each data comes from', pt: 'Lineage: de onde vem cada dado' }
      ],
      nonFunctional: [
        { es: 'Metadata actualizada automÃ¡ticamente', en: 'Metadata updated automatically', pt: 'Metadata atualizada automaticamente' },
        { es: 'SSO integration', en: 'SSO integration', pt: 'SSO integration' }
      ]
    },
    solution: [
      {
        step: 1,
        title: { es: 'Metadata Crawlers', en: 'Metadata Crawlers', pt: 'Metadata Crawlers' },
        description: { es: 'Crawlers que extraen schema, samples, stats de cada fuente. Programados diariamente.', en: 'Crawlers that extract schema, samples, stats from each source. Scheduled daily.', pt: 'Crawlers que extraem schema, samples, stats de cada fonte. Programados diariamente.' },
        components: ['Crawlers', 'Glue', 'Custom Connectors'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Data Catalog                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ Snowflake â”‚  â”‚    S3     â”‚  â”‚ PostgreSQLâ”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜               â”‚
â”‚        â”‚              â”‚              â”‚                       â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                       â–¼                                      â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚              â”‚   Crawlers     â”‚                              â”‚
â”‚              â”‚ (schema, stats)â”‚                              â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                       â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚              Metadata Store (PostgreSQL)                 â”‚â”‚
â”‚  â”‚  - Tables, columns, types                                â”‚â”‚
â”‚  â”‚  - Descriptions, tags, owners                            â”‚â”‚
â”‚  â”‚  - Lineage relationships                                 â”‚â”‚
â”‚  â”‚  - Access logs                                           â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                       â”‚                                      â”‚
â”‚                       â–¼                                      â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚              â”‚  Search UI     â”‚                              â”‚
â”‚              â”‚ (Elasticsearch)â”‚                              â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
      },
      {
        step: 2,
        title: { es: 'Search con Elasticsearch', en: 'Search with Elasticsearch', pt: 'Search com Elasticsearch' },
        description: { es: 'Index metadata en ES para bÃºsqueda full-text. Facets por owner, tags, source.', en: 'Index metadata in ES for full-text search. Facets by owner, tags, source.', pt: 'Index metadata no ES para busca full-text. Facets por owner, tags, source.' },
        components: ['Elasticsearch', 'Search API']
      },
      {
        step: 3,
        title: { es: 'PII Detection', en: 'PII Detection', pt: 'PII Detection' },
        description: { es: 'ML para detectar columnas con PII (emails, nombres, SSN). Taggear automÃ¡ticamente.', en: 'ML to detect columns with PII (emails, names, SSN). Auto-tag.', pt: 'ML para detectar colunas com PII (emails, nomes, CPF). Taggear automaticamente.' },
        components: ['AWS Macie', 'Custom ML', 'Auto-tagging']
      }
    ],
    tradeoffs: [
      {
        decision: { es: 'Build vs Buy (DataHub, Atlan, Collibra)', en: 'Build vs Buy (DataHub, Atlan, Collibra)', pt: 'Build vs Buy (DataHub, Atlan, Collibra)' },
        option1: { es: 'DataHub (open source): gratis, hay que operar', en: 'DataHub (open source): free, need to operate', pt: 'DataHub (open source): grÃ¡tis, precisa operar' },
        option2: { es: 'Atlan/Collibra: managed, $100k+/aÃ±o', en: 'Atlan/Collibra: managed, $100k+/year', pt: 'Atlan/Collibra: managed, $100k+/ano' },
        recommendation: { es: 'DataHub si tenÃ©s equipo de plataforma. Atlan si no.', en: 'DataHub if you have platform team. Atlan if not.', pt: 'DataHub se tem equipe de plataforma. Atlan se nÃ£o.' }
      }
    ],
    commonMistakes: [
      { es: 'âŒ No definir ownership - nadie mantiene las descripciones', en: 'âŒ Not defining ownership - nobody maintains descriptions', pt: 'âŒ NÃ£o definir ownership - ninguÃ©m mantÃ©m as descriÃ§Ãµes' },
      { es: 'âŒ Hacer todo manual - se desactualiza en semanas', en: 'âŒ Doing everything manual - gets outdated in weeks', pt: 'âŒ Fazer tudo manual - fica desatualizado em semanas' }
    ],
    interviewerTips: [
      { es: 'ğŸ’¡ MencionÃ¡ data contracts para mantener calidad', en: 'ğŸ’¡ Mention data contracts to maintain quality', pt: 'ğŸ’¡ Mencione data contracts para manter qualidade' },
      { es: 'ğŸ’¡ HablÃ¡ de cÃ³mo incentivar a los equipos a documentar', en: 'ğŸ’¡ Talk about how to incentivize teams to document', pt: 'ğŸ’¡ Fale de como incentivar os times a documentar' }
    ],
    relatedTopics: ['Data Catalog', 'Governance', 'DataHub', 'Metadata'],
    estimatedXP: 450
  },

  // ============ INTERVIEW 20: MULTI-TENANT ANALYTICS ============
  {
    id: 'sd-multitenant-analytics',
    title: {
      es: 'Analytics Multi-tenant SaaS',
      en: 'Multi-tenant SaaS Analytics',
      pt: 'Analytics Multi-tenant SaaS'
    },
    company: 'B2B SaaS',
    difficulty: 'senior',
    duration: '45 min',
    tags: ['Multi-tenant', 'SaaS', 'Isolation', 'Analytics'],
    problem: {
      es: `Sos DE en un SaaS B2B con 500 clientes (tenants).
Cada cliente quiere:
1. Dashboard con SUS mÃ©tricas (no ver datos de otros)
2. Exports de sus datos
3. Algunos clientes grandes quieren conectar su propio BI tool

Restricciones:
- Aislamiento total entre tenants (compliance)
- Algunos tenants tienen 100x mÃ¡s datos que otros
- No podemos cobrar mucho mÃ¡s a tenants pequeÃ±os

Â¿CÃ³mo diseÃ±arÃ­as la plataforma de analytics?`,
      en: `You're a DE at a B2B SaaS with 500 customers (tenants).
Each customer wants:
1. Dashboard with THEIR metrics (cant see others data)
2. Exports of their data
3. Some large clients want to connect their own BI tool

Constraints:
- Total isolation between tenants (compliance)
- Some tenants have 100x more data than others
- We cant charge much more to small tenants

How would you design the analytics platform?`,
      pt: `VocÃª Ã© DE em um SaaS B2B com 500 clientes (tenants).
Cada cliente quer:
1. Dashboard com SUAS mÃ©tricas (nÃ£o ver dados de outros)
2. Exports dos seus dados
3. Alguns clientes grandes querem conectar sua prÃ³pria ferramenta de BI

RestriÃ§Ãµes:
- Isolamento total entre tenants (compliance)
- Alguns tenants tÃªm 100x mais dados que outros
- NÃ£o podemos cobrar muito mais para tenants pequenos

Como vocÃª projetaria a plataforma de analytics?`
    },
    clarifyingQuestions: [
      {
        question: { es: 'Â¿QuÃ© porcentaje de clientes son enterprise vs SMB?', en: 'What percentage of customers are enterprise vs SMB?', pt: 'Que porcentagem de clientes sÃ£o enterprise vs SMB?' },
        whyAsk: { es: 'Define si necesitamos tiered architecture', en: 'Defines if we need tiered architecture', pt: 'Define se precisamos de arquitetura em tiers' },
        typicalAnswer: { es: '10% enterprise (80% del revenue), 90% SMB', en: '10% enterprise (80% of revenue), 90% SMB', pt: '10% enterprise (80% da receita), 90% SMB' }
      }
    ],
    requirements: {
      functional: [
        { es: 'Dashboards embebidos en el producto', en: 'Embedded dashboards in the product', pt: 'Dashboards embebidos no produto' },
        { es: 'Data export a CSV/Parquet', en: 'Data export to CSV/Parquet', pt: 'Data export para CSV/Parquet' },
        { es: 'ConexiÃ³n directa para clientes enterprise', en: 'Direct connection for enterprise clients', pt: 'ConexÃ£o direta para clientes enterprise' }
      ],
      nonFunctional: [
        { es: 'Aislamiento 100% entre tenants', en: '100% isolation between tenants', pt: '100% de isolamento entre tenants' },
        { es: 'Query time < 5s para 95% de queries', en: 'Query time < 5s for 95% of queries', pt: 'Query time < 5s para 95% das queries' }
      ]
    },
    solution: [
      {
        step: 1,
        title: { es: 'Pool model con row-level security', en: 'Pool model with row-level security', pt: 'Pool model com row-level security' },
        description: { es: 'Un DW compartido con tenant_id en cada tabla. Row-level security en Snowflake/BigQuery.', en: 'Shared DW with tenant_id in each table. Row-level security in Snowflake/BigQuery.', pt: 'DW compartilhado com tenant_id em cada tabela. Row-level security no Snowflake/BigQuery.' },
        components: ['Snowflake', 'Row-Level Security', 'tenant_id'],
        diagram: `
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Multi-tenant Analytics                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                Shared Data Warehouse                   â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚ Table: events                                    â”‚  â”‚  â”‚
â”‚  â”‚  â”‚ - tenant_id (partition key)                     â”‚  â”‚  â”‚
â”‚  â”‚  â”‚ - event_type, timestamp, data...                â”‚  â”‚  â”‚
â”‚  â”‚  â”‚ [Row-Level Security: WHERE tenant_id = @user]   â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â”‚                                   â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚         â–¼                â–¼                â–¼                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  SMB Tier   â”‚  â”‚  Pro Tier   â”‚  â”‚ Enterprise  â”‚         â”‚
â”‚  â”‚ (embedded)  â”‚  â”‚ (embedded+  â”‚  â”‚ (dedicated  â”‚         â”‚
â”‚  â”‚             â”‚  â”‚  export)    â”‚  â”‚  schema)    â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
      },
      {
        step: 2,
        title: { es: 'Tiered architecture', en: 'Tiered architecture', pt: 'Arquitetura em tiers' },
        description: { es: 'SMB: pool compartido. Enterprise: schema dedicado o incluso DW separado para cumplir SLAs.', en: 'SMB: shared pool. Enterprise: dedicated schema or even separate DW to meet SLAs.', pt: 'SMB: pool compartilhado. Enterprise: schema dedicado ou atÃ© DW separado para cumprir SLAs.' },
        components: ['Tiering', 'Schema per tenant', 'Resource governors']
      },
      {
        step: 3,
        title: { es: 'Embedded BI', en: 'Embedded BI', pt: 'BI Embebido' },
        description: { es: 'Metabase/Preset/Looker embebido con filtro de tenant automÃ¡tico. API para custom dashboards.', en: 'Metabase/Preset/Looker embedded with automatic tenant filter. API for custom dashboards.', pt: 'Metabase/Preset/Looker embebido com filtro de tenant automÃ¡tico. API para dashboards custom.' },
        components: ['Metabase', 'Looker', 'Embedded Analytics']
      }
    ],
    tradeoffs: [
      {
        decision: { es: 'Pool (shared) vs Silo (dedicated)', en: 'Pool (shared) vs Silo (dedicated)', pt: 'Pool (shared) vs Silo (dedicated)' },
        option1: { es: 'Pool: mÃ¡s eficiente en costos, riesgo de noisy neighbor', en: 'Pool: more cost efficient, noisy neighbor risk', pt: 'Pool: mais eficiente em custos, risco de noisy neighbor' },
        option2: { es: 'Silo: aislamiento perfecto, caro de operar', en: 'Silo: perfect isolation, expensive to operate', pt: 'Silo: isolamento perfeito, caro de operar' },
        recommendation: { es: 'Pool para SMB, Silo para enterprise con SLAs estrictos.', en: 'Pool for SMB, Silo for enterprise with strict SLAs.', pt: 'Pool para SMB, Silo para enterprise com SLAs estritos.' }
      }
    ],
    commonMistakes: [
      { es: 'âŒ No poner tenant_id en todas las tablas - queries filtran mal', en: 'âŒ Not putting tenant_id in all tables - queries filter incorrectly', pt: 'âŒ NÃ£o colocar tenant_id em todas as tabelas - queries filtram errado' },
      { es: 'âŒ No usar resource governors - un tenant grande afecta a todos', en: 'âŒ Not using resource governors - one large tenant affects all', pt: 'âŒ NÃ£o usar resource governors - um tenant grande afeta todos' }
    ],
    interviewerTips: [
      { es: 'ğŸ’¡ MencionÃ¡ query queues separadas por tier', en: 'ğŸ’¡ Mention separate query queues by tier', pt: 'ğŸ’¡ Mencione query queues separadas por tier' },
      { es: 'ğŸ’¡ HablÃ¡ de cÃ³mo manejar tenant offboarding (delete data)', en: 'ğŸ’¡ Talk about handling tenant offboarding (delete data)', pt: 'ğŸ’¡ Fale de como lidar com tenant offboarding (delete data)' }
    ],
    relatedTopics: ['Multi-tenant', 'SaaS', 'Snowflake', 'Row-Level Security'],
    estimatedXP: 450
  }
];

// Helper functions
export const getSystemDesignById = (id: string): SystemDesignInterview | undefined => {
  return SYSTEM_DESIGN_INTERVIEWS.find(sd => sd.id === id);
};

export const getSystemDesignsByDifficulty = (difficulty: 'junior' | 'mid' | 'senior'): SystemDesignInterview[] => {
  return SYSTEM_DESIGN_INTERVIEWS.filter(sd => sd.difficulty === difficulty);
};

export const getSystemDesignsByTag = (tag: string): SystemDesignInterview[] => {
  return SYSTEM_DESIGN_INTERVIEWS.filter(sd => sd.tags.includes(tag));
};

export const SYSTEM_DESIGN_STATS = {
  total: SYSTEM_DESIGN_INTERVIEWS.length,
  byDifficulty: {
    junior: SYSTEM_DESIGN_INTERVIEWS.filter(sd => sd.difficulty === 'junior').length,
    mid: SYSTEM_DESIGN_INTERVIEWS.filter(sd => sd.difficulty === 'mid').length,
    senior: SYSTEM_DESIGN_INTERVIEWS.filter(sd => sd.difficulty === 'senior').length,
  },
  totalXP: SYSTEM_DESIGN_INTERVIEWS.reduce((sum, sd) => sum + sd.estimatedXP, 0),
};

