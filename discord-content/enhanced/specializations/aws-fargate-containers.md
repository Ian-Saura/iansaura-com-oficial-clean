---
id: "spec-aws-fargate-containers"
version: "1.0.0"
lastUpdated: "2026-02-08"

title:
  es: "ECS Fargate para Data Engineering: Contenedores sin Servidores"
  en: "ECS Fargate for Data Engineering: Serverless Containers"
  pt: "ECS Fargate para Data Engineering: ContÃªineres sem Servidores"

subtitle:
  es: "Procesamiento pesado de datos con contenedores Docker gestionados por AWS"
  en: "Heavy data processing with Docker containers managed by AWS"
  pt: "Processamento pesado de dados com contÃªineres Docker gerenciados pela AWS"

level: "specialization"
phase: "spec-aws-fargate"
estimatedTime: "25-35 horas"

prerequisites:
  - "spec-aws-lambda-serverless"
  - "spec-aws-data-stack"

tags:
  - "aws"
  - "fargate"
  - "ecs"
  - "docker"
  - "containers"
  - "data-engineering"

theoreticalFoundations:
  - "Container orchestration"
  - "Docker fundamentals"
  - "Distributed data processing"
  - "Cost optimization"
---

<!-- 
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ“š BLOQUE: ECS FARGATE PARA DATA ENGINEERING              â•‘
â•‘  EspecializaciÃ³n: AWS Data Engineering                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-->

# ğŸ³ ECS Fargate para Data Engineering: Contenedores sin Servidores

> **Objetivo**: Dominar ECS Fargate para procesar cargas de datos que superan los lÃ­mites de Lambda. Docker, ECR, Task Definitions, orquestaciÃ³n con Step Functions y optimizaciÃ³n de costos.

---

## 1. Â¿CuÃ¡ndo Lambda No Alcanza?

### Ãrbol de DecisiÃ³n

```
                    Â¿Necesitas procesamiento de datos?
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                    â”‚
              Archivo < 5 GB       Archivo > 5 GB
              Tiempo < 10 min      Tiempo > 15 min
              Memoria < 10 GB      Memoria > 10 GB
                    â”‚                    â”‚
                    â–¼                    â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  LAMBDA  â”‚        â”‚   FARGATE    â”‚
              â”‚  âš¡ $0.00 â”‚        â”‚   ğŸ³ $0.04+  â”‚
              â”‚  cuando   â”‚        â”‚   por hora   â”‚
              â”‚  idle     â”‚        â”‚   de uso     â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### SeÃ±ales de que necesitas Fargate

| SeÃ±al | Ejemplo Real |
|-------|-------------|
| **Timeout > 15 min** | TransformaciÃ³n de 50M filas con joins complejos |
| **RAM > 10 GB** | Cargar dataset completo en memoria para deduplicaciÃ³n |
| **Archivo > 10 GB** | Archivos Parquet/CSV de data warehouse export |
| **Dependencias pesadas** | Spark local, modelos ML, librerÃ­as de C++ |
| **GPU necesaria** | Procesamiento de imÃ¡genes o NLP batch |
| **Long-running service** | Consumidor Kafka que corre 24/7 |

> **Regla de oro**: Lambda es para **eventos** (archivo llega â†’ procesar). Fargate es para **tareas** (procesar batch de 2 horas cada noche).

---

## 2. Docker para Data Engineers

### Dockerfile para ETL (Multi-Stage Build)

```dockerfile
# ============================================
# STAGE 1: Builder - Instalar dependencias
# ============================================
FROM python:3.12-slim AS builder

WORKDIR /build

# Instalar dependencias de compilaciÃ³n
RUN apt-get update && apt-get install -y --no-install-recommends \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# Copiar solo requirements primero (cache de Docker)
COPY requirements.txt .
RUN pip install --no-cache-dir --prefix=/install -r requirements.txt

# ============================================
# STAGE 2: Runtime - Imagen final ligera
# ============================================
FROM python:3.12-slim AS runtime

WORKDIR /app

# Copiar dependencias instaladas del builder
COPY --from=builder /install /usr/local

# Copiar cÃ³digo de la aplicaciÃ³n
COPY src/ ./src/
COPY config/ ./config/

# Variables de entorno
ENV PYTHONUNBUFFERED=1
ENV AWS_DEFAULT_REGION=us-east-1

# Healthcheck (opcional para services)
HEALTHCHECK --interval=30s --timeout=5s --retries=3 \
    CMD python -c "print('healthy')" || exit 1

# Ejecutar el ETL
ENTRYPOINT ["python", "-m", "src.etl_main"]
```

### requirements.txt tÃ­pico

```
pandas==2.2.0
pyarrow==15.0.0
boto3==1.34.0
psycopg2-binary==2.9.9
sqlalchemy==2.0.25
python-dotenv==1.0.0
```

### Estructura del Proyecto

```
data-etl-fargate/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ etl_main.py          # Punto de entrada
â”‚   â”œâ”€â”€ extractors/
â”‚   â”‚   â”œâ”€â”€ s3_extractor.py
â”‚   â”‚   â””â”€â”€ api_extractor.py
â”‚   â”œâ”€â”€ transformers/
â”‚   â”‚   â”œâ”€â”€ cleaner.py
â”‚   â”‚   â””â”€â”€ enricher.py
â”‚   â””â”€â”€ loaders/
â”‚       â”œâ”€â”€ s3_loader.py
â”‚       â””â”€â”€ redshift_loader.py
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_etl.py
â””â”€â”€ .dockerignore
```

### .dockerignore (Importante para imÃ¡genes ligeras)

```
.git
.gitignore
__pycache__
*.pyc
.env
.venv
tests/
*.md
.DS_Store
```

---

## 3. ECR: Tu Registro Privado

### Crear Repositorio y Subir Imagen

```bash
# 1. Crear repositorio en ECR
aws ecr create-repository \
  --repository-name data-etl-pipeline \
  --image-scanning-configuration scanOnPush=true \
  --encryption-configuration encryptionType=AES256

# 2. Autenticarse con ECR
aws ecr get-login-password --region us-east-1 | \
  docker login --username AWS --password-stdin \
  123456789012.dkr.ecr.us-east-1.amazonaws.com

# 3. Construir imagen
docker build -t data-etl-pipeline:latest .

# 4. Etiquetar con URI del ECR
docker tag data-etl-pipeline:latest \
  123456789012.dkr.ecr.us-east-1.amazonaws.com/data-etl-pipeline:latest

# 5. Subir (push)
docker push \
  123456789012.dkr.ecr.us-east-1.amazonaws.com/data-etl-pipeline:latest
```

### Lifecycle Policy (Limpiar imÃ¡genes antiguas)

```json
{
  "rules": [
    {
      "rulePriority": 1,
      "description": "Mantener solo las Ãºltimas 10 imÃ¡genes",
      "selection": {
        "tagStatus": "any",
        "countType": "imageCountMoreThan",
        "countNumber": 10
      },
      "action": {
        "type": "expire"
      }
    }
  ]
}
```

```bash
# Aplicar lifecycle policy
aws ecr put-lifecycle-policy \
  --repository-name data-etl-pipeline \
  --lifecycle-policy-text file://lifecycle-policy.json
```

---

## 4. ECS/Fargate Concepts

### JerarquÃ­a de Componentes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ECS CLUSTER                       â”‚
â”‚  "data-processing-cluster"                          â”‚
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚             TASK DEFINITION                     â”‚ â”‚
â”‚  â”‚  "etl-ventas-task:3"  (versiÃ³n 3)              â”‚ â”‚
â”‚  â”‚                                                 â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚ â”‚
â”‚  â”‚  â”‚ Container 1  â”‚  â”‚ Container 2  â”‚            â”‚ â”‚
â”‚  â”‚  â”‚ etl-worker   â”‚  â”‚ datadog-agentâ”‚  (sidecar) â”‚ â”‚
â”‚  â”‚  â”‚ 2 vCPU       â”‚  â”‚ 0.25 vCPU    â”‚            â”‚ â”‚
â”‚  â”‚  â”‚ 8 GB RAM     â”‚  â”‚ 512 MB RAM   â”‚            â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚   TASK 1     â”‚  â”‚   TASK 2     â”‚  (instancias  â”‚
â”‚  â”‚  (running)   â”‚  â”‚  (running)   â”‚   del task    â”‚
â”‚  â”‚  archivo_a   â”‚  â”‚  archivo_b   â”‚   definition) â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              SERVICE (opcional)                 â”‚ â”‚
â”‚  â”‚  "kafka-consumer-service"                      â”‚ â”‚
â”‚  â”‚  desiredCount: 3  â† mantiene 3 tasks corriendo â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Conceptos Clave

| Concepto | AnalogÃ­a | En Data Engineering |
|----------|----------|---------------------|
| **Cluster** | El "edificio" | AgrupaciÃ³n lÃ³gica de tareas |
| **Task Definition** | El "plano del departamento" | ConfiguraciÃ³n: imagen, CPU, RAM, env vars |
| **Task** | El "departamento construido" | Instancia en ejecuciÃ³n del task definition |
| **Service** | El "contrato de mantenimiento" | Mantiene N tasks corriendo (long-running) |
| **Container** | La "habitaciÃ³n" | Un proceso dentro del task |

> **Para ETL batch**: Usas **Tasks** (se ejecutan y terminan). Para consumidores Kafka: usas **Services** (corren siempre).

---

## 5. Task Definition para ETL

### Ejemplo Completo (JSON)

```json
{
  "family": "etl-ventas-diarias",
  "networkMode": "awsvpc",
  "requiresCompatibilities": ["FARGATE"],
  "cpu": "2048",
  "memory": "8192",
  "executionRoleArn": "arn:aws:iam::123456789012:role/ecsTaskExecutionRole",
  "taskRoleArn": "arn:aws:iam::123456789012:role/etl-task-role",
  "containerDefinitions": [
    {
      "name": "etl-worker",
      "image": "123456789012.dkr.ecr.us-east-1.amazonaws.com/data-etl-pipeline:latest",
      "essential": true,
      "cpu": 1792,
      "memory": 7680,
      "environment": [
        {"name": "ENV", "value": "production"},
        {"name": "S3_RAW_BUCKET", "value": "raw-data-lake"},
        {"name": "S3_CLEAN_BUCKET", "value": "clean-data-lake"},
        {"name": "REDSHIFT_SECRET_ARN", "value": "arn:aws:secretsmanager:us-east-1:123456789012:secret:prod/redshift"}
      ],
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
          "awslogs-group": "/ecs/etl-ventas",
          "awslogs-region": "us-east-1",
          "awslogs-stream-prefix": "etl"
        }
      },
      "healthCheck": {
        "command": ["CMD-SHELL", "python -c 'print(\"ok\")' || exit 1"],
        "interval": 30,
        "timeout": 5,
        "retries": 3
      }
    },
    {
      "name": "datadog-agent",
      "image": "datadog/agent:latest",
      "essential": false,
      "cpu": 256,
      "memory": 512,
      "environment": [
        {"name": "DD_API_KEY", "value": "your-datadog-key"},
        {"name": "ECS_FARGATE", "value": "true"}
      ]
    }
  ],
  "ephemeralStorage": {
    "sizeInGiB": 100
  }
}
```

### Configuraciones de CPU y Memoria VÃ¡lidas

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CPU (vCPU)  â”‚  Memoria (GB) disponible          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  0.25        â”‚  0.5, 1, 2                        â”‚
â”‚  0.5         â”‚  1, 2, 3, 4                       â”‚
â”‚  1           â”‚  2, 3, 4, 5, 6, 7, 8              â”‚
â”‚  2           â”‚  4 - 16 (incrementos de 1 GB)      â”‚
â”‚  4           â”‚  8 - 30 (incrementos de 1 GB)      â”‚
â”‚  8           â”‚  16 - 60 (incrementos de 4 GB)     â”‚
â”‚  16          â”‚  32 - 120 (incrementos de 8 GB)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Roles IAM Necesarios

```
Execution Role (ecsTaskExecutionRole):
  â”œâ”€â”€ Permisos para ECS
  â”‚   â”œâ”€â”€ ecr:GetAuthorizationToken
  â”‚   â”œâ”€â”€ ecr:BatchGetImage
  â”‚   â””â”€â”€ logs:PutLogEvents
  â””â”€â”€ Permisos para secretos
      â””â”€â”€ secretsmanager:GetSecretValue

Task Role (etl-task-role):
  â”œâ”€â”€ S3
  â”‚   â”œâ”€â”€ s3:GetObject      (leer raw)
  â”‚   â”œâ”€â”€ s3:PutObject      (escribir processed)
  â”‚   â””â”€â”€ s3:ListBucket
  â”œâ”€â”€ Redshift
  â”‚   â””â”€â”€ redshift-data:ExecuteStatement
  â””â”€â”€ Glue Catalog
      â”œâ”€â”€ glue:GetTable
      â””â”€â”€ glue:UpdateTable
```

---

## 6. Lanzar y Monitorear Tareas

### Ejecutar Task con boto3

```python
import boto3
import time
import logging

logger = logging.getLogger(__name__)
ecs_client = boto3.client('ecs')


def run_etl_task(
    cluster: str = 'data-processing-cluster',
    task_definition: str = 'etl-ventas-diarias',
    subnet_ids: list = None,
    security_group_ids: list = None,
    overrides: dict = None
) -> str:
    """
    Lanzar una tarea Fargate para procesamiento ETL.

    Returns:
        task_arn: ARN de la tarea lanzada.
    """
    network_config = {
        'awsvpcConfiguration': {
            'subnets': subnet_ids or ['subnet-abc123', 'subnet-def456'],
            'securityGroups': security_group_ids or ['sg-etl-tasks'],
            'assignPublicIp': 'DISABLED'  # Usar NAT Gateway o VPC Endpoints
        }
    }

    # Overrides permiten cambiar env vars sin nueva Task Definition
    container_overrides = overrides or {
        'containerOverrides': [{
            'name': 'etl-worker',
            'environment': [
                {'name': 'INPUT_FILE', 'value': 's3://raw/ventas_2026_02.csv'},
                {'name': 'BATCH_DATE', 'value': '2026-02-08'}
            ]
        }]
    }

    response = ecs_client.run_task(
        cluster=cluster,
        taskDefinition=task_definition,
        launchType='FARGATE',
        count=1,
        networkConfiguration=network_config,
        overrides=container_overrides,
        platformVersion='LATEST'
    )

    task_arn = response['tasks'][0]['taskArn']
    logger.info(f"Task lanzada: {task_arn}")
    return task_arn


def wait_for_task(cluster: str, task_arn: str, timeout_minutes: int = 60) -> str:
    """
    Esperar a que la tarea termine y retornar el exit code.
    """
    waiter = ecs_client.get_waiter('tasks_stopped')

    logger.info(f"Esperando tarea (timeout: {timeout_minutes} min)...")
    waiter.wait(
        cluster=cluster,
        tasks=[task_arn],
        WaiterConfig={
            'Delay': 30,       # Verificar cada 30 segundos
            'MaxAttempts': timeout_minutes * 2  # 30s * 2 = 1 min
        }
    )

    # Obtener resultado
    response = ecs_client.describe_tasks(cluster=cluster, tasks=[task_arn])
    task = response['tasks'][0]

    container = task['containers'][0]
    exit_code = container.get('exitCode', -1)
    reason = container.get('reason', 'N/A')

    if exit_code == 0:
        logger.info(f"Task completada exitosamente: {task_arn}")
    else:
        logger.error(f"Task fallÃ³ (exit code {exit_code}): {reason}")

    return exit_code


# Uso
if __name__ == '__main__':
    task_arn = run_etl_task()
    exit_code = wait_for_task('data-processing-cluster', task_arn)
    if exit_code != 0:
        raise RuntimeError(f"ETL task fallÃ³ con exit code {exit_code}")
```

---

## 7. Procesamiento de Archivos Pesados (+10 GB)

### Lectura por Chunks (Streaming)

```python
import boto3
import pandas as pd
import pyarrow as pa
import pyarrow.parquet as pq
from io import BytesIO
import logging

logger = logging.getLogger(__name__)
s3_client = boto3.client('s3')

CHUNK_SIZE = 500_000  # filas por chunk


def process_large_csv(
    source_bucket: str,
    source_key: str,
    dest_bucket: str,
    dest_prefix: str
):
    """
    Procesar CSV de +10 GB leyendo por chunks.

    Cada chunk se transforma y escribe como un archivo Parquet separado.
    Ideal para archivos que no caben en memoria.
    """
    # Descargar archivo a almacenamiento efÃ­mero (/tmp en Fargate)
    local_path = f'/tmp/{source_key.split("/")[-1]}'
    logger.info(f"Descargando s3://{source_bucket}/{source_key} a {local_path}...")

    s3_client.download_file(source_bucket, source_key, local_path)
    logger.info("Descarga completada.")

    # Procesar por chunks
    chunk_number = 0
    total_rows = 0

    for chunk_df in pd.read_csv(local_path, chunksize=CHUNK_SIZE):
        chunk_number += 1
        rows_in_chunk = len(chunk_df)
        total_rows += rows_in_chunk

        logger.info(f"Chunk {chunk_number}: {rows_in_chunk} filas (total: {total_rows})")

        # Transformar
        chunk_df = transform_chunk(chunk_df)

        # Escribir chunk como Parquet a S3
        output_key = f"{dest_prefix}/part-{chunk_number:05d}.parquet"
        write_parquet(chunk_df, dest_bucket, output_key)

    logger.info(f"Proceso completado: {total_rows} filas en {chunk_number} chunks")
    return {'total_rows': total_rows, 'chunks': chunk_number}


def transform_chunk(df: pd.DataFrame) -> pd.DataFrame:
    """Transformaciones aplicadas a cada chunk."""
    # Normalizar columnas
    df.columns = [c.strip().lower().replace(' ', '_') for c in df.columns]

    # Tipos de dato
    for col in df.select_dtypes(include=['object']).columns:
        if 'fecha' in col or 'date' in col:
            df[col] = pd.to_datetime(df[col], errors='coerce')

    # Eliminar nulos completos
    df = df.dropna(how='all')

    return df


def write_parquet(df: pd.DataFrame, bucket: str, key: str):
    """Escribir DataFrame como Parquet a S3."""
    buffer = BytesIO()
    table = pa.Table.from_pandas(df)
    pq.write_table(table, buffer, compression='snappy')
    buffer.seek(0)

    s3_client.put_object(Bucket=bucket, Key=key, Body=buffer.getvalue())
    logger.info(f"Escrito: s3://{bucket}/{key}")
```

### Uso de Almacenamiento EfÃ­mero en Fargate

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Fargate Task                        â”‚
â”‚                                               â”‚
â”‚   /tmp (ephemeral storage)                    â”‚
â”‚   â”œâ”€â”€ MÃ­nimo: 20 GB (gratis)                 â”‚
â”‚   â”œâ”€â”€ MÃ¡ximo: 200 GB (costo adicional)        â”‚
â”‚   â””â”€â”€ Se pierde al terminar la tarea          â”‚
â”‚                                               â”‚
â”‚   Estrategia:                                 â”‚
â”‚   1. Descargar archivo grande a /tmp          â”‚
â”‚   2. Procesar por chunks desde disco          â”‚
â”‚   3. Escribir resultados a S3                 â”‚
â”‚   4. Limpiar /tmp (opcional, se borra solo)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 8. OrquestaciÃ³n con Step Functions

### Â¿Por quÃ© Step Functions?

Lambda y Fargate son **compute**. Step Functions es el **orquestador** que coordina mÃºltiples pasos, maneja errores, y reintentos.

### Ejemplo: Pipeline de Ventas Diarias

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Lambda:     â”‚â”€â”€â”€â”€â–ºâ”‚  Fargate:    â”‚â”€â”€â”€â”€â–ºâ”‚  Lambda:     â”‚
â”‚  Validar     â”‚     â”‚  Transformar â”‚     â”‚  Notificar   â”‚
â”‚  archivo     â”‚     â”‚  (30 min)    â”‚     â”‚  resultado   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                    â”‚
       â–¼ (error)            â–¼ (error)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SNS: Alerta â”‚     â”‚  SNS: Alerta â”‚
â”‚  + DLQ       â”‚     â”‚  + Retry     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Amazon States Language (ASL) - DefiniciÃ³n

```json
{
  "Comment": "Pipeline ETL: Validar â†’ Transformar â†’ Notificar",
  "StartAt": "ValidateInput",
  "States": {
    "ValidateInput": {
      "Type": "Task",
      "Resource": "arn:aws:lambda:us-east-1:123456789012:function:validate-input",
      "InputPath": "$.detail",
      "ResultPath": "$.validation",
      "Next": "IsValid",
      "Catch": [{
        "ErrorEquals": ["States.ALL"],
        "Next": "NotifyFailure"
      }]
    },

    "IsValid": {
      "Type": "Choice",
      "Choices": [
        {
          "Variable": "$.validation.valid",
          "BooleanEquals": true,
          "Next": "TransformData"
        }
      ],
      "Default": "NotifyInvalidData"
    },

    "TransformData": {
      "Type": "Task",
      "Resource": "arn:aws:states:::ecs:runTask.sync",
      "Parameters": {
        "Cluster": "arn:aws:ecs:us-east-1:123456789012:cluster/data-processing",
        "TaskDefinition": "arn:aws:ecs:us-east-1:123456789012:task-definition/etl-ventas:3",
        "LaunchType": "FARGATE",
        "NetworkConfiguration": {
          "AwsvpcConfiguration": {
            "Subnets": ["subnet-abc123"],
            "SecurityGroups": ["sg-etl"],
            "AssignPublicIp": "DISABLED"
          }
        },
        "Overrides": {
          "ContainerOverrides": [{
            "Name": "etl-worker",
            "Environment": [
              {"Name": "INPUT_FILE", "Value.$": "$.detail.s3Key"},
              {"Name": "BATCH_DATE", "Value.$": "$.detail.batchDate"}
            ]
          }]
        }
      },
      "TimeoutSeconds": 3600,
      "Retry": [{
        "ErrorEquals": ["States.TaskFailed"],
        "IntervalSeconds": 60,
        "MaxAttempts": 2,
        "BackoffRate": 2.0
      }],
      "Catch": [{
        "ErrorEquals": ["States.ALL"],
        "Next": "NotifyFailure"
      }],
      "Next": "NotifySuccess"
    },

    "NotifySuccess": {
      "Type": "Task",
      "Resource": "arn:aws:states:::sns:publish",
      "Parameters": {
        "TopicArn": "arn:aws:sns:us-east-1:123456789012:etl-success",
        "Message.$": "States.Format('ETL completado para {}', $.detail.batchDate)"
      },
      "End": true
    },

    "NotifyInvalidData": {
      "Type": "Task",
      "Resource": "arn:aws:states:::sns:publish",
      "Parameters": {
        "TopicArn": "arn:aws:sns:us-east-1:123456789012:etl-alerts",
        "Message": "Datos de entrada invÃ¡lidos - verificar formato"
      },
      "End": true
    },

    "NotifyFailure": {
      "Type": "Task",
      "Resource": "arn:aws:states:::sns:publish",
      "Parameters": {
        "TopicArn": "arn:aws:sns:us-east-1:123456789012:etl-alerts",
        "Message.$": "States.Format('ETL FALLIDO: {}', $.Error)"
      },
      "End": true
    }
  }
}
```

> **`.sync`**: El sufijo `.sync` en `ecs:runTask.sync` hace que Step Functions **espere** a que la tarea Fargate termine antes de continuar. Sin `.sync`, Step Functions solo lanza la tarea y pasa al siguiente estado.

---

## 9. Costos y OptimizaciÃ³n

### Modelo de Precios Fargate (us-east-1, 2026)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Recurso        â”‚ Precio/hora    â”‚ Precio/segundoâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1 vCPU         â”‚  ~$0.04048     â”‚  $0.000011    â”‚
â”‚  1 GB RAM       â”‚  ~$0.004445    â”‚  $0.0000012   â”‚
â”‚  20 GB storage  â”‚  Incluido      â”‚  Incluido     â”‚
â”‚  Storage extra  â”‚  ~$0.000111/GB â”‚  por segundo  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ejemplo: Task con 2 vCPU + 8 GB RAM corriendo 30 minutos:
  CPU:  2 Ã— $0.04048 Ã— 0.5h  = $0.04048
  RAM:  8 Ã— $0.004445 Ã— 0.5h = $0.01778
  TOTAL: ~$0.058 por ejecuciÃ³n
```

### Fargate Spot (Ahorro del 70%)

```python
# Lanzar task con Fargate Spot
response = ecs_client.run_task(
    cluster='data-processing',
    taskDefinition='etl-ventas-diarias',
    launchType='FARGATE',
    count=1,
    networkConfiguration=network_config,
    capacityProviderStrategy=[
        {
            'capacityProvider': 'FARGATE_SPOT',
            'weight': 1,
            'base': 0
        }
    ]
)
```

> **Fargate Spot**: Hasta 70% mÃ¡s barato. AWS puede interrumpir la tarea con 2 minutos de aviso. Ideal para ETL que puede re-ejecutarse (idempotente).

### Right-Sizing: Optimizar CPU y Memoria

```python
# Monitorear uso real para right-sizing
import psutil

def log_resource_usage():
    """Llamar periÃ³dicamente durante el ETL."""
    cpu_percent = psutil.cpu_percent(interval=1)
    memory = psutil.virtual_memory()

    logger.info(
        f"Recursos: CPU={cpu_percent}%, "
        f"RAM={memory.used / (1024**3):.1f}GB / {memory.total / (1024**3):.1f}GB "
        f"({memory.percent}%)"
    )

# Si observas: CPU=20%, RAM=30% â†’ estÃ¡s sobre-provisionando
# Reducir CPU y RAM en la Task Definition para ahorrar
```

### ComparaciÃ³n de Costos Mensual

```
Escenario: Procesar 100 archivos/dÃ­a, 30 min cada uno

Lambda (1 GB RAM):
  100 Ã— 30min Ã— 60s Ã— $0.0000166667/GB-s = $3.00/dÃ­a
  Mensual: ~$90

Fargate (2 vCPU, 8 GB):
  100 Ã— 0.5h Ã— ($0.08096 + $0.03556) = $5.83/dÃ­a
  Mensual: ~$175

Fargate Spot (2 vCPU, 8 GB):
  100 Ã— 0.5h Ã— $0.035 â‰ˆ $1.75/dÃ­a
  Mensual: ~$52

âš ï¸  Lambda gana en archivos pequeÃ±os/rÃ¡pidos.
    Fargate Spot gana en tareas largas y pesadas.
```

---

## 10. Lambda vs Fargate vs Glue vs EMR

### Tabla de ComparaciÃ³n Completa

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              â”‚   Lambda     â”‚   Fargate    â”‚   Glue       â”‚    EMR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Caso de uso  â”‚ Ingesta      â”‚ ETL pesado   â”‚ ETL Spark    â”‚ Big Data     â”‚
â”‚              â”‚ event-driven â”‚ batch        â”‚ managed      â”‚ Spark/Hadoop â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Max runtime  â”‚ 15 min       â”‚ Sin lÃ­mite   â”‚ Sin lÃ­mite   â”‚ Sin lÃ­mite   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Max memoria  â”‚ 10 GB        â”‚ 120 GB       â”‚ Auto-scaled  â”‚ TB+          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Escalabilidadâ”‚ Auto (1000+  â”‚ Manual/Auto  â”‚ Auto (DPUs)  â”‚ Auto/Manual  â”‚
â”‚              â”‚ concurrent)  â”‚ (tasks)      â”‚              â”‚ (nodes)      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Costo idle   â”‚ $0           â”‚ $0           â”‚ $0           â”‚ $0 (si off)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Setup        â”‚ MÃ­nimo       â”‚ Medio        â”‚ Medio        â”‚ Alto         â”‚
â”‚              â”‚ (cÃ³digo)     â”‚ (Docker+ECS) â”‚ (Spark/ETL)  â”‚ (cluster)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ CuÃ¡ndo usar  â”‚ < 10 GB      â”‚ 10-100 GB    â”‚ 10 GB - 1 TB â”‚ > 1 TB      â”‚
â”‚              â”‚ < 15 min     â”‚ cualquier    â”‚ Spark ETL    â”‚ Spark/Hive   â”‚
â”‚              â”‚ event-driven â”‚ duraciÃ³n     â”‚              â”‚ ML a escala  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precio aprox â”‚ ~$0.05/hr    â”‚ ~$0.05-0.15  â”‚ ~$0.44/DPU   â”‚ ~$0.10+/hr   â”‚
â”‚ (mÃ­nimo)     â”‚ (1 GB)       â”‚ /hr          â”‚ /hr          â”‚ por nodo     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### PatrÃ³n HÃ­brido Recomendado

```
                        Archivos llegan a S3
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Lambda: Clasificar â”‚
                    â”‚  tamaÃ±o y tipo      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              < 5 GB â”‚                   â”‚ > 5 GB
                    â”‚                    â”‚
                    â–¼                    â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚  Lambda  â”‚        â”‚   Fargate    â”‚
             â”‚  ETL     â”‚        â”‚   ETL        â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   S3 (Parquet)   â”‚
                    â”‚   + Glue Catalog â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 11. Preguntas de Entrevista

### Pregunta 1: DiseÃ±o de Pipeline HÃ­brido
**P**: Recibes 10,000 archivos al dÃ­a: 9,500 son < 1 MB y 500 son > 1 GB. Â¿CÃ³mo diseÃ±as el pipeline?

**R**: Pipeline hÃ­brido con clasificaciÃ³n inteligente:
1. **S3 trigger â†’ Lambda clasificadora** que evalÃºa el tamaÃ±o del objeto.
2. Archivos < 100 MB â†’ **Lambda ETL** directamente (bajo costo, rÃ¡pido).
3. Archivos > 100 MB â†’ Enviar mensaje a **SQS** que trigger **Fargate task**.
4. Fargate con **Spot** para los archivos grandes (ahorro 70%).
5. Ambos escriben a **S3 (Parquet)** con registro en **Glue Catalog**.
6. **Step Functions** como orquestador para retry y monitoreo.
7. **CloudWatch Alarms** para error rate y duraciÃ³n anÃ³mala.

---

### Pregunta 2: Fargate vs Lambda para Kafka Consumer
**P**: Necesitas consumir mensajes de MSK (Kafka) 24/7. Â¿Lambda o Fargate?

**R**: Depende del patrÃ³n de consumo:
- **Lambda con MSK trigger**: AWS gestiona el consumer group. Ideal si el procesamiento por batch es < 15 min y no necesitas estado entre invocaciones. Escala automÃ¡ticamente con particiones.
- **Fargate Service**: Para consumidores stateful, procesamiento complejo, o cuando necesitas control total del offset management. Corre 24/7 con un Service ECS (desiredCount = nÃºmero de particiones).
- **RecomendaciÃ³n**: Empezar con Lambda MSK trigger (mÃ¡s simple). Migrar a Fargate solo si necesitas mÃ¡s control o el procesamiento excede 15 min por batch.

---

### Pregunta 3: OptimizaciÃ³n de Costos
**P**: Tu pipeline Fargate cuesta $2,000/mes. Â¿CÃ³mo lo optimizas?

**R**: Estrategia de optimizaciÃ³n en capas:
1. **Right-sizing**: Monitorear CPU y RAM real con CloudWatch Container Insights. Reducir si el uso es < 50%.
2. **Fargate Spot**: Para tareas idempotentes (re-ejecutables), ahorro de hasta 70%.
3. **Reducir duraciÃ³n**: Optimizar cÃ³digo (lectura por chunks, procesamiento paralelo con multiprocessing).
4. **Arquitectura**: Â¿Los archivos pequeÃ±os realmente necesitan Fargate? Mover a Lambda si < 5 GB.
5. **Scheduling**: Si es batch nocturno, asegurarse de que las tareas no corren mÃ¡s de lo necesario.
6. **Savings Plans**: Fargate Savings Plans para workloads predecibles (hasta 50% descuento).
7. **Comprimir datos**: Inputs y outputs comprimidos (gzip/snappy) reducen tiempo de I/O.

---

## 12. Enlaces Oficiales

| Recurso | URL |
|---------|-----|
| ECS Developer Guide | https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ |
| Fargate User Guide | https://docs.aws.amazon.com/AmazonECS/latest/userguide/what-is-fargate.html |
| ECR User Guide | https://docs.aws.amazon.com/AmazonECR/latest/userguide/ |
| Task Definition Parameters | https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition_parameters.html |
| Step Functions Developer Guide | https://docs.aws.amazon.com/step-functions/latest/dg/ |
| Fargate Pricing | https://aws.amazon.com/fargate/pricing/ |
| Fargate Spot | https://docs.aws.amazon.com/AmazonECS/latest/developerguide/fargate-capacity-providers.html |
| Container Insights | https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/ContainerInsights.html |
| Docker Best Practices | https://docs.docker.com/develop/develop-images/dockerfile_best-practices/ |

---

> **Ruta de aprendizaje**: Lambda â†’ **Fargate** (estÃ¡s aquÃ­) â†’ Glue (ETL Spark managed) â†’ EMR (Big Data a escala). Cada herramienta resuelve un rango de volumen de datos diferente.
