---
id: "l2-kafka-streaming"
version: "1.0.0"
lastUpdated: "2026-01-05"

title:
  es: "Kafka: Streaming en Tiempo Real"
  en: "Kafka: Real-Time Streaming"
  pt: "Kafka: Streaming em Tempo Real"

subtitle:
  es: "Event sourcing, exactly-once y arquitecturas event-driven"
  en: "Event sourcing, exactly-once and event-driven architectures"
  pt: "Event sourcing, exactly-once e arquiteturas event-driven"

level: 2
phase: "l2-streaming"
estimatedTime: "28-35 horas"

prerequisites:
  - "l1-python-fundamentals"
  - "l1-docker-containers"

tags:
  - "kafka"
  - "streaming"
  - "real-time"
  - "event-sourcing"
  - "distributed"

theoreticalFoundations:
  - "Event sourcing"
  - "CQRS"
  - "Exactly-once semantics"
  - "Distributed log"
---

<!-- 
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ðŸ“š BLOQUE: APACHE KAFKA                                     â•‘
â•‘  Nivel: 2 | Fase: Real-Time Streaming                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-->

# ðŸ“¡ Kafka: Streaming en Tiempo Real

> **Objetivo**: Dominar Apache Kafka para streaming de datos. Entender event sourcing, exactly-once semantics, y arquitecturas event-driven.

---

## ðŸ§  Mapa Conceptual

```mermaid
mindmap
  root((Apache Kafka
    Mastery))
    ðŸ”¬ Architecture
      Brokers
        Leader election
        Replication
        ISR
      Topics
        Partitions
        Retention
        Compaction
      Producers
        Serialization
        Partitioning
        Batching
      Consumers
        Consumer groups
        Offsets
        Rebalancing
    ðŸ“– Core Concepts
      Distributed Log
        Immutable
        Ordered
        Durable
      Partitions
        Parallelism
        Ordering
        Key-based
      Offsets
        Position
        Commit
        Seek
      Consumer Groups
        Load balancing
        Fault tolerance
    âš¡ Semantics
      At-most-once
        Fire and forget
        May lose
      At-least-once
        Retry on failure
        May duplicate
      Exactly-once
        Transactions
        Idempotent
        Complex
    ðŸ—ï¸ Patterns
      Event Sourcing
        State from events
        Replay
        Audit trail
      CQRS
        Read/write split
        Projections
        Eventually consistent
      Kafka Streams
        Stream processing
        KTable
        Joins
      CDC
        Database events
        Debezium
        Real-time sync
```

---

## ðŸ”— First Principles: De la TeorÃ­a a la PrÃ¡ctica

| Concepto | QuÃ© significa | ImplementaciÃ³n en Kafka |
|----------|---------------|------------------------|
| **Distributed Log** | Secuencia ordenada e inmutable de eventos | Kafka es un commit log distribuido. Los mensajes se appendean, nunca se modifican. |
| **Partitions** | DivisiÃ³n del topic para paralelismo | Cada particiÃ³n es una secuencia ordenada independiente. Keys determinan particiÃ³n. |
| **Consumer Groups** | MÃºltiples consumidores cooperando | Cada particiÃ³n asignada a un consumidor. Agregar consumidores = mÃ¡s paralelismo. |
| **Exactly-Once** | Cada mensaje procesado exactamente una vez | Requiere transacciones + idempotent producer + consumer commit atÃ³mico. |
| **Event Sourcing** | Estado derivado de secuencia de eventos | No guardas estado, guardas eventos. Estado = replay de eventos. |

> [!IMPORTANT]
> ðŸ§  **First Principle clave**: Kafka no es una message queue, es un **distributed commit log**. Los mensajes persisten por configuraciÃ³n de retenciÃ³n, no se borran al leer. MÃºltiples consumidores pueden leer los mismos mensajes.

---

## ðŸ“‹ Technical Cheat Sheet

### ðŸ–¥ï¸ Comandos CLI CrÃ­ticos

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TOPICS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Listar topics
kafka-topics.sh --bootstrap-server localhost:9092 --list

# Crear topic
kafka-topics.sh --bootstrap-server localhost:9092 \
  --create \
  --topic orders \
  --partitions 6 \
  --replication-factor 3 \
  --config retention.ms=604800000  # 7 dÃ­as

# Describir topic
kafka-topics.sh --bootstrap-server localhost:9092 \
  --describe \
  --topic orders

# Aumentar particiones (no se puede reducir)
kafka-topics.sh --bootstrap-server localhost:9092 \
  --alter \
  --topic orders \
  --partitions 12

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PRODUCER/CONSUMER CLI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Producir mensajes
kafka-console-producer.sh --bootstrap-server localhost:9092 \
  --topic orders

# Producir con key
kafka-console-producer.sh --bootstrap-server localhost:9092 \
  --topic orders \
  --property "key.separator=:" \
  --property "parse.key=true"
# Input: customer_123:{"order_id": "456"}

# Consumir desde inicio
kafka-console-consumer.sh --bootstrap-server localhost:9092 \
  --topic orders \
  --from-beginning

# Consumir con consumer group
kafka-console-consumer.sh --bootstrap-server localhost:9092 \
  --topic orders \
  --group my-consumer-group

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONSUMER GROUPS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Listar consumer groups
kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list

# Describir consumer group (ver lag)
kafka-consumer-groups.sh --bootstrap-server localhost:9092 \
  --describe \
  --group my-consumer-group

# Reset offsets a inicio
kafka-consumer-groups.sh --bootstrap-server localhost:9092 \
  --group my-consumer-group \
  --topic orders \
  --reset-offsets \
  --to-earliest \
  --execute

# Reset a timestamp especÃ­fico
kafka-consumer-groups.sh --bootstrap-server localhost:9092 \
  --group my-consumer-group \
  --topic orders \
  --reset-offsets \
  --to-datetime "2026-01-01T00:00:00.000" \
  --execute
```

### ðŸ“ Producer en Python

```python
# producer.py
# ðŸ”¥ BEST PRACTICE: Idempotent producer con retry

from confluent_kafka import Producer
import json
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ConfiguraciÃ³n de producciÃ³n
config = {
    'bootstrap.servers': 'localhost:9092',
    
    # ðŸ”’ Idempotencia - evita duplicados en retry
    'enable.idempotence': True,
    
    # Acknowledgments - esperar a replicas
    'acks': 'all',  # Espera a todas las replicas en ISR
    
    # Retries automÃ¡ticos
    'retries': 5,
    'retry.backoff.ms': 100,
    
    # Batching para throughput
    'batch.size': 16384,  # 16KB
    'linger.ms': 5,  # Esperar hasta 5ms para batch
    
    # CompresiÃ³n
    'compression.type': 'snappy'
}

producer = Producer(config)

def delivery_callback(err, msg):
    """Callback ejecutado cuando mensaje es acknowledged"""
    if err:
        logger.error(f'Delivery failed: {err}')
    else:
        logger.info(f'Message delivered to {msg.topic()}[{msg.partition()}] @ offset {msg.offset()}')

def produce_order(order: dict):
    """Producir orden con key para partitioning consistente"""
    
    # Key = customer_id para que Ã³rdenes del mismo cliente vayan a la misma particiÃ³n
    key = order['customer_id']
    value = json.dumps(order)
    
    producer.produce(
        topic='orders',
        key=key.encode('utf-8'),
        value=value.encode('utf-8'),
        callback=delivery_callback
    )
    
    # Flush periÃ³dico (o al final del batch)
    producer.poll(0)  # Trigger callbacks sin bloquear

def close():
    """Flush todos los mensajes pendientes"""
    producer.flush(timeout=10)  # Esperar hasta 10 segundos

# Uso
if __name__ == '__main__':
    orders = [
        {'order_id': '1', 'customer_id': 'c100', 'amount': 99.99},
        {'order_id': '2', 'customer_id': 'c100', 'amount': 149.99},
        {'order_id': '3', 'customer_id': 'c200', 'amount': 29.99},
    ]
    
    for order in orders:
        produce_order(order)
    
    close()
```

### ðŸ“ Consumer en Python

```python
# consumer.py
# ðŸ”¥ BEST PRACTICE: Consumer con manejo de errores y commit manual

from confluent_kafka import Consumer, KafkaError, KafkaException
import json
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

config = {
    'bootstrap.servers': 'localhost:9092',
    'group.id': 'order-processor',
    
    # ðŸ”’ Manual commit para control de exactly-once
    'enable.auto.commit': False,
    
    # Desde dÃ³nde empezar si no hay offset guardado
    'auto.offset.reset': 'earliest',
    
    # AislaciÃ³n de transacciones
    'isolation.level': 'read_committed',
    
    # Max records por poll
    'max.poll.records': 500,
}

consumer = Consumer(config)

def process_message(msg):
    """Procesar mensaje individual"""
    try:
        key = msg.key().decode('utf-8') if msg.key() else None
        value = json.loads(msg.value().decode('utf-8'))
        
        logger.info(f"Processing order: {value['order_id']} for customer: {key}")
        
        # Tu lÃ³gica de negocio aquÃ­
        save_to_database(value)
        
        return True
    except Exception as e:
        logger.error(f"Error processing message: {e}")
        return False

def consume_loop():
    """Loop principal de consumo"""
    consumer.subscribe(['orders'])
    
    try:
        while True:
            msg = consumer.poll(timeout=1.0)
            
            if msg is None:
                continue
            
            if msg.error():
                if msg.error().code() == KafkaError._PARTITION_EOF:
                    # End of partition - normal
                    logger.debug(f'Reached end of partition {msg.partition()}')
                else:
                    raise KafkaException(msg.error())
            else:
                # Procesar mensaje
                success = process_message(msg)
                
                if success:
                    # âœ… Commit solo si procesamos exitosamente
                    consumer.commit(msg)
                else:
                    # âŒ No commiteamos - se re-procesarÃ¡
                    logger.warning("Message not committed, will retry")
                    
    except KeyboardInterrupt:
        logger.info("Shutting down...")
    finally:
        consumer.close()

if __name__ == '__main__':
    consume_loop()
```

### ðŸ“ Exactly-Once con Transacciones

```python
# transactional_producer.py
# ðŸ”¥ BEST PRACTICE: Transacciones para exactly-once

from confluent_kafka import Producer

config = {
    'bootstrap.servers': 'localhost:9092',
    'transactional.id': 'order-processor-tx-1',  # ID Ãºnico para transacciÃ³n
    'enable.idempotence': True,
    'acks': 'all'
}

producer = Producer(config)

# Inicializar transacciones (una vez al inicio)
producer.init_transactions()

def process_and_produce_transactionally(input_messages):
    """
    Lee de un topic, procesa, y escribe a otro topic
    de forma atÃ³mica (exactly-once)
    """
    try:
        producer.begin_transaction()
        
        for msg in input_messages:
            # Transformar mensaje
            transformed = transform(msg)
            
            # Producir resultado
            producer.produce(
                topic='processed-orders',
                value=json.dumps(transformed).encode('utf-8')
            )
        
        # Commit de la transacciÃ³n (incluye offsets del consumer)
        producer.commit_transaction()
        
    except Exception as e:
        # Abort si algo falla - nada se escribe
        producer.abort_transaction()
        raise e
```

### ðŸ—ï¸ Arquitectura Event-Driven

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EVENT-DRIVEN ARCHITECTURE                     â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Web App     â”‚â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚        KAFKA CLUSTER            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚                                 â”‚  â”‚
â”‚                          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚  â”‚ Topic: orders              â”‚ â”‚  â”‚
â”‚  â”‚ Mobile App  â”‚â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚  â”‚ Partitions: 12            â”‚ â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  â”‚ Replication: 3            â”‚ â”‚  â”‚
â”‚                          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚                                 â”‚  â”‚
â”‚  â”‚ API Gateway â”‚â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  â”‚ Topic: inventory-events   â”‚ â”‚  â”‚
â”‚                          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚                          â”‚                                 â”‚  â”‚
â”‚                          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚                          â”‚  â”‚ Topic: notifications      â”‚ â”‚  â”‚
â”‚                          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                  â”‚             â”‚              â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚            â–¼                     â–¼             â–¼        â”‚    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚   â”‚ Order Service   â”‚  â”‚ Inventory   â”‚  â”‚ Email     â”‚  â”‚    â”‚
â”‚   â”‚ (Kafka Streams) â”‚  â”‚ Service     â”‚  â”‚ Service   â”‚  â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚                                                         â”‚    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚   â”‚ Analytics       â”‚  â”‚ Data Lake   â”‚  â”‚ Search    â”‚  â”‚    â”‚
â”‚   â”‚ (Flink)         â”‚  â”‚ (S3 Sink)   â”‚  â”‚ (Elastic) â”‚  â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚            CONSUMERS                                    â”‚    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### âš ï¸ Gotchas de Nivel Senior

> [!WARNING]
> **Gotcha #1: Partitions y ordering**
> 
> El orden solo estÃ¡ garantizado DENTRO de una particiÃ³n.
> 
> ```python
> # âŒ INCORRECTO - Ã“rdenes de mismo cliente pueden desordenarse
> producer.produce(topic='orders', value=order)  # Random partition
> 
> # âœ… CORRECTO - Key = customer_id para ordenamiento
> producer.produce(
>     topic='orders', 
>     key=customer_id.encode(),  # Mismo key â†’ misma particiÃ³n
>     value=order
> )
> ```

> [!WARNING]
> **Gotcha #2: Consumer group rebalancing**
> 
> Rebalancing causa duplicados si no manejas correctamente.
> 
> ```python
> # âœ… Commit sÃ­ncrono antes de rebalance
> def on_revoke(consumer, partitions):
>     consumer.commit(asynchronous=False)
>     
> consumer.subscribe(['orders'], on_revoke=on_revoke)
> ```

> [!WARNING]
> **Gotcha #3: Lag creciente sin bound**
> 
> Si consumidores son mÃ¡s lentos que productores, lag crece infinito.
> 
> ```bash
> # Monitorear lag constantemente
> kafka-consumer-groups.sh --describe --group my-group
> 
> # Si lag crece: escalar consumidores (hasta # particiones)
> ```

> [!WARNING]
> **Gotcha #4: Log compaction y tombstones**
> 
> Topics compacted borran mensajes antiguos con mismo key.
> 
> ```bash
> # Para topics de state (CDC), usar compaction
> --config cleanup.policy=compact
> 
> # Delete = mensaje con value=null (tombstone)
> producer.produce(topic='users', key='user_123', value=None)
> ```

---

## ðŸ“Š Comparativa de Delivery Semantics

| SemÃ¡ntica | GarantÃ­a | ImplementaciÃ³n | CuÃ¡ndo usar |
|-----------|----------|----------------|-------------|
| **At-most-once** | Puede perder | Fire-and-forget, acks=0 | Logs, mÃ©tricas no crÃ­ticas |
| **At-least-once** | Puede duplicar | Retry + manual commit | Default, con idempotencia en consumer |
| **Exactly-once** | Exacto | Transactions + EOS | Financiero, crÃ­tico |

---

## ðŸ“š BibliografÃ­a AcadÃ©mica y Profesional

### ðŸ“– Recursos Seminales

| Recurso | Autor | Por quÃ© consumirlo |
|---------|-------|-------------------|
| **Kafka: The Definitive Guide** | Narkhede, Shapira & Palino | El libro completo de O'Reilly. |
| **Designing Event-Driven Systems** | Ben Stopford | Free ebook de Confluent sobre arquitecturas. |
| **Kafka Documentation** | Confluent | Referencia oficial actualizada. |

### ðŸ“„ Papers Clave

1. **"Kafka: a Distributed Messaging System for Log Processing"** (LinkedIn, 2011)
   - ðŸ”— [Original Paper](https://www.microsoft.com/en-us/research/wp-content/uploads/2017/09/Kafka.pdf)
   - ðŸ’¡ **Insight clave**: DiseÃ±o original de Kafka como log distribuido.

2. **"Exactly-once Semantics in Apache Kafka"** (Confluent, 2017)
   - ðŸ”— [Confluent Blog](https://www.confluent.io/blog/exactly-once-semantics-are-possible-heres-how-apache-kafka-does-it/)
   - ðŸ’¡ **Insight clave**: ImplementaciÃ³n de exactly-once con transactions.

---

## âœ… Checklist de Dominio

Antes de avanzar, verifica que puedes:

- [ ] Crear topics con particiones y replicaciÃ³n adecuadas
- [ ] Escribir producers con idempotencia habilitada
- [ ] Implementar consumers con commit manual
- [ ] Explicar la diferencia entre at-least-once y exactly-once
- [ ] Usar consumer groups para paralelismo
- [ ] Monitorear lag y diagnosticar problemas
- [ ] Implementar transacciones para exactly-once
- [ ] DiseÃ±ar esquema de partitioning basado en keys
- [ ] Manejar rebalancing sin perder mensajes
- [ ] Elegir retention policy correcta (time vs size vs compact)

---

*Ãšltima actualizaciÃ³n: Enero 2026 | VersiÃ³n: 1.0.0*

